# DQN Parameters
episode_number: 1000000 #  type=int, help='Number of episodes'
learning_rate: 0.00005 #  type=float, help='Learning rate'
optimizer: 'RMSprop' # choices=['Adam', 'RMSProp'], help='Optimization method'
memory_capacity: 1000000 #  type=int, help='Memory capacity'
batch_size: 64 # type=int, help='Batch size')
target_frequency: 10000 #  type=int, help='Number of steps between the updates of target network')
maximum_exploration: 100000 # type=int, help='Maximum exploration step'
first_step_memory: 0 # type=float, help='Number of initial steps for just filling the memory'
replay_steps: 4 # type=float, help='Steps between updating the network'
number_nodes: 256 #  type=int, help='Number of nodes in each layer of NN'
target_type: 'DDQN' #  choices=['DQN', 'DDQN']
memory: 'PER' # choices=['UER', 'PER']
prioritization_scale: 0.5 #  type=float, help='Scale for prioritization')
dueling: false # action='store_true', help='Enable Dueling architecture if "store_false" ')

gpu_num: '2' # help='Number of GPU to use')
test: false # '--test', action='store_true', help='Enable the test phase if "store_false"'

# Game Parameters
env: 'IM' # help='environment to train on'
grid_size: 10 # type=int, help='Grid size')
env_steps: 100 # '--max-timestep', type=int, help='Maximum number of timesteps per episode')
game_mode: 1 # choices=[0, 1], type=int, help='Mode of the game, '
                                # '0: landmarks and agents fixed, '
                                # '1: landmarks and agents random ')

reward_mode: 1 # choices=[0, 1, 2], type=int, help='Mode of the reward', '0: Only terminal rewards'
                                                                                         #  '1: Partial rewards '
                                                                                            #  '(number of unoccupied landmarks'
                                                                                            #  '2: Full rewards '
                                                                                            #  '(sum of dinstances of agents to landmarks)')
max_random_moves: 0 # type=int, help='Maximum number of random initial moves for the agents')


# Visualization Parameters
render: true #  action='store_false', help='Turn on visualization if "store_false"')
recorder: false #  action='store_true', help='Store the visualization as a movie' 'if "store_false"')