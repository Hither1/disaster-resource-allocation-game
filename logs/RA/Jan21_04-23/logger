2024-01-21 04:23:52,039 : lr: 0.001
2024-01-21 04:23:52,039 : gamma: 0.1
2024-01-21 04:23:52,039 : gamma_rate: 0.002
2024-01-21 04:23:52,039 : gamma_final: 0.9
2024-01-21 04:23:52,040 : tau: 1.0
2024-01-21 04:23:52,040 : entropy: 0.005
2024-01-21 04:23:52,040 : grad_entropy: 1.0
2024-01-21 04:23:52,040 : seed: 1
2024-01-21 04:23:52,040 : workers: 6
2024-01-21 04:23:52,040 : A2C_steps: 20
2024-01-21 04:23:52,040 : env_steps: 20
2024-01-21 04:23:52,040 : start_eps: 2000
2024-01-21 04:23:52,040 : ToM_train_loops: 1
2024-01-21 04:23:52,040 : policy_train_loops: 1
2024-01-21 04:23:52,040 : test_eps: 20
2024-01-21 04:23:52,040 : ToM_frozen: 5
2024-01-21 04:23:52,040 : env: RA
2024-01-21 04:23:52,040 : optimizer: Adam
2024-01-21 04:23:52,040 : amsgrad: True
2024-01-21 04:23:52,040 : load_model_dir: None
2024-01-21 04:23:52,040 : load_executor_dir: None
2024-01-21 04:23:52,040 : log_dir: logs/RA/Jan21_04-23
2024-01-21 04:23:52,040 : model: ToM2C
2024-01-21 04:23:52,040 : gpu_id: [-1]
2024-01-21 04:23:52,040 : norm_reward: True
2024-01-21 04:23:52,040 : train_comm: False
2024-01-21 04:23:52,040 : random_target: True
2024-01-21 04:23:52,040 : mask_actions: False
2024-01-21 04:23:52,040 : mask: False
2024-01-21 04:23:52,040 : render: False
2024-01-21 04:23:52,040 : fix: False
2024-01-21 04:23:52,041 : shared_optimizer: True
2024-01-21 04:23:52,041 : train_mode: -1
2024-01-21 04:23:52,041 : lstm_out: 32
2024-01-21 04:23:52,041 : sleep_time: 0
2024-01-21 04:23:52,041 : max_step: 3000000
2024-01-21 04:23:52,041 : render_save: False
2024-01-21 04:23:52,041 : num_agents: -1
2024-01-21 04:23:52,041 : num_targets: -1
2024-01-21 04:25:32,325 : Time 00h 01m 38s, ave eps reward [-140.45 -140.45 -140.45], ave eps length 20.0, reward step [-7.02 -7.02 -7.02], FPS 8.39, mean reward -140.45, std reward 32.12432878676223, AG 0.0
2024-01-21 04:27:09,081 : Time 00h 03m 14s, ave eps reward [-150.52 -150.52 -150.52], ave eps length 20.0, reward step [-7.53 -7.53 -7.53], FPS 8.62, mean reward -150.525, std reward 26.691513164299995, AG 0.0
