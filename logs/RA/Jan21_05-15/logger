2024-01-21 05:15:50,312 : lr: 0.001
2024-01-21 05:15:50,312 : gamma: 0.1
2024-01-21 05:15:50,312 : gamma_rate: 0.002
2024-01-21 05:15:50,312 : gamma_final: 0.9
2024-01-21 05:15:50,312 : tau: 1.0
2024-01-21 05:15:50,312 : entropy: 0.005
2024-01-21 05:15:50,312 : grad_entropy: 1.0
2024-01-21 05:15:50,312 : seed: 1
2024-01-21 05:15:50,313 : workers: 6
2024-01-21 05:15:50,313 : A2C_steps: 20
2024-01-21 05:15:50,313 : env_steps: 20
2024-01-21 05:15:50,313 : start_eps: 2000
2024-01-21 05:15:50,313 : ToM_train_loops: 1
2024-01-21 05:15:50,313 : policy_train_loops: 1
2024-01-21 05:15:50,313 : test_eps: 20
2024-01-21 05:15:50,313 : ToM_frozen: 5
2024-01-21 05:15:50,313 : env: RA
2024-01-21 05:15:50,313 : optimizer: Adam
2024-01-21 05:15:50,313 : amsgrad: True
2024-01-21 05:15:50,313 : load_model_dir: None
2024-01-21 05:15:50,313 : load_executor_dir: None
2024-01-21 05:15:50,313 : log_dir: logs/RA/Jan21_05-15
2024-01-21 05:15:50,313 : model: ToM2C
2024-01-21 05:15:50,313 : gpu_id: [-1]
2024-01-21 05:15:50,313 : norm_reward: True
2024-01-21 05:15:50,313 : train_comm: False
2024-01-21 05:15:50,313 : random_target: True
2024-01-21 05:15:50,313 : mask_actions: False
2024-01-21 05:15:50,313 : mask: False
2024-01-21 05:15:50,313 : render: False
2024-01-21 05:15:50,313 : fix: False
2024-01-21 05:15:50,313 : shared_optimizer: True
2024-01-21 05:15:50,313 : train_mode: -1
2024-01-21 05:15:50,313 : lstm_out: 32
2024-01-21 05:15:50,313 : sleep_time: 0
2024-01-21 05:15:50,314 : max_step: 3000000
2024-01-21 05:15:50,314 : render_save: False
2024-01-21 05:15:50,314 : num_agents: -1
2024-01-21 05:15:50,314 : num_targets: -1
2024-01-21 05:17:31,874 : Time 00h 01m 39s, ave eps reward [-140.43 -140.43 -140.43], ave eps length 20.0, reward step [-7.02 -7.02 -7.02], FPS 7.18, mean reward -140.425, std reward 23.780388453513538, AG 0.0
2024-01-21 05:19:08,552 : Time 00h 03m 15s, ave eps reward [-131.9 -131.9 -131.9], ave eps length 20.0, reward step [-6.6 -6.6 -6.6], FPS 8.06, mean reward -131.9, std reward 17.120601624942974, AG 0.0
