obs <crafter.objects.Shelter object at 0x15e48c8b0> [ 0 39  0  0 39  0  0 14  0]
obs <crafter.objects.Warehouse object at 0x12c07b9d0> [ 0 39  0  0 40  0  0  9  0]
obs <crafter.objects.Station object at 0x15e4923a0> [ 0  9  0  0  9  0  0 14  0]
obs <crafter.objects.Shelter object at 0x15e48c8b0> [ 0 39  0  0 39  0  0 11  0]
obs <crafter.objects.Warehouse object at 0x12c07b9d0> [ 0 41  0  0 40  0  0  9  0]
obs <crafter.objects.Station object at 0x15e4923a0> [ 0  9  0  0  9  0  0 11  0]
{'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0}
training start after waiting for 0.002830028533935547 seconds
19 rew tensor(0.8249, dtype=torch.float64) delta_t tensor(0.6054, dtype=torch.float64)
19 gae_duplicate tensor(0.5408, dtype=torch.float64) tensor(-6.5610, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8617, dtype=torch.float64) delta_t tensor(0.7652, dtype=torch.float64)
18 gae_duplicate tensor(0.7810, dtype=torch.float64) tensor(-10.1117, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9039, dtype=torch.float64) delta_t tensor(0.7649, dtype=torch.float64)
17 gae_duplicate tensor(0.5968, dtype=torch.float64) tensor(-9.8437, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9532, dtype=torch.float64) delta_t tensor(0.8028, dtype=torch.float64)
16 gae_duplicate tensor(0.6546, dtype=torch.float64) tensor(-10.0051, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(1.0118, dtype=torch.float64) delta_t tensor(0.9982, dtype=torch.float64)
15 gae_duplicate tensor(0.9834, dtype=torch.float64) tensor(-13.1881, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(1.0831, dtype=torch.float64) delta_t tensor(1.0704, dtype=torch.float64)
14 gae_duplicate tensor(1.0502, dtype=torch.float64) tensor(-14.3224, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(1.1725, dtype=torch.float64) delta_t tensor(1.1514, dtype=torch.float64)
13 gae_duplicate tensor(1.1323, dtype=torch.float64) tensor(-14.6275, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(1.2896, dtype=torch.float64) delta_t tensor(1.2646, dtype=torch.float64)
12 gae_duplicate tensor(1.2398, dtype=torch.float64) tensor(-16.7801, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(1.4525, dtype=torch.float64) delta_t tensor(1.4177, dtype=torch.float64)
11 gae_duplicate tensor(1.4108, dtype=torch.float64) tensor(-18.8181, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(1.4093, dtype=torch.float64) delta_t tensor(1.3472, dtype=torch.float64)
10 gae_duplicate tensor(1.1844, dtype=torch.float64) tensor(-18.5972, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(1.3822, dtype=torch.float64) delta_t tensor(1.3029, dtype=torch.float64)
9 gae_duplicate tensor(1.1537, dtype=torch.float64) tensor(-16.6169, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(1.3735, dtype=torch.float64) delta_t tensor(1.2626, dtype=torch.float64)
8 gae_duplicate tensor(1.1883, dtype=torch.float64) tensor(-15.4603, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(1.3282, dtype=torch.float64) delta_t tensor(1.2193, dtype=torch.float64)
7 gae_duplicate tensor(1.0990, dtype=torch.float64) tensor(-17.5744, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(0.3828, dtype=torch.float64) delta_t tensor(0.0400, dtype=torch.float64)
6 gae_duplicate tensor(-0.5339, dtype=torch.float64) tensor(-2.0414, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.3352, dtype=torch.float64) delta_t tensor(-0.4974, dtype=torch.float64)
5 gae_duplicate tensor(-0.8014, dtype=torch.float64) tensor(6.9200, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.0349, dtype=torch.float64) delta_t tensor(-1.2082, dtype=torch.float64)
4 gae_duplicate tensor(-1.5998, dtype=torch.float64) tensor(14.5352, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.0119, dtype=torch.float64) delta_t tensor(-1.2939, dtype=torch.float64)
3 gae_duplicate tensor(-1.6380, dtype=torch.float64) tensor(15.4795, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.1122, dtype=torch.float64) delta_t tensor(-1.3463, dtype=torch.float64)
2 gae_duplicate tensor(-1.5431, dtype=torch.float64) tensor(18.9529, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:4592.2548828125
value loss:234.2449493408203
entropies:219.52969360351562
Policy training finished
---------------------
gamma: 0.1
/Users/suhuangyuan/DRA/ToM2C/shared_optim.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1420.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
training start after waiting for 4.9058427810668945 seconds
19 rew tensor(0.8480, dtype=torch.float64) delta_t tensor(0.6434, dtype=torch.float64)
19 gae_duplicate tensor(0.5374, dtype=torch.float64) tensor(-7.3151, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8444, dtype=torch.float64) delta_t tensor(0.7203, dtype=torch.float64)
18 gae_duplicate tensor(0.7511, dtype=torch.float64) tensor(-8.9700, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.8188, dtype=torch.float64) delta_t tensor(0.6930, dtype=torch.float64)
17 gae_duplicate tensor(0.5241, dtype=torch.float64) tensor(-9.4316, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.7934, dtype=torch.float64) delta_t tensor(0.6399, dtype=torch.float64)
16 gae_duplicate tensor(0.1560, dtype=torch.float64) tensor(-8.8997, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6922, dtype=torch.float64) delta_t tensor(0.6494, dtype=torch.float64)
15 gae_duplicate tensor(-0.3849, dtype=torch.float64) tensor(-9.6845, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9488, dtype=torch.float64) delta_t tensor(0.9059, dtype=torch.float64)
14 gae_duplicate tensor(0.9502, dtype=torch.float64) tensor(-11.8957, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9757, dtype=torch.float64) delta_t tensor(0.9390, dtype=torch.float64)
13 gae_duplicate tensor(0.9775, dtype=torch.float64) tensor(-13.9802, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9726, dtype=torch.float64) delta_t tensor(0.9242, dtype=torch.float64)
12 gae_duplicate tensor(0.9710, dtype=torch.float64) tensor(-11.0686, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.9160, dtype=torch.float64) delta_t tensor(0.8590, dtype=torch.float64)
11 gae_duplicate tensor(0.4071, dtype=torch.float64) tensor(-11.8107, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.8048, dtype=torch.float64) delta_t tensor(0.7093, dtype=torch.float64)
10 gae_duplicate tensor(0.0179, dtype=torch.float64) tensor(-10.0009, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.4660, dtype=torch.float64) delta_t tensor(0.4050, dtype=torch.float64)
9 gae_duplicate tensor(-0.1074, dtype=torch.float64) tensor(-6.5719, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.2995, dtype=torch.float64) delta_t tensor(0.1584, dtype=torch.float64)
8 gae_duplicate tensor(-0.3442, dtype=torch.float64) tensor(-2.2774, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(0.1262, dtype=torch.float64) delta_t tensor(-0.0649, dtype=torch.float64)
7 gae_duplicate tensor(-0.3514, dtype=torch.float64) tensor(0.7121, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.8344, dtype=torch.float64) delta_t tensor(-1.1343, dtype=torch.float64)
6 gae_duplicate tensor(-1.3405, dtype=torch.float64) tensor(14.0290, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.3140, dtype=torch.float64) delta_t tensor(-1.5122, dtype=torch.float64)
5 gae_duplicate tensor(-1.9367, dtype=torch.float64) tensor(19.8491, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.6335, dtype=torch.float64) delta_t tensor(-1.7999, dtype=torch.float64)
4 gae_duplicate tensor(-2.1597, dtype=torch.float64) tensor(27.9768, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.5049, dtype=torch.float64) delta_t tensor(-1.7849, dtype=torch.float64)
3 gae_duplicate tensor(-2.3155, dtype=torch.float64) tensor(21.3187, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.5445, dtype=torch.float64) delta_t tensor(-1.7709, dtype=torch.float64)
2 gae_duplicate tensor(-2.4021, dtype=torch.float64) tensor(25.1167, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:65.1965103149414
value loss:217.32496643066406
entropies:218.5475616455078
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.283369064331055 seconds
19 rew tensor(0.8444, dtype=torch.float64) delta_t tensor(0.6319, dtype=torch.float64)
19 gae_duplicate tensor(0.5288, dtype=torch.float64) tensor(-7.7843, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8567, dtype=torch.float64) delta_t tensor(0.7079, dtype=torch.float64)
18 gae_duplicate tensor(0.7004, dtype=torch.float64) tensor(-8.9049, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.8696, dtype=torch.float64) delta_t tensor(0.7288, dtype=torch.float64)
17 gae_duplicate tensor(0.7624, dtype=torch.float64) tensor(-9.1822, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.8831, dtype=torch.float64) delta_t tensor(0.6864, dtype=torch.float64)
16 gae_duplicate tensor(0.6538, dtype=torch.float64) tensor(-10.3763, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.8973, dtype=torch.float64) delta_t tensor(0.8590, dtype=torch.float64)
15 gae_duplicate tensor(0.8562, dtype=torch.float64) tensor(-11.2976, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9122, dtype=torch.float64) delta_t tensor(0.8647, dtype=torch.float64)
14 gae_duplicate tensor(0.8668, dtype=torch.float64) tensor(-10.2086, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9278, dtype=torch.float64) delta_t tensor(0.8817, dtype=torch.float64)
13 gae_duplicate tensor(0.8786, dtype=torch.float64) tensor(-13.3159, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9443, dtype=torch.float64) delta_t tensor(0.8916, dtype=torch.float64)
12 gae_duplicate tensor(0.8931, dtype=torch.float64) tensor(-10.5189, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.9618, dtype=torch.float64) delta_t tensor(0.9103, dtype=torch.float64)
11 gae_duplicate tensor(0.9421, dtype=torch.float64) tensor(-13.0447, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.8300, dtype=torch.float64) delta_t tensor(0.7157, dtype=torch.float64)
10 gae_duplicate tensor(0.6678, dtype=torch.float64) tensor(-10.5477, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.5369, dtype=torch.float64) delta_t tensor(0.4135, dtype=torch.float64)
9 gae_duplicate tensor(0.3049, dtype=torch.float64) tensor(-5.2773, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.2939, dtype=torch.float64) delta_t tensor(0.1265, dtype=torch.float64)
8 gae_duplicate tensor(-0.1684, dtype=torch.float64) tensor(-2.0438, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.0853, dtype=torch.float64) delta_t tensor(-0.2274, dtype=torch.float64)
7 gae_duplicate tensor(-0.6828, dtype=torch.float64) tensor(2.2358, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.8965, dtype=torch.float64) delta_t tensor(-1.2268, dtype=torch.float64)
6 gae_duplicate tensor(-1.5494, dtype=torch.float64) tensor(14.9248, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.3814, dtype=torch.float64) delta_t tensor(-1.5479, dtype=torch.float64)
5 gae_duplicate tensor(-2.4459, dtype=torch.float64) tensor(17.8071, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.9334, dtype=torch.float64) delta_t tensor(-2.1107, dtype=torch.float64)
4 gae_duplicate tensor(-2.8165, dtype=torch.float64) tensor(24.2816, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.5365, dtype=torch.float64) delta_t tensor(-1.8123, dtype=torch.float64)
3 gae_duplicate tensor(-2.3425, dtype=torch.float64) tensor(24.6787, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.4498, dtype=torch.float64) delta_t tensor(-1.6823, dtype=torch.float64)
2 gae_duplicate tensor(-2.3449, dtype=torch.float64) tensor(23.7009, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:136.2805938720703
value loss:235.0496368408203
entropies:217.56573486328125
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.283874750137329 seconds
19 rew tensor(0.8405, dtype=torch.float64) delta_t tensor(0.6215, dtype=torch.float64)
19 gae_duplicate tensor(0.5261, dtype=torch.float64) tensor(-8.0862, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8279, dtype=torch.float64) delta_t tensor(0.6538, dtype=torch.float64)
18 gae_duplicate tensor(0.5635, dtype=torch.float64) tensor(-8.7835, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.7935, dtype=torch.float64) delta_t tensor(0.6005, dtype=torch.float64)
17 gae_duplicate tensor(0.2365, dtype=torch.float64) tensor(-7.9614, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.7483, dtype=torch.float64) delta_t tensor(0.6035, dtype=torch.float64)
16 gae_duplicate tensor(-0.0980, dtype=torch.float64) tensor(-8.4676, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6389, dtype=torch.float64) delta_t tensor(0.5580, dtype=torch.float64)
15 gae_duplicate tensor(-0.6154, dtype=torch.float64) tensor(-7.9170, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8924, dtype=torch.float64) delta_t tensor(0.8074, dtype=torch.float64)
14 gae_duplicate tensor(0.7788, dtype=torch.float64) tensor(-10.5838, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9033, dtype=torch.float64) delta_t tensor(0.8367, dtype=torch.float64)
13 gae_duplicate tensor(0.8580, dtype=torch.float64) tensor(-11.9301, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9040, dtype=torch.float64) delta_t tensor(0.8216, dtype=torch.float64)
12 gae_duplicate tensor(0.8493, dtype=torch.float64) tensor(-10.4226, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.7879, dtype=torch.float64) delta_t tensor(0.7030, dtype=torch.float64)
11 gae_duplicate tensor(0.0814, dtype=torch.float64) tensor(-9.7864, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.7234, dtype=torch.float64) delta_t tensor(0.5728, dtype=torch.float64)
10 gae_duplicate tensor(-0.0836, dtype=torch.float64) tensor(-8.2987, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.5094, dtype=torch.float64) delta_t tensor(0.3862, dtype=torch.float64)
9 gae_duplicate tensor(-0.2648, dtype=torch.float64) tensor(-5.4100, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.2312, dtype=torch.float64) delta_t tensor(0.0804, dtype=torch.float64)
8 gae_duplicate tensor(-0.5284, dtype=torch.float64) tensor(-1.5029, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(0.0735, dtype=torch.float64) delta_t tensor(-0.0881, dtype=torch.float64)
7 gae_duplicate tensor(-0.2707, dtype=torch.float64) tensor(0.7562, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.7198, dtype=torch.float64) delta_t tensor(-1.0430, dtype=torch.float64)
6 gae_duplicate tensor(-1.6284, dtype=torch.float64) tensor(13.1991, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.2286, dtype=torch.float64) delta_t tensor(-1.3837, dtype=torch.float64)
5 gae_duplicate tensor(-2.2345, dtype=torch.float64) tensor(18.0480, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.7347, dtype=torch.float64) delta_t tensor(-1.9490, dtype=torch.float64)
4 gae_duplicate tensor(-2.4182, dtype=torch.float64) tensor(26.9431, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.4770, dtype=torch.float64) delta_t tensor(-1.7401, dtype=torch.float64)
3 gae_duplicate tensor(-2.3810, dtype=torch.float64) tensor(22.2876, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.4604, dtype=torch.float64) delta_t tensor(-1.7186, dtype=torch.float64)
2 gae_duplicate tensor(-2.5154, dtype=torch.float64) tensor(22.0120, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-186.60360717773438
value loss:204.1737060546875
entropies:217.5321502685547
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.719289064407349 seconds
19 rew tensor(0.8406, dtype=torch.float64) delta_t tensor(0.5913, dtype=torch.float64)
19 gae_duplicate tensor(0.4954, dtype=torch.float64) tensor(-6.6854, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8267, dtype=torch.float64) delta_t tensor(0.6298, dtype=torch.float64)
18 gae_duplicate tensor(0.5402, dtype=torch.float64) tensor(-7.9269, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.8021, dtype=torch.float64) delta_t tensor(0.6042, dtype=torch.float64)
17 gae_duplicate tensor(0.3465, dtype=torch.float64) tensor(-8.5176, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.7670, dtype=torch.float64) delta_t tensor(0.5958, dtype=torch.float64)
16 gae_duplicate tensor(0.1208, dtype=torch.float64) tensor(-8.3309, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6690, dtype=torch.float64) delta_t tensor(0.5681, dtype=torch.float64)
15 gae_duplicate tensor(-0.4290, dtype=torch.float64) tensor(-7.3721, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8843, dtype=torch.float64) delta_t tensor(0.7757, dtype=torch.float64)
14 gae_duplicate tensor(0.7562, dtype=torch.float64) tensor(-9.5712, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8927, dtype=torch.float64) delta_t tensor(0.7840, dtype=torch.float64)
13 gae_duplicate tensor(0.8126, dtype=torch.float64) tensor(-11.1130, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9013, dtype=torch.float64) delta_t tensor(0.7910, dtype=torch.float64)
12 gae_duplicate tensor(0.8253, dtype=torch.float64) tensor(-11.3556, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.9103, dtype=torch.float64) delta_t tensor(0.8144, dtype=torch.float64)
11 gae_duplicate tensor(0.8524, dtype=torch.float64) tensor(-10.9360, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.8027, dtype=torch.float64) delta_t tensor(0.6497, dtype=torch.float64)
10 gae_duplicate tensor(0.4644, dtype=torch.float64) tensor(-9.7064, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.5340, dtype=torch.float64) delta_t tensor(0.3831, dtype=torch.float64)
9 gae_duplicate tensor(0.2419, dtype=torch.float64) tensor(-5.2134, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.3145, dtype=torch.float64) delta_t tensor(0.1075, dtype=torch.float64)
8 gae_duplicate tensor(-0.1301, dtype=torch.float64) tensor(-1.7825, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.0736, dtype=torch.float64) delta_t tensor(-0.2335, dtype=torch.float64)
7 gae_duplicate tensor(-0.5579, dtype=torch.float64) tensor(2.9471, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.9805, dtype=torch.float64) delta_t tensor(-1.3230, dtype=torch.float64)
6 gae_duplicate tensor(-1.6600, dtype=torch.float64) tensor(17.6041, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.3378, dtype=torch.float64) delta_t tensor(-1.4990, dtype=torch.float64)
5 gae_duplicate tensor(-2.1757, dtype=torch.float64) tensor(18.7737, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.8876, dtype=torch.float64) delta_t tensor(-2.0548, dtype=torch.float64)
4 gae_duplicate tensor(-2.7179, dtype=torch.float64) tensor(25.6761, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.5897, dtype=torch.float64) delta_t tensor(-1.8626, dtype=torch.float64)
3 gae_duplicate tensor(-2.2683, dtype=torch.float64) tensor(25.4722, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.4171, dtype=torch.float64) delta_t tensor(-1.6684, dtype=torch.float64)
2 gae_duplicate tensor(-2.5082, dtype=torch.float64) tensor(25.7441, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-676.6544799804688
value loss:215.91793823242188
entropies:217.89707946777344
Policy training finished
---------------------
ToM training started
ToM data loaded
batch_size =  600
ToM_loss = tensor(2504.6450)
ToM Target loss= tensor(1800.4232)
optimized based on ToM loss
---------------------
gamma: 0.1
training start after waiting for 4.996913909912109 seconds
19 rew tensor(0.8540, dtype=torch.float64) delta_t tensor(0.6128, dtype=torch.float64)
19 gae_duplicate tensor(0.5419, dtype=torch.float64) tensor(-7.5412, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8602, dtype=torch.float64) delta_t tensor(0.6467, dtype=torch.float64)
18 gae_duplicate tensor(0.6137, dtype=torch.float64) tensor(-8.6262, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.8666, dtype=torch.float64) delta_t tensor(0.5991, dtype=torch.float64)
17 gae_duplicate tensor(0.5049, dtype=torch.float64) tensor(-7.9823, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.8731, dtype=torch.float64) delta_t tensor(0.6797, dtype=torch.float64)
16 gae_duplicate tensor(0.5626, dtype=torch.float64) tensor(-8.5704, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.8797, dtype=torch.float64) delta_t tensor(0.7934, dtype=torch.float64)
15 gae_duplicate tensor(0.8149, dtype=torch.float64) tensor(-10.9956, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8865, dtype=torch.float64) delta_t tensor(0.7836, dtype=torch.float64)
14 gae_duplicate tensor(0.8219, dtype=torch.float64) tensor(-10.5536, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8935, dtype=torch.float64) delta_t tensor(0.7855, dtype=torch.float64)
13 gae_duplicate tensor(0.8290, dtype=torch.float64) tensor(-10.6339, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8238, dtype=torch.float64) delta_t tensor(0.7237, dtype=torch.float64)
12 gae_duplicate tensor(0.4546, dtype=torch.float64) tensor(-10.3724, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8302, dtype=torch.float64) delta_t tensor(0.7301, dtype=torch.float64)
11 gae_duplicate tensor(0.4127, dtype=torch.float64) tensor(-9.3874, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.7511, dtype=torch.float64) delta_t tensor(0.5894, dtype=torch.float64)
10 gae_duplicate tensor(0.2862, dtype=torch.float64) tensor(-7.8263, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.3595, dtype=torch.float64) delta_t tensor(0.1821, dtype=torch.float64)
9 gae_duplicate tensor(0.0025, dtype=torch.float64) tensor(-3.0829, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.2662, dtype=torch.float64) delta_t tensor(0.0466, dtype=torch.float64)
8 gae_duplicate tensor(-0.1839, dtype=torch.float64) tensor(-1.0329, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.1599, dtype=torch.float64) delta_t tensor(-0.3238, dtype=torch.float64)
7 gae_duplicate tensor(-0.7748, dtype=torch.float64) tensor(3.4511, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.8197, dtype=torch.float64) delta_t tensor(-1.1694, dtype=torch.float64)
6 gae_duplicate tensor(-1.9517, dtype=torch.float64) tensor(16.6440, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.1979, dtype=torch.float64) delta_t tensor(-1.3365, dtype=torch.float64)
5 gae_duplicate tensor(-2.0977, dtype=torch.float64) tensor(15.5691, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.7860, dtype=torch.float64) delta_t tensor(-1.9849, dtype=torch.float64)
4 gae_duplicate tensor(-2.4649, dtype=torch.float64) tensor(24.2719, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.6730, dtype=torch.float64) delta_t tensor(-1.9228, dtype=torch.float64)
3 gae_duplicate tensor(-2.4395, dtype=torch.float64) tensor(25.4849, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.2587, dtype=torch.float64) delta_t tensor(-1.5144, dtype=torch.float64)
2 gae_duplicate tensor(-2.1538, dtype=torch.float64) tensor(21.1486, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-398.000732421875
value loss:202.41529846191406
entropies:218.17774963378906
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.255964994430542 seconds
19 rew tensor(0.7916, dtype=torch.float64) delta_t tensor(0.4922, dtype=torch.float64)
19 gae_duplicate tensor(0.3150, dtype=torch.float64) tensor(-6.2724, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.7755, dtype=torch.float64) delta_t tensor(0.4791, dtype=torch.float64)
18 gae_duplicate tensor(0.0315, dtype=torch.float64) tensor(-6.1144, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6788, dtype=torch.float64) delta_t tensor(0.4289, dtype=torch.float64)
17 gae_duplicate tensor(-0.2456, dtype=torch.float64) tensor(-5.9649, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.5326, dtype=torch.float64) delta_t tensor(0.3143, dtype=torch.float64)
16 gae_duplicate tensor(-0.8529, dtype=torch.float64) tensor(-4.4072, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.7577, dtype=torch.float64) delta_t tensor(0.6214, dtype=torch.float64)
15 gae_duplicate tensor(-0.0029, dtype=torch.float64) tensor(-7.7289, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6534, dtype=torch.float64) delta_t tensor(0.5307, dtype=torch.float64)
14 gae_duplicate tensor(-0.5484, dtype=torch.float64) tensor(-7.5111, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8665, dtype=torch.float64) delta_t tensor(0.7415, dtype=torch.float64)
13 gae_duplicate tensor(0.6335, dtype=torch.float64) tensor(-10.2778, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8722, dtype=torch.float64) delta_t tensor(0.7455, dtype=torch.float64)
12 gae_duplicate tensor(0.7567, dtype=torch.float64) tensor(-10.0727, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8780, dtype=torch.float64) delta_t tensor(0.7268, dtype=torch.float64)
11 gae_duplicate tensor(0.6684, dtype=torch.float64) tensor(-10.8056, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.7406, dtype=torch.float64) delta_t tensor(0.5392, dtype=torch.float64)
10 gae_duplicate tensor(0.4397, dtype=torch.float64) tensor(-8.3510, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.2542, dtype=torch.float64) delta_t tensor(-0.4674, dtype=torch.float64)
9 gae_duplicate tensor(-2.1463, dtype=torch.float64) tensor(5.2707, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.0577, dtype=torch.float64) delta_t tensor(-0.2786, dtype=torch.float64)
8 gae_duplicate tensor(-2.1946, dtype=torch.float64) tensor(3.2592, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.1630, dtype=torch.float64) delta_t tensor(-0.3671, dtype=torch.float64)
7 gae_duplicate tensor(-1.2117, dtype=torch.float64) tensor(4.3616, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-1.3276, dtype=torch.float64) delta_t tensor(-1.5880, dtype=torch.float64)
6 gae_duplicate tensor(-2.6178, dtype=torch.float64) tensor(17.6214, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-2.0597, dtype=torch.float64) delta_t tensor(-2.2283, dtype=torch.float64)
5 gae_duplicate tensor(-4.3962, dtype=torch.float64) tensor(29.8666, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.2888, dtype=torch.float64) delta_t tensor(-2.4499, dtype=torch.float64)
4 gae_duplicate tensor(-5.8748, dtype=torch.float64) tensor(31.1252, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.2303, dtype=torch.float64) delta_t tensor(-1.4539, dtype=torch.float64)
3 gae_duplicate tensor(-2.4748, dtype=torch.float64) tensor(24.5901, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.2174, dtype=torch.float64) delta_t tensor(-1.4520, dtype=torch.float64)
2 gae_duplicate tensor(-2.3693, dtype=torch.float64) tensor(21.0699, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-2187.1591796875
value loss:302.5138244628906
entropies:219.14064025878906
Policy training finished
---------------------
gamma: 0.1
Process Process-9:
Traceback (most recent call last):
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/suhuangyuan/DRA/ToM2C/train.py", line 453, in train
    if train_modes[rank] != -10:
  File "<string>", line 2, in __getitem__
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/managers.py", line 809, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/reduction.py", line 41, in __init__
    self.dispatch_table.update(self._extra_reducers)
KeyboardInterrupt