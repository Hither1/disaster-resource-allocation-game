obs <crafter.objects.Shelter object at 0x11ad0c520> [39.  0.  0.  0. 39.  0.  0.  0. 11.  0.  0.  0.]
obs <crafter.objects.Warehouse object at 0x12d8d6850> [39.  0.  0.  0. 41.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Station object at 0x12d8d67f0> [ 9.  0.  0.  0.  9.  0.  0.  0. 13.  0.  0.  0.]
obs <crafter.objects.Shelter object at 0x11ad0c520> [39.  0.  0.  0. 39.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Warehouse object at 0x12d8d6850> [40.  0.  0.  0. 41.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Station object at 0x12d8d67f0> [ 9.  0.  0.  0.  9.  0.  0.  0. 11.  0.  0.  0.]
{'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0}
training start after waiting for 0.003139972686767578 seconds
19 rew tensor(0.6335, dtype=torch.float64) delta_t tensor(0.7485, dtype=torch.float64)
19 gae_duplicate tensor(0.4117, dtype=torch.float64) tensor(-14.7024, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6572, dtype=torch.float64) delta_t tensor(0.7607, dtype=torch.float64)
18 gae_duplicate tensor(0.4725, dtype=torch.float64) tensor(-16.4941, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6840, dtype=torch.float64) delta_t tensor(0.7875, dtype=torch.float64)
17 gae_duplicate tensor(0.4942, dtype=torch.float64) tensor(-17.2294, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.7145, dtype=torch.float64) delta_t tensor(0.8180, dtype=torch.float64)
16 gae_duplicate tensor(0.5137, dtype=torch.float64) tensor(-17.8438, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.7497, dtype=torch.float64) delta_t tensor(0.8532, dtype=torch.float64)
15 gae_duplicate tensor(0.5351, dtype=torch.float64) tensor(-18.6696, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.7909, dtype=torch.float64) delta_t tensor(0.8944, dtype=torch.float64)
14 gae_duplicate tensor(0.5590, dtype=torch.float64) tensor(-19.3272, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8404, dtype=torch.float64) delta_t tensor(0.9440, dtype=torch.float64)
13 gae_duplicate tensor(0.5861, dtype=torch.float64) tensor(-20.3382, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9015, dtype=torch.float64) delta_t tensor(1.0050, dtype=torch.float64)
12 gae_duplicate tensor(0.6173, dtype=torch.float64) tensor(-21.9505, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.9801, dtype=torch.float64) delta_t tensor(0.8478, dtype=torch.float64)
11 gae_duplicate tensor(0.6148, dtype=torch.float64) tensor(-18.9116, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(1.0878, dtype=torch.float64) delta_t tensor(1.0894, dtype=torch.float64)
10 gae_duplicate tensor(0.6918, dtype=torch.float64) tensor(-23.3070, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.0802, dtype=torch.float64) delta_t tensor(-0.0877, dtype=torch.float64)
9 gae_duplicate tensor(-0.4151, dtype=torch.float64) tensor(-0.6646, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.0808, dtype=torch.float64) delta_t tensor(0.0738, dtype=torch.float64)
8 gae_duplicate tensor(-0.4838, dtype=torch.float64) tensor(-1.5646, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.3375, dtype=torch.float64) delta_t tensor(-0.3376, dtype=torch.float64)
7 gae_duplicate tensor(-1.7679, dtype=torch.float64) tensor(6.4482, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.2028, dtype=torch.float64) delta_t tensor(-0.1550, dtype=torch.float64)
6 gae_duplicate tensor(-1.4111, dtype=torch.float64) tensor(3.8114, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.2462, dtype=torch.float64) delta_t tensor(-0.1833, dtype=torch.float64)
5 gae_duplicate tensor(-2.0896, dtype=torch.float64) tensor(3.9040, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.6253, dtype=torch.float64) delta_t tensor(-1.5940, dtype=torch.float64)
4 gae_duplicate tensor(-1.7578, dtype=torch.float64) tensor(31.9409, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.8141, dtype=torch.float64) delta_t tensor(0.8167, dtype=torch.float64)
3 gae_duplicate tensor(0.3284, dtype=torch.float64) tensor(-12.8820, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.5774, dtype=torch.float64) delta_t tensor(0.6145, dtype=torch.float64)
2 gae_duplicate tensor(0.5862, dtype=torch.float64) tensor(-13.3476, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:9144.853515625
value loss:143.234619140625
entropies:355.7957458496094
Policy training finished
---------------------
gamma: 0.1
/Users/suhuangyuan/DRA/ToM2C/shared_optim.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1420.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
training start after waiting for 4.994507074356079 seconds
19 rew tensor(0.6501, dtype=torch.float64) delta_t tensor(0.7419, dtype=torch.float64)
19 gae_duplicate tensor(0.5316, dtype=torch.float64) tensor(-14.6396, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6621, dtype=torch.float64) delta_t tensor(0.7447, dtype=torch.float64)
18 gae_duplicate tensor(0.6065, dtype=torch.float64) tensor(-16.3489, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6748, dtype=torch.float64) delta_t tensor(0.7573, dtype=torch.float64)
17 gae_duplicate tensor(0.6260, dtype=torch.float64) tensor(-16.3604, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6882, dtype=torch.float64) delta_t tensor(0.7708, dtype=torch.float64)
16 gae_duplicate tensor(0.6406, dtype=torch.float64) tensor(-16.9941, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.7025, dtype=torch.float64) delta_t tensor(0.7850, dtype=torch.float64)
15 gae_duplicate tensor(0.6555, dtype=torch.float64) tensor(-17.0694, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.7177, dtype=torch.float64) delta_t tensor(0.8003, dtype=torch.float64)
14 gae_duplicate tensor(0.6712, dtype=torch.float64) tensor(-17.7927, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.7340, dtype=torch.float64) delta_t tensor(0.8166, dtype=torch.float64)
13 gae_duplicate tensor(0.6880, dtype=torch.float64) tensor(-18.3584, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.7515, dtype=torch.float64) delta_t tensor(0.8341, dtype=torch.float64)
12 gae_duplicate tensor(0.7060, dtype=torch.float64) tensor(-18.5036, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.7703, dtype=torch.float64) delta_t tensor(0.5577, dtype=torch.float64)
11 gae_duplicate tensor(0.4796, dtype=torch.float64) tensor(-13.1086, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.7907, dtype=torch.float64) delta_t tensor(0.7866, dtype=torch.float64)
10 gae_duplicate tensor(0.6770, dtype=torch.float64) tensor(-16.8560, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.4983, dtype=torch.float64) delta_t tensor(-0.5178, dtype=torch.float64)
9 gae_duplicate tensor(-0.8662, dtype=torch.float64) tensor(8.7686, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-1.1001, dtype=torch.float64) delta_t tensor(-1.1190, dtype=torch.float64)
8 gae_duplicate tensor(-2.9828, dtype=torch.float64) tensor(22.4827, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.4805, dtype=torch.float64) delta_t tensor(-0.4990, dtype=torch.float64)
7 gae_duplicate tensor(-1.5943, dtype=torch.float64) tensor(11.9225, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.6895, dtype=torch.float64) delta_t tensor(-0.6828, dtype=torch.float64)
6 gae_duplicate tensor(-1.5826, dtype=torch.float64) tensor(14.8792, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.5748, dtype=torch.float64) delta_t tensor(-0.5366, dtype=torch.float64)
5 gae_duplicate tensor(-0.9158, dtype=torch.float64) tensor(12.1572, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-0.5625, dtype=torch.float64) delta_t tensor(-0.5917, dtype=torch.float64)
4 gae_duplicate tensor(-2.9615, dtype=torch.float64) tensor(13.1495, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.2886, dtype=torch.float64) delta_t tensor(0.2260, dtype=torch.float64)
3 gae_duplicate tensor(-0.1291, dtype=torch.float64) tensor(-3.3073, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.0909, dtype=torch.float64) delta_t tensor(-0.1022, dtype=torch.float64)
2 gae_duplicate tensor(-0.4719, dtype=torch.float64) tensor(1.6533, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:4457.63427734375
value loss:134.16871643066406
entropies:355.4194030761719
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.1656248569488525 seconds
19 rew tensor(0.6653, dtype=torch.float64) delta_t tensor(0.6805, dtype=torch.float64)
19 gae_duplicate tensor(0.4036, dtype=torch.float64) tensor(-13.3394, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6735, dtype=torch.float64) delta_t tensor(0.6873, dtype=torch.float64)
18 gae_duplicate tensor(0.4601, dtype=torch.float64) tensor(-15.2304, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6821, dtype=torch.float64) delta_t tensor(0.6958, dtype=torch.float64)
17 gae_duplicate tensor(0.4713, dtype=torch.float64) tensor(-15.1419, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6910, dtype=torch.float64) delta_t tensor(0.7047, dtype=torch.float64)
16 gae_duplicate tensor(0.4782, dtype=torch.float64) tensor(-15.4598, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.7002, dtype=torch.float64) delta_t tensor(0.7139, dtype=torch.float64)
15 gae_duplicate tensor(0.4848, dtype=torch.float64) tensor(-15.6626, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.7098, dtype=torch.float64) delta_t tensor(0.7236, dtype=torch.float64)
14 gae_duplicate tensor(0.4917, dtype=torch.float64) tensor(-15.9000, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.7199, dtype=torch.float64) delta_t tensor(0.7336, dtype=torch.float64)
13 gae_duplicate tensor(0.4987, dtype=torch.float64) tensor(-15.7830, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.7304, dtype=torch.float64) delta_t tensor(0.7441, dtype=torch.float64)
12 gae_duplicate tensor(0.5060, dtype=torch.float64) tensor(-16.3960, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.7413, dtype=torch.float64) delta_t tensor(0.5205, dtype=torch.float64)
11 gae_duplicate tensor(0.4623, dtype=torch.float64) tensor(-12.0051, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.7528, dtype=torch.float64) delta_t tensor(0.6676, dtype=torch.float64)
10 gae_duplicate tensor(0.4835, dtype=torch.float64) tensor(-14.2782, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.6907, dtype=torch.float64) delta_t tensor(-0.7854, dtype=torch.float64)
9 gae_duplicate tensor(-1.0728, dtype=torch.float64) tensor(14.5551, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.8444, dtype=torch.float64) delta_t tensor(-0.9397, dtype=torch.float64)
8 gae_duplicate tensor(-2.0766, dtype=torch.float64) tensor(20.4870, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.6294, dtype=torch.float64) delta_t tensor(-0.7212, dtype=torch.float64)
7 gae_duplicate tensor(-1.3720, dtype=torch.float64) tensor(16.1659, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.6337, dtype=torch.float64) delta_t tensor(-0.6732, dtype=torch.float64)
6 gae_duplicate tensor(-1.3284, dtype=torch.float64) tensor(14.9588, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.2525, dtype=torch.float64) delta_t tensor(-1.2596, dtype=torch.float64)
5 gae_duplicate tensor(-2.0821, dtype=torch.float64) tensor(26.6085, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.8631, dtype=torch.float64) delta_t tensor(-2.9254, dtype=torch.float64)
4 gae_duplicate tensor(-4.4573, dtype=torch.float64) tensor(59.7587, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.1161, dtype=torch.float64) delta_t tensor(0.0345, dtype=torch.float64)
3 gae_duplicate tensor(-0.6364, dtype=torch.float64) tensor(5.3093, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.0278, dtype=torch.float64) delta_t tensor(-0.0831, dtype=torch.float64)
2 gae_duplicate tensor(-0.4727, dtype=torch.float64) tensor(2.2441, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-684.078369140625
value loss:195.59523010253906
entropies:355.4527587890625
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.1684489250183105 seconds
19 rew tensor(0.6521, dtype=torch.float64) delta_t tensor(0.5590, dtype=torch.float64)
19 gae_duplicate tensor(0.4201, dtype=torch.float64) tensor(-11.1260, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6580, dtype=torch.float64) delta_t tensor(0.5742, dtype=torch.float64)
18 gae_duplicate tensor(0.4788, dtype=torch.float64) tensor(-12.5058, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6640, dtype=torch.float64) delta_t tensor(0.5803, dtype=torch.float64)
17 gae_duplicate tensor(0.4892, dtype=torch.float64) tensor(-12.8787, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6703, dtype=torch.float64) delta_t tensor(0.5865, dtype=torch.float64)
16 gae_duplicate tensor(0.4949, dtype=torch.float64) tensor(-13.1741, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6767, dtype=torch.float64) delta_t tensor(0.5929, dtype=torch.float64)
15 gae_duplicate tensor(0.5003, dtype=torch.float64) tensor(-12.9713, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6833, dtype=torch.float64) delta_t tensor(0.5995, dtype=torch.float64)
14 gae_duplicate tensor(0.5057, dtype=torch.float64) tensor(-13.2385, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6901, dtype=torch.float64) delta_t tensor(0.6064, dtype=torch.float64)
13 gae_duplicate tensor(0.5113, dtype=torch.float64) tensor(-13.3465, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6972, dtype=torch.float64) delta_t tensor(0.6134, dtype=torch.float64)
12 gae_duplicate tensor(0.5170, dtype=torch.float64) tensor(-13.4864, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.7044, dtype=torch.float64) delta_t tensor(0.5001, dtype=torch.float64)
11 gae_duplicate tensor(0.4984, dtype=torch.float64) tensor(-11.4129, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.7119, dtype=torch.float64) delta_t tensor(0.5878, dtype=torch.float64)
10 gae_duplicate tensor(0.4498, dtype=torch.float64) tensor(-12.7703, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.4433, dtype=torch.float64) delta_t tensor(-0.5703, dtype=torch.float64)
9 gae_duplicate tensor(-1.0685, dtype=torch.float64) tensor(9.8554, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-1.1431, dtype=torch.float64) delta_t tensor(-1.2703, dtype=torch.float64)
8 gae_duplicate tensor(-3.6472, dtype=torch.float64) tensor(25.8610, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.6654, dtype=torch.float64) delta_t tensor(-0.7849, dtype=torch.float64)
7 gae_duplicate tensor(-1.5523, dtype=torch.float64) tensor(18.1523, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.4176, dtype=torch.float64) delta_t tensor(-0.4523, dtype=torch.float64)
6 gae_duplicate tensor(-1.3583, dtype=torch.float64) tensor(10.6004, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7178, dtype=torch.float64) delta_t tensor(-0.6994, dtype=torch.float64)
5 gae_duplicate tensor(-1.4277, dtype=torch.float64) tensor(15.3297, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.4525, dtype=torch.float64) delta_t tensor(-2.4824, dtype=torch.float64)
4 gae_duplicate tensor(-5.6632, dtype=torch.float64) tensor(50.2078, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.0879, dtype=torch.float64) delta_t tensor(0.0282, dtype=torch.float64)
3 gae_duplicate tensor(-0.5002, dtype=torch.float64) tensor(4.3969, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.0445, dtype=torch.float64) delta_t tensor(-0.0945, dtype=torch.float64)
2 gae_duplicate tensor(-0.4400, dtype=torch.float64) tensor(2.2559, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-622.3673095703125
value loss:183.44313049316406
entropies:355.2904052734375
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.9091198444366455 seconds
19 rew tensor(0.6461, dtype=torch.float64) delta_t tensor(0.4655, dtype=torch.float64)
19 gae_duplicate tensor(0.3649, dtype=torch.float64) tensor(-9.2139, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6507, dtype=torch.float64) delta_t tensor(0.4883, dtype=torch.float64)
18 gae_duplicate tensor(0.4259, dtype=torch.float64) tensor(-10.5306, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6555, dtype=torch.float64) delta_t tensor(0.4930, dtype=torch.float64)
17 gae_duplicate tensor(0.4358, dtype=torch.float64) tensor(-10.8963, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6604, dtype=torch.float64) delta_t tensor(0.4979, dtype=torch.float64)
16 gae_duplicate tensor(0.4408, dtype=torch.float64) tensor(-10.7641, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6653, dtype=torch.float64) delta_t tensor(0.5029, dtype=torch.float64)
15 gae_duplicate tensor(0.4454, dtype=torch.float64) tensor(-11.3561, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6704, dtype=torch.float64) delta_t tensor(0.5080, dtype=torch.float64)
14 gae_duplicate tensor(0.4500, dtype=torch.float64) tensor(-11.1990, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6756, dtype=torch.float64) delta_t tensor(0.5132, dtype=torch.float64)
13 gae_duplicate tensor(0.4546, dtype=torch.float64) tensor(-11.0488, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6810, dtype=torch.float64) delta_t tensor(0.5185, dtype=torch.float64)
12 gae_duplicate tensor(0.4594, dtype=torch.float64) tensor(-11.1906, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6864, dtype=torch.float64) delta_t tensor(0.5134, dtype=torch.float64)
11 gae_duplicate tensor(0.4499, dtype=torch.float64) tensor(-11.3335, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6920, dtype=torch.float64) delta_t tensor(0.5455, dtype=torch.float64)
10 gae_duplicate tensor(0.4767, dtype=torch.float64) tensor(-11.8101, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.7942, dtype=torch.float64) delta_t tensor(-0.9361, dtype=torch.float64)
9 gae_duplicate tensor(-1.0943, dtype=torch.float64) tensor(17.2310, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.8023, dtype=torch.float64) delta_t tensor(-0.9471, dtype=torch.float64)
8 gae_duplicate tensor(-1.2724, dtype=torch.float64) tensor(20.3835, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.8767, dtype=torch.float64) delta_t tensor(-1.0149, dtype=torch.float64)
7 gae_duplicate tensor(-2.2026, dtype=torch.float64) tensor(22.0868, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.6901, dtype=torch.float64) delta_t tensor(-0.7513, dtype=torch.float64)
6 gae_duplicate tensor(-1.4636, dtype=torch.float64) tensor(17.1865, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7412, dtype=torch.float64) delta_t tensor(-0.7463, dtype=torch.float64)
5 gae_duplicate tensor(-1.4372, dtype=torch.float64) tensor(16.7109, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-3.6285, dtype=torch.float64) delta_t tensor(-3.6057, dtype=torch.float64)
4 gae_duplicate tensor(-4.8827, dtype=torch.float64) tensor(72.0126, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.1488, dtype=torch.float64) delta_t tensor(0.1122, dtype=torch.float64)
3 gae_duplicate tensor(-0.6005, dtype=torch.float64) tensor(5.1355, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0704, dtype=torch.float64) delta_t tensor(0.0392, dtype=torch.float64)
2 gae_duplicate tensor(-0.3170, dtype=torch.float64) tensor(-0.2171, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-3400.020751953125
value loss:211.3487091064453
entropies:355.2886047363281
Policy training finished
---------------------
ToM training started
ToM data loaded
batch_size =  600
ToM_loss = tensor(3972.8496)
ToM Target loss= tensor(3299.0149)
optimized based on ToM loss
---------------------
gamma: 0.1
training start after waiting for 5.466007709503174 seconds
19 rew tensor(0.6481, dtype=torch.float64) delta_t tensor(0.5443, dtype=torch.float64)
19 gae_duplicate tensor(0.4417, dtype=torch.float64) tensor(-10.6241, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6520, dtype=torch.float64) delta_t tensor(0.5586, dtype=torch.float64)
18 gae_duplicate tensor(0.5060, dtype=torch.float64) tensor(-12.0291, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6560, dtype=torch.float64) delta_t tensor(0.5625, dtype=torch.float64)
17 gae_duplicate tensor(0.5160, dtype=torch.float64) tensor(-12.4267, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6600, dtype=torch.float64) delta_t tensor(0.5665, dtype=torch.float64)
16 gae_duplicate tensor(0.5206, dtype=torch.float64) tensor(-12.3980, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6641, dtype=torch.float64) delta_t tensor(0.5707, dtype=torch.float64)
15 gae_duplicate tensor(0.5248, dtype=torch.float64) tensor(-12.2473, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6683, dtype=torch.float64) delta_t tensor(0.5748, dtype=torch.float64)
14 gae_duplicate tensor(0.5289, dtype=torch.float64) tensor(-12.7608, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6725, dtype=torch.float64) delta_t tensor(0.5791, dtype=torch.float64)
13 gae_duplicate tensor(0.5331, dtype=torch.float64) tensor(-12.7660, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6769, dtype=torch.float64) delta_t tensor(0.5834, dtype=torch.float64)
12 gae_duplicate tensor(0.5375, dtype=torch.float64) tensor(-13.0793, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6813, dtype=torch.float64) delta_t tensor(0.6212, dtype=torch.float64)
11 gae_duplicate tensor(0.5840, dtype=torch.float64) tensor(-13.4257, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6858, dtype=torch.float64) delta_t tensor(0.6522, dtype=torch.float64)
10 gae_duplicate tensor(0.5876, dtype=torch.float64) tensor(-14.2450, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.7727, dtype=torch.float64) delta_t tensor(-0.7990, dtype=torch.float64)
9 gae_duplicate tensor(-1.6587, dtype=torch.float64) tensor(14.4723, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.4583, dtype=torch.float64) delta_t tensor(-0.5067, dtype=torch.float64)
8 gae_duplicate tensor(-1.1359, dtype=torch.float64) tensor(11.3987, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.7401, dtype=torch.float64) delta_t tensor(-0.7871, dtype=torch.float64)
7 gae_duplicate tensor(-1.1322, dtype=torch.float64) tensor(16.7029, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.6839, dtype=torch.float64) delta_t tensor(-0.6867, dtype=torch.float64)
6 gae_duplicate tensor(-1.0987, dtype=torch.float64) tensor(15.0805, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.9449, dtype=torch.float64) delta_t tensor(-0.8207, dtype=torch.float64)
5 gae_duplicate tensor(-1.9217, dtype=torch.float64) tensor(17.7757, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.9187, dtype=torch.float64) delta_t tensor(-1.7051, dtype=torch.float64)
4 gae_duplicate tensor(-5.0028, dtype=torch.float64) tensor(35.1593, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.2253, dtype=torch.float64) delta_t tensor(0.3256, dtype=torch.float64)
3 gae_duplicate tensor(-0.1836, dtype=torch.float64) tensor(-2.8452, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.0199, dtype=torch.float64) delta_t tensor(0.0445, dtype=torch.float64)
2 gae_duplicate tensor(-0.2386, dtype=torch.float64) tensor(-1.1094, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:949.8651733398438
value loss:131.70501708984375
entropies:355.4050598144531
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.938952922821045 seconds
19 rew tensor(0.6502, dtype=torch.float64) delta_t tensor(0.5234, dtype=torch.float64)
19 gae_duplicate tensor(0.3984, dtype=torch.float64) tensor(-10.4777, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6535, dtype=torch.float64) delta_t tensor(0.5394, dtype=torch.float64)
18 gae_duplicate tensor(0.4683, dtype=torch.float64) tensor(-11.6905, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6569, dtype=torch.float64) delta_t tensor(0.5428, dtype=torch.float64)
17 gae_duplicate tensor(0.4788, dtype=torch.float64) tensor(-11.8182, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6603, dtype=torch.float64) delta_t tensor(0.5463, dtype=torch.float64)
16 gae_duplicate tensor(0.4834, dtype=torch.float64) tensor(-11.8730, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6638, dtype=torch.float64) delta_t tensor(0.5498, dtype=torch.float64)
15 gae_duplicate tensor(0.4874, dtype=torch.float64) tensor(-11.8107, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6674, dtype=torch.float64) delta_t tensor(0.5533, dtype=torch.float64)
14 gae_duplicate tensor(0.4915, dtype=torch.float64) tensor(-12.0150, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6710, dtype=torch.float64) delta_t tensor(0.5569, dtype=torch.float64)
13 gae_duplicate tensor(0.4956, dtype=torch.float64) tensor(-12.1912, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6747, dtype=torch.float64) delta_t tensor(0.5606, dtype=torch.float64)
12 gae_duplicate tensor(0.4998, dtype=torch.float64) tensor(-12.3192, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6784, dtype=torch.float64) delta_t tensor(0.6986, dtype=torch.float64)
11 gae_duplicate tensor(0.7201, dtype=torch.float64) tensor(-15.0549, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6822, dtype=torch.float64) delta_t tensor(0.7365, dtype=torch.float64)
10 gae_duplicate tensor(0.7316, dtype=torch.float64) tensor(-16.2595, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.8691, dtype=torch.float64) delta_t tensor(-0.8104, dtype=torch.float64)
9 gae_duplicate tensor(-1.4309, dtype=torch.float64) tensor(14.5063, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.6106, dtype=torch.float64) delta_t tensor(-0.5876, dtype=torch.float64)
8 gae_duplicate tensor(-1.8405, dtype=torch.float64) tensor(12.7929, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.8544, dtype=torch.float64) delta_t tensor(-0.8388, dtype=torch.float64)
7 gae_duplicate tensor(-1.7902, dtype=torch.float64) tensor(18.2837, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.5460, dtype=torch.float64) delta_t tensor(-0.4797, dtype=torch.float64)
6 gae_duplicate tensor(-1.8653, dtype=torch.float64) tensor(11.0673, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7072, dtype=torch.float64) delta_t tensor(-0.3093, dtype=torch.float64)
5 gae_duplicate tensor(-1.1251, dtype=torch.float64) tensor(7.2969, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.1240, dtype=torch.float64) delta_t tensor(-1.8485, dtype=torch.float64)
4 gae_duplicate tensor(-5.1028, dtype=torch.float64) tensor(36.8338, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.2180, dtype=torch.float64) delta_t tensor(0.4339, dtype=torch.float64)
3 gae_duplicate tensor(-0.3777, dtype=torch.float64) tensor(-4.8919, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.0787, dtype=torch.float64) delta_t tensor(0.0901, dtype=torch.float64)
2 gae_duplicate tensor(-0.0887, dtype=torch.float64) tensor(-2.2472, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:1624.8843994140625
value loss:135.9894256591797
entropies:355.53631591796875
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.812767028808594 seconds
19 rew tensor(0.6544, dtype=torch.float64) delta_t tensor(0.3564, dtype=torch.float64)
19 gae_duplicate tensor(0.1928, dtype=torch.float64) tensor(-7.0198, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6573, dtype=torch.float64) delta_t tensor(0.3891, dtype=torch.float64)
18 gae_duplicate tensor(0.2549, dtype=torch.float64) tensor(-8.3393, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6603, dtype=torch.float64) delta_t tensor(0.3921, dtype=torch.float64)
17 gae_duplicate tensor(0.2637, dtype=torch.float64) tensor(-8.6032, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6633, dtype=torch.float64) delta_t tensor(0.3951, dtype=torch.float64)
16 gae_duplicate tensor(0.2671, dtype=torch.float64) tensor(-8.7433, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6664, dtype=torch.float64) delta_t tensor(0.3982, dtype=torch.float64)
15 gae_duplicate tensor(0.2701, dtype=torch.float64) tensor(-8.6576, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6695, dtype=torch.float64) delta_t tensor(0.4013, dtype=torch.float64)
14 gae_duplicate tensor(0.2731, dtype=torch.float64) tensor(-8.7855, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6727, dtype=torch.float64) delta_t tensor(0.4045, dtype=torch.float64)
13 gae_duplicate tensor(0.2761, dtype=torch.float64) tensor(-8.7808, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6759, dtype=torch.float64) delta_t tensor(0.4077, dtype=torch.float64)
12 gae_duplicate tensor(0.2791, dtype=torch.float64) tensor(-8.8620, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6791, dtype=torch.float64) delta_t tensor(0.8037, dtype=torch.float64)
11 gae_duplicate tensor(0.8037, dtype=torch.float64) tensor(-16.9602, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6824, dtype=torch.float64) delta_t tensor(0.6773, dtype=torch.float64)
10 gae_duplicate tensor(0.6391, dtype=torch.float64) tensor(-14.9771, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.2182, dtype=torch.float64) delta_t tensor(-0.2103, dtype=torch.float64)
9 gae_duplicate tensor(-0.7853, dtype=torch.float64) tensor(2.4494, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.6718, dtype=torch.float64) delta_t tensor(-0.6662, dtype=torch.float64)
8 gae_duplicate tensor(-1.2212, dtype=torch.float64) tensor(13.5674, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.9752, dtype=torch.float64) delta_t tensor(-0.9644, dtype=torch.float64)
7 gae_duplicate tensor(-2.5067, dtype=torch.float64) tensor(20.3053, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.8409, dtype=torch.float64) delta_t tensor(-0.7272, dtype=torch.float64)
6 gae_duplicate tensor(-1.5061, dtype=torch.float64) tensor(16.6069, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.8635, dtype=torch.float64) delta_t tensor(-0.4503, dtype=torch.float64)
5 gae_duplicate tensor(-1.8047, dtype=torch.float64) tensor(10.5707, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.2719, dtype=torch.float64) delta_t tensor(-1.8091, dtype=torch.float64)
4 gae_duplicate tensor(-3.2136, dtype=torch.float64) tensor(37.2356, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.0839, dtype=torch.float64) delta_t tensor(0.3416, dtype=torch.float64)
3 gae_duplicate tensor(-0.1150, dtype=torch.float64) tensor(-3.0568, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0176, dtype=torch.float64) delta_t tensor(0.2275, dtype=torch.float64)
2 gae_duplicate tensor(0.0063, dtype=torch.float64) tensor(-4.7487, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:271.1119384765625
value loss:116.20684814453125
entropies:355.6903991699219
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.15768027305603 seconds
19 rew tensor(0.6502, dtype=torch.float64) delta_t tensor(0.4227, dtype=torch.float64)
19 gae_duplicate tensor(0.1802, dtype=torch.float64) tensor(-8.3645, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6528, dtype=torch.float64) delta_t tensor(0.4480, dtype=torch.float64)
18 gae_duplicate tensor(0.2458, dtype=torch.float64) tensor(-9.7786, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6554, dtype=torch.float64) delta_t tensor(0.4507, dtype=torch.float64)
17 gae_duplicate tensor(0.2549, dtype=torch.float64) tensor(-9.9319, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6581, dtype=torch.float64) delta_t tensor(0.4533, dtype=torch.float64)
16 gae_duplicate tensor(0.2583, dtype=torch.float64) tensor(-9.8869, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6608, dtype=torch.float64) delta_t tensor(0.4560, dtype=torch.float64)
15 gae_duplicate tensor(0.2612, dtype=torch.float64) tensor(-9.8384, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6635, dtype=torch.float64) delta_t tensor(0.4587, dtype=torch.float64)
14 gae_duplicate tensor(0.2641, dtype=torch.float64) tensor(-9.8973, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6663, dtype=torch.float64) delta_t tensor(0.4615, dtype=torch.float64)
13 gae_duplicate tensor(0.2670, dtype=torch.float64) tensor(-10.2504, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6691, dtype=torch.float64) delta_t tensor(0.4643, dtype=torch.float64)
12 gae_duplicate tensor(0.2700, dtype=torch.float64) tensor(-10.2509, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6719, dtype=torch.float64) delta_t tensor(0.7571, dtype=torch.float64)
11 gae_duplicate tensor(0.5471, dtype=torch.float64) tensor(-15.9911, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6747, dtype=torch.float64) delta_t tensor(0.7239, dtype=torch.float64)
10 gae_duplicate tensor(0.6612, dtype=torch.float64) tensor(-16.2097, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.4743, dtype=torch.float64) delta_t tensor(-0.3925, dtype=torch.float64)
9 gae_duplicate tensor(-0.6222, dtype=torch.float64) tensor(6.2409, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.6911, dtype=torch.float64) delta_t tensor(-0.6375, dtype=torch.float64)
8 gae_duplicate tensor(-1.2915, dtype=torch.float64) tensor(13.3484, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.5351, dtype=torch.float64) delta_t tensor(-0.4697, dtype=torch.float64)
7 gae_duplicate tensor(-1.2049, dtype=torch.float64) tensor(10.4067, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.7239, dtype=torch.float64) delta_t tensor(-0.5847, dtype=torch.float64)
6 gae_duplicate tensor(-0.9695, dtype=torch.float64) tensor(12.6456, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7524, dtype=torch.float64) delta_t tensor(-0.4332, dtype=torch.float64)
5 gae_duplicate tensor(-0.8170, dtype=torch.float64) tensor(9.6501, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.3455, dtype=torch.float64) delta_t tensor(-1.9036, dtype=torch.float64)
4 gae_duplicate tensor(-5.9360, dtype=torch.float64) tensor(37.9249, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.2814, dtype=torch.float64) delta_t tensor(0.6211, dtype=torch.float64)
3 gae_duplicate tensor(-0.0741, dtype=torch.float64) tensor(-8.5091, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0514, dtype=torch.float64) delta_t tensor(0.3132, dtype=torch.float64)
2 gae_duplicate tensor(-0.0134, dtype=torch.float64) tensor(-7.1708, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:1840.560302734375
value loss:140.66209411621094
entropies:355.68780517578125
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.053309917449951 seconds
19 rew tensor(0.6499, dtype=torch.float64) delta_t tensor(0.2605, dtype=torch.float64)
19 gae_duplicate tensor(0.0739, dtype=torch.float64) tensor(-5.1965, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6522, dtype=torch.float64) delta_t tensor(0.3017, dtype=torch.float64)
18 gae_duplicate tensor(0.1390, dtype=torch.float64) tensor(-6.4388, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6546, dtype=torch.float64) delta_t tensor(0.3041, dtype=torch.float64)
17 gae_duplicate tensor(0.1477, dtype=torch.float64) tensor(-6.6243, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6570, dtype=torch.float64) delta_t tensor(0.3065, dtype=torch.float64)
16 gae_duplicate tensor(0.1509, dtype=torch.float64) tensor(-6.7446, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6594, dtype=torch.float64) delta_t tensor(0.3089, dtype=torch.float64)
15 gae_duplicate tensor(0.1534, dtype=torch.float64) tensor(-6.8173, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6618, dtype=torch.float64) delta_t tensor(0.3113, dtype=torch.float64)
14 gae_duplicate tensor(0.1560, dtype=torch.float64) tensor(-6.9168, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6643, dtype=torch.float64) delta_t tensor(0.3138, dtype=torch.float64)
13 gae_duplicate tensor(0.1586, dtype=torch.float64) tensor(-6.7837, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6668, dtype=torch.float64) delta_t tensor(0.3162, dtype=torch.float64)
12 gae_duplicate tensor(0.1612, dtype=torch.float64) tensor(-6.9801, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6693, dtype=torch.float64) delta_t tensor(0.8073, dtype=torch.float64)
11 gae_duplicate tensor(0.6269, dtype=torch.float64) tensor(-16.6502, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6718, dtype=torch.float64) delta_t tensor(0.7118, dtype=torch.float64)
10 gae_duplicate tensor(0.7306, dtype=torch.float64) tensor(-15.7446, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.7817, dtype=torch.float64) delta_t tensor(-0.7211, dtype=torch.float64)
9 gae_duplicate tensor(-1.0027, dtype=torch.float64) tensor(12.7257, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.6868, dtype=torch.float64) delta_t tensor(-0.6327, dtype=torch.float64)
8 gae_duplicate tensor(-0.8793, dtype=torch.float64) tensor(13.9835, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.8863, dtype=torch.float64) delta_t tensor(-0.8196, dtype=torch.float64)
7 gae_duplicate tensor(-1.7596, dtype=torch.float64) tensor(17.3275, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.8754, dtype=torch.float64) delta_t tensor(-0.6819, dtype=torch.float64)
6 gae_duplicate tensor(-1.5478, dtype=torch.float64) tensor(15.1727, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.8986, dtype=torch.float64) delta_t tensor(-0.4957, dtype=torch.float64)
5 gae_duplicate tensor(-1.1626, dtype=torch.float64) tensor(11.2949, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.7768, dtype=torch.float64) delta_t tensor(-2.1619, dtype=torch.float64)
4 gae_duplicate tensor(-5.0507, dtype=torch.float64) tensor(43.3069, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.1735, dtype=torch.float64) delta_t tensor(0.5056, dtype=torch.float64)
3 gae_duplicate tensor(-0.0834, dtype=torch.float64) tensor(-5.6776, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0672, dtype=torch.float64) delta_t tensor(0.4375, dtype=torch.float64)
2 gae_duplicate tensor(0.2509, dtype=torch.float64) tensor(-9.3349, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-846.7557983398438
value loss:136.97218322753906
entropies:355.78668212890625
Policy training finished
---------------------
ToM training started
ToM data loaded
batch_size =  600
ToM_loss = tensor(3958.2078)
ToM Target loss= tensor(3305.4104)
optimized based on ToM loss
---------------------
gamma: 0.1
training start after waiting for 4.9308788776397705 seconds
19 rew tensor(0.6442, dtype=torch.float64) delta_t tensor(0.2857, dtype=torch.float64)
19 gae_duplicate tensor(-0.0078, dtype=torch.float64) tensor(-5.6263, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6463, dtype=torch.float64) delta_t tensor(0.3236, dtype=torch.float64)
18 gae_duplicate tensor(0.0557, dtype=torch.float64) tensor(-6.9793, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6484, dtype=torch.float64) delta_t tensor(0.3257, dtype=torch.float64)
17 gae_duplicate tensor(0.0640, dtype=torch.float64) tensor(-7.1236, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6505, dtype=torch.float64) delta_t tensor(0.3279, dtype=torch.float64)
16 gae_duplicate tensor(0.0668, dtype=torch.float64) tensor(-7.2384, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6527, dtype=torch.float64) delta_t tensor(0.3300, dtype=torch.float64)
15 gae_duplicate tensor(0.0691, dtype=torch.float64) tensor(-7.1891, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6548, dtype=torch.float64) delta_t tensor(0.3322, dtype=torch.float64)
14 gae_duplicate tensor(0.0713, dtype=torch.float64) tensor(-7.2881, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6570, dtype=torch.float64) delta_t tensor(0.3344, dtype=torch.float64)
13 gae_duplicate tensor(0.0736, dtype=torch.float64) tensor(-7.3957, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6592, dtype=torch.float64) delta_t tensor(0.3366, dtype=torch.float64)
12 gae_duplicate tensor(0.0758, dtype=torch.float64) tensor(-7.4277, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6615, dtype=torch.float64) delta_t tensor(0.8143, dtype=torch.float64)
11 gae_duplicate tensor(0.5791, dtype=torch.float64) tensor(-16.7261, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6637, dtype=torch.float64) delta_t tensor(0.7197, dtype=torch.float64)
10 gae_duplicate tensor(0.7273, dtype=torch.float64) tensor(-15.8697, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.6689, dtype=torch.float64) delta_t tensor(-0.6003, dtype=torch.float64)
9 gae_duplicate tensor(-1.0462, dtype=torch.float64) tensor(10.3802, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.5802, dtype=torch.float64) delta_t tensor(-0.5164, dtype=torch.float64)
8 gae_duplicate tensor(-0.9216, dtype=torch.float64) tensor(11.2693, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.9131, dtype=torch.float64) delta_t tensor(-0.8480, dtype=torch.float64)
7 gae_duplicate tensor(-1.7592, dtype=torch.float64) tensor(17.7443, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.7164, dtype=torch.float64) delta_t tensor(-0.5471, dtype=torch.float64)
6 gae_duplicate tensor(-1.0710, dtype=torch.float64) tensor(12.6296, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.5776, dtype=torch.float64) delta_t tensor(-0.2644, dtype=torch.float64)
5 gae_duplicate tensor(-0.9633, dtype=torch.float64) tensor(6.5969, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-3.7026, dtype=torch.float64) delta_t tensor(-2.9150, dtype=torch.float64)
4 gae_duplicate tensor(-4.9843, dtype=torch.float64) tensor(58.4696, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.1249, dtype=torch.float64) delta_t tensor(0.4776, dtype=torch.float64)
3 gae_duplicate tensor(-0.1347, dtype=torch.float64) tensor(-3.6373, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0567, dtype=torch.float64) delta_t tensor(0.4686, dtype=torch.float64)
2 gae_duplicate tensor(0.1694, dtype=torch.float64) tensor(-9.6090, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-904.9779052734375
value loss:165.98291015625
entropies:355.8703308105469
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.914190053939819 seconds
19 rew tensor(0.6470, dtype=torch.float64) delta_t tensor(-0.0353, dtype=torch.float64)
19 gae_duplicate tensor(-0.0704, dtype=torch.float64) tensor(0.6924, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6489, dtype=torch.float64) delta_t tensor(0.0348, dtype=torch.float64)
18 gae_duplicate tensor(-0.0063, dtype=torch.float64) tensor(-0.6189, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6509, dtype=torch.float64) delta_t tensor(0.0368, dtype=torch.float64)
17 gae_duplicate tensor(0.0019, dtype=torch.float64) tensor(-0.7863, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6528, dtype=torch.float64) delta_t tensor(0.0387, dtype=torch.float64)
16 gae_duplicate tensor(0.0046, dtype=torch.float64) tensor(-0.8391, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6548, dtype=torch.float64) delta_t tensor(0.0407, dtype=torch.float64)
15 gae_duplicate tensor(0.0067, dtype=torch.float64) tensor(-0.8883, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6568, dtype=torch.float64) delta_t tensor(0.0427, dtype=torch.float64)
14 gae_duplicate tensor(0.0088, dtype=torch.float64) tensor(-0.9396, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6588, dtype=torch.float64) delta_t tensor(0.0447, dtype=torch.float64)
13 gae_duplicate tensor(0.0109, dtype=torch.float64) tensor(-0.9852, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6608, dtype=torch.float64) delta_t tensor(0.0468, dtype=torch.float64)
12 gae_duplicate tensor(0.0130, dtype=torch.float64) tensor(-1.0265, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6629, dtype=torch.float64) delta_t tensor(0.9783, dtype=torch.float64)
11 gae_duplicate tensor(0.9170, dtype=torch.float64) tensor(-19.3222, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6650, dtype=torch.float64) delta_t tensor(0.7275, dtype=torch.float64)
10 gae_duplicate tensor(0.7688, dtype=torch.float64) tensor(-16.3192, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.4524, dtype=torch.float64) delta_t tensor(-0.3699, dtype=torch.float64)
9 gae_duplicate tensor(-1.0755, dtype=torch.float64) tensor(5.6270, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.3412, dtype=torch.float64) delta_t tensor(-0.2602, dtype=torch.float64)
8 gae_duplicate tensor(-0.9844, dtype=torch.float64) tensor(5.6538, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.6914, dtype=torch.float64) delta_t tensor(-0.5931, dtype=torch.float64)
7 gae_duplicate tensor(-0.8629, dtype=torch.float64) tensor(12.2924, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.2470, dtype=torch.float64) delta_t tensor(0.0421, dtype=torch.float64)
6 gae_duplicate tensor(-0.8507, dtype=torch.float64) tensor(0.3561, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.2297, dtype=torch.float64) delta_t tensor(-0.5963, dtype=torch.float64)
5 gae_duplicate tensor(-1.5262, dtype=torch.float64) tensor(11.8670, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.5406, dtype=torch.float64) delta_t tensor(-1.6266, dtype=torch.float64)
4 gae_duplicate tensor(-2.4330, dtype=torch.float64) tensor(33.2945, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.0599, dtype=torch.float64) delta_t tensor(0.4195, dtype=torch.float64)
3 gae_duplicate tensor(0.0655, dtype=torch.float64) tensor(-4.9385, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0502, dtype=torch.float64) delta_t tensor(0.5182, dtype=torch.float64)
2 gae_duplicate tensor(0.2990, dtype=torch.float64) tensor(-10.7387, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-764.6450805664062
value loss:68.10115814208984
entropies:355.9104309082031
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.0176191329956055 seconds
19 rew tensor(0.6514, dtype=torch.float64) delta_t tensor(-0.1024, dtype=torch.float64)
19 gae_duplicate tensor(-0.1442, dtype=torch.float64) tensor(2.0164, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6532, dtype=torch.float64) delta_t tensor(-0.0253, dtype=torch.float64)
18 gae_duplicate tensor(-0.0804, dtype=torch.float64) tensor(0.6983, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6550, dtype=torch.float64) delta_t tensor(-0.0235, dtype=torch.float64)
17 gae_duplicate tensor(-0.0723, dtype=torch.float64) tensor(0.5353, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6568, dtype=torch.float64) delta_t tensor(-0.0216, dtype=torch.float64)
16 gae_duplicate tensor(-0.0698, dtype=torch.float64) tensor(0.4862, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6587, dtype=torch.float64) delta_t tensor(-0.0198, dtype=torch.float64)
15 gae_duplicate tensor(-0.0679, dtype=torch.float64) tensor(0.4439, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6605, dtype=torch.float64) delta_t tensor(-0.0179, dtype=torch.float64)
14 gae_duplicate tensor(-0.0660, dtype=torch.float64) tensor(0.3988, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6624, dtype=torch.float64) delta_t tensor(-0.0161, dtype=torch.float64)
13 gae_duplicate tensor(-0.0640, dtype=torch.float64) tensor(0.3589, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6643, dtype=torch.float64) delta_t tensor(-0.0142, dtype=torch.float64)
12 gae_duplicate tensor(-0.0621, dtype=torch.float64) tensor(0.3180, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6662, dtype=torch.float64) delta_t tensor(0.8649, dtype=torch.float64)
11 gae_duplicate tensor(0.6101, dtype=torch.float64) tensor(-17.0822, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6681, dtype=torch.float64) delta_t tensor(0.8399, dtype=torch.float64)
10 gae_duplicate tensor(0.8656, dtype=torch.float64) tensor(-18.2445, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.5742, dtype=torch.float64) delta_t tensor(-0.4053, dtype=torch.float64)
9 gae_duplicate tensor(-0.9247, dtype=torch.float64) tensor(6.1936, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.7199, dtype=torch.float64) delta_t tensor(-0.5505, dtype=torch.float64)
8 gae_duplicate tensor(-0.7974, dtype=torch.float64) tensor(11.4646, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.5799, dtype=torch.float64) delta_t tensor(-0.4070, dtype=torch.float64)
7 gae_duplicate tensor(-0.6289, dtype=torch.float64) tensor(9.1732, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.3973, dtype=torch.float64) delta_t tensor(-0.2448, dtype=torch.float64)
6 gae_duplicate tensor(-0.6376, dtype=torch.float64) tensor(5.7603, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.6535, dtype=torch.float64) delta_t tensor(-0.2387, dtype=torch.float64)
5 gae_duplicate tensor(-0.7064, dtype=torch.float64) tensor(5.3762, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-0.7998, dtype=torch.float64) delta_t tensor(0.3213, dtype=torch.float64)
4 gae_duplicate tensor(-1.3794, dtype=torch.float64) tensor(-5.8060, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.3517, dtype=torch.float64) delta_t tensor(1.1186, dtype=torch.float64)
3 gae_duplicate tensor(0.9877, dtype=torch.float64) tensor(-22.6538, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.1473, dtype=torch.float64) delta_t tensor(0.4220, dtype=torch.float64)
2 gae_duplicate tensor(0.2917, dtype=torch.float64) tensor(-10.6169, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:1587.60693359375
value loss:54.93562698364258
entropies:355.9190368652344
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.134462118148804 seconds
19 rew tensor(0.6530, dtype=torch.float64) delta_t tensor(0.1047, dtype=torch.float64)
19 gae_duplicate tensor(-0.1635, dtype=torch.float64) tensor(-2.0391, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6546, dtype=torch.float64) delta_t tensor(0.1612, dtype=torch.float64)
18 gae_duplicate tensor(-0.0981, dtype=torch.float64) tensor(-3.3763, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6563, dtype=torch.float64) delta_t tensor(0.1629, dtype=torch.float64)
17 gae_duplicate tensor(-0.0900, dtype=torch.float64) tensor(-3.5218, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6580, dtype=torch.float64) delta_t tensor(0.1646, dtype=torch.float64)
16 gae_duplicate tensor(-0.0876, dtype=torch.float64) tensor(-3.5992, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6597, dtype=torch.float64) delta_t tensor(0.1663, dtype=torch.float64)
15 gae_duplicate tensor(-0.0857, dtype=torch.float64) tensor(-3.6267, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6615, dtype=torch.float64) delta_t tensor(0.1681, dtype=torch.float64)
14 gae_duplicate tensor(-0.0838, dtype=torch.float64) tensor(-3.6921, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6632, dtype=torch.float64) delta_t tensor(0.1698, dtype=torch.float64)
13 gae_duplicate tensor(-0.0820, dtype=torch.float64) tensor(-3.7317, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6650, dtype=torch.float64) delta_t tensor(0.1716, dtype=torch.float64)
12 gae_duplicate tensor(-0.0801, dtype=torch.float64) tensor(-3.8073, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6667, dtype=torch.float64) delta_t tensor(0.8000, dtype=torch.float64)
11 gae_duplicate tensor(0.5329, dtype=torch.float64) tensor(-16.1874, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6685, dtype=torch.float64) delta_t tensor(0.8295, dtype=torch.float64)
10 gae_duplicate tensor(0.8352, dtype=torch.float64) tensor(-18.0592, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.7257, dtype=torch.float64) delta_t tensor(-0.5660, dtype=torch.float64)
9 gae_duplicate tensor(-1.1294, dtype=torch.float64) tensor(9.3791, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.9470, dtype=torch.float64) delta_t tensor(-0.7938, dtype=torch.float64)
8 gae_duplicate tensor(-1.9079, dtype=torch.float64) tensor(16.7250, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.9389, dtype=torch.float64) delta_t tensor(-0.7858, dtype=torch.float64)
7 gae_duplicate tensor(-1.2124, dtype=torch.float64) tensor(17.3264, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.7753, dtype=torch.float64) delta_t tensor(-0.5017, dtype=torch.float64)
6 gae_duplicate tensor(-0.8418, dtype=torch.float64) tensor(11.6019, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.0210, dtype=torch.float64) delta_t tensor(-0.2435, dtype=torch.float64)
5 gae_duplicate tensor(-1.3470, dtype=torch.float64) tensor(5.9982, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.0479, dtype=torch.float64) delta_t tensor(-0.9646, dtype=torch.float64)
4 gae_duplicate tensor(-4.6626, dtype=torch.float64) tensor(19.7918, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.1228, dtype=torch.float64) delta_t tensor(0.7565, dtype=torch.float64)
3 gae_duplicate tensor(-0.0246, dtype=torch.float64) tensor(-12.9984, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.0026, dtype=torch.float64) delta_t tensor(0.5750, dtype=torch.float64)
2 gae_duplicate tensor(0.3849, dtype=torch.float64) tensor(-12.7020, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:255.92759704589844
value loss:115.26809692382812
entropies:355.91754150390625
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.871784210205078 seconds
19 rew tensor(0.6571, dtype=torch.float64) delta_t tensor(-0.0630, dtype=torch.float64)
19 gae_duplicate tensor(-0.2278, dtype=torch.float64) tensor(1.2569, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6587, dtype=torch.float64) delta_t tensor(0.0106, dtype=torch.float64)
18 gae_duplicate tensor(-0.1633, dtype=torch.float64) tensor(-0.0671, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6603, dtype=torch.float64) delta_t tensor(0.0121, dtype=torch.float64)
17 gae_duplicate tensor(-0.1554, dtype=torch.float64) tensor(-0.2912, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6619, dtype=torch.float64) delta_t tensor(0.0137, dtype=torch.float64)
16 gae_duplicate tensor(-0.1531, dtype=torch.float64) tensor(-0.2708, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6635, dtype=torch.float64) delta_t tensor(0.0154, dtype=torch.float64)
15 gae_duplicate tensor(-0.1513, dtype=torch.float64) tensor(-0.3622, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6651, dtype=torch.float64) delta_t tensor(0.0170, dtype=torch.float64)
14 gae_duplicate tensor(-0.1497, dtype=torch.float64) tensor(-0.4005, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6668, dtype=torch.float64) delta_t tensor(0.0186, dtype=torch.float64)
13 gae_duplicate tensor(-0.1480, dtype=torch.float64) tensor(-0.4364, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6684, dtype=torch.float64) delta_t tensor(0.0203, dtype=torch.float64)
12 gae_duplicate tensor(-0.1463, dtype=torch.float64) tensor(-0.4183, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6701, dtype=torch.float64) delta_t tensor(0.9295, dtype=torch.float64)
11 gae_duplicate tensor(0.5876, dtype=torch.float64) tensor(-18.4500, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6717, dtype=torch.float64) delta_t tensor(0.8306, dtype=torch.float64)
10 gae_duplicate tensor(0.8673, dtype=torch.float64) tensor(-18.1387, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.6959, dtype=torch.float64) delta_t tensor(-0.5315, dtype=torch.float64)
9 gae_duplicate tensor(-1.0052, dtype=torch.float64) tensor(8.6840, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.7362, dtype=torch.float64) delta_t tensor(-0.5736, dtype=torch.float64)
8 gae_duplicate tensor(-0.8032, dtype=torch.float64) tensor(12.1973, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-1.1748, dtype=torch.float64) delta_t tensor(-1.0058, dtype=torch.float64)
7 gae_duplicate tensor(-1.9662, dtype=torch.float64) tensor(21.1730, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.8961, dtype=torch.float64) delta_t tensor(-0.5844, dtype=torch.float64)
6 gae_duplicate tensor(-1.1964, dtype=torch.float64) tensor(13.7021, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.5847, dtype=torch.float64) delta_t tensor(0.3871, dtype=torch.float64)
5 gae_duplicate tensor(-0.8211, dtype=torch.float64) tensor(-6.2581, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.5735, dtype=torch.float64) delta_t tensor(-0.3879, dtype=torch.float64)
4 gae_duplicate tensor(-3.5583, dtype=torch.float64) tensor(6.8816, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.0773, dtype=torch.float64) delta_t tensor(0.8532, dtype=torch.float64)
3 gae_duplicate tensor(0.1762, dtype=torch.float64) tensor(-16.1662, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.0056, dtype=torch.float64) delta_t tensor(0.5773, dtype=torch.float64)
2 gae_duplicate tensor(0.1728, dtype=torch.float64) tensor(-13.0199, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:464.66998291015625
value loss:89.3497314453125
entropies:355.8956604003906
Policy training finished
---------------------
ToM training started
ToM data loaded
batch_size =  600
ToM_loss = tensor(3954.9700)
ToM Target loss= tensor(3281.0293)
optimized based on ToM loss
---------------------
gamma: 0.1
training start after waiting for 5.200392961502075 seconds
19 rew tensor(0.6520, dtype=torch.float64) delta_t tensor(0.1682, dtype=torch.float64)
19 gae_duplicate tensor(-0.2688, dtype=torch.float64) tensor(-3.3334, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6534, dtype=torch.float64) delta_t tensor(0.2180, dtype=torch.float64)
18 gae_duplicate tensor(-0.2046, dtype=torch.float64) tensor(-4.7622, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6549, dtype=torch.float64) delta_t tensor(0.2195, dtype=torch.float64)
17 gae_duplicate tensor(-0.1968, dtype=torch.float64) tensor(-4.7886, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6564, dtype=torch.float64) delta_t tensor(0.2210, dtype=torch.float64)
16 gae_duplicate tensor(-0.1946, dtype=torch.float64) tensor(-4.9269, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6579, dtype=torch.float64) delta_t tensor(0.2224, dtype=torch.float64)
15 gae_duplicate tensor(-0.1930, dtype=torch.float64) tensor(-4.8311, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6594, dtype=torch.float64) delta_t tensor(0.2239, dtype=torch.float64)
14 gae_duplicate tensor(-0.1914, dtype=torch.float64) tensor(-4.9138, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6609, dtype=torch.float64) delta_t tensor(0.2255, dtype=torch.float64)
13 gae_duplicate tensor(-0.1899, dtype=torch.float64) tensor(-4.9397, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6624, dtype=torch.float64) delta_t tensor(0.2270, dtype=torch.float64)
12 gae_duplicate tensor(-0.1883, dtype=torch.float64) tensor(-4.9933, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6639, dtype=torch.float64) delta_t tensor(0.7304, dtype=torch.float64)
11 gae_duplicate tensor(0.4695, dtype=torch.float64) tensor(-14.9130, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6655, dtype=torch.float64) delta_t tensor(0.8273, dtype=torch.float64)
10 gae_duplicate tensor(0.8464, dtype=torch.float64) tensor(-17.8766, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.7073, dtype=torch.float64) delta_t tensor(-0.5497, dtype=torch.float64)
9 gae_duplicate tensor(-0.9984, dtype=torch.float64) tensor(9.0670, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.9289, dtype=torch.float64) delta_t tensor(-0.7790, dtype=torch.float64)
8 gae_duplicate tensor(-1.1919, dtype=torch.float64) tensor(16.3814, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-1.1964, dtype=torch.float64) delta_t tensor(-1.0456, dtype=torch.float64)
7 gae_duplicate tensor(-2.4524, dtype=torch.float64) tensor(22.3087, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.5661, dtype=torch.float64) delta_t tensor(-0.2576, dtype=torch.float64)
6 gae_duplicate tensor(-0.8961, dtype=torch.float64) tensor(7.3133, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.9226, dtype=torch.float64) delta_t tensor(-0.0984, dtype=torch.float64)
5 gae_duplicate tensor(-0.6819, dtype=torch.float64) tensor(2.6617, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-4.2273, dtype=torch.float64) delta_t tensor(-3.0944, dtype=torch.float64)
4 gae_duplicate tensor(-5.0057, dtype=torch.float64) tensor(61.6047, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.0899, dtype=torch.float64) delta_t tensor(0.6951, dtype=torch.float64)
3 gae_duplicate tensor(-0.2110, dtype=torch.float64) tensor(-7.5651, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0792, dtype=torch.float64) delta_t tensor(0.6890, dtype=torch.float64)
2 gae_duplicate tensor(0.6026, dtype=torch.float64) tensor(-14.4508, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-1556.3739013671875
value loss:168.2545928955078
entropies:355.8636169433594
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.098505973815918 seconds
19 rew tensor(0.6544, dtype=torch.float64) delta_t tensor(-0.2284, dtype=torch.float64)
19 gae_duplicate tensor(-0.2902, dtype=torch.float64) tensor(4.5113, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6558, dtype=torch.float64) delta_t tensor(-0.1387, dtype=torch.float64)
18 gae_duplicate tensor(-0.2242, dtype=torch.float64) tensor(3.2342, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6572, dtype=torch.float64) delta_t tensor(-0.1373, dtype=torch.float64)
17 gae_duplicate tensor(-0.2162, dtype=torch.float64) tensor(3.0047, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6586, dtype=torch.float64) delta_t tensor(-0.1359, dtype=torch.float64)
16 gae_duplicate tensor(-0.2141, dtype=torch.float64) tensor(2.9731, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6600, dtype=torch.float64) delta_t tensor(-0.1345, dtype=torch.float64)
15 gae_duplicate tensor(-0.2125, dtype=torch.float64) tensor(3.0026, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6614, dtype=torch.float64) delta_t tensor(-0.1331, dtype=torch.float64)
14 gae_duplicate tensor(-0.2109, dtype=torch.float64) tensor(2.8904, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6628, dtype=torch.float64) delta_t tensor(-0.1317, dtype=torch.float64)
13 gae_duplicate tensor(-0.2094, dtype=torch.float64) tensor(2.8834, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6642, dtype=torch.float64) delta_t tensor(-0.1302, dtype=torch.float64)
12 gae_duplicate tensor(-0.2078, dtype=torch.float64) tensor(2.8609, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6657, dtype=torch.float64) delta_t tensor(0.8062, dtype=torch.float64)
11 gae_duplicate tensor(0.4561, dtype=torch.float64) tensor(-15.5709, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6671, dtype=torch.float64) delta_t tensor(0.8671, dtype=torch.float64)
10 gae_duplicate tensor(0.8936, dtype=torch.float64) tensor(-18.7946, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.6063, dtype=torch.float64) delta_t tensor(-0.4189, dtype=torch.float64)
9 gae_duplicate tensor(-1.0229, dtype=torch.float64) tensor(6.3873, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.9332, dtype=torch.float64) delta_t tensor(-0.7450, dtype=torch.float64)
8 gae_duplicate tensor(-1.8567, dtype=torch.float64) tensor(15.3818, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.4753, dtype=torch.float64) delta_t tensor(-0.2714, dtype=torch.float64)
7 gae_duplicate tensor(-0.6485, dtype=torch.float64) tensor(6.8386, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.5732, dtype=torch.float64) delta_t tensor(-0.1946, dtype=torch.float64)
6 gae_duplicate tensor(-0.5871, dtype=torch.float64) tensor(4.5828, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.9290, dtype=torch.float64) delta_t tensor(0.2818, dtype=torch.float64)
5 gae_duplicate tensor(-0.8905, dtype=torch.float64) tensor(-5.0565, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-3.0199, dtype=torch.float64) delta_t tensor(-1.7492, dtype=torch.float64)
4 gae_duplicate tensor(-2.5986, dtype=torch.float64) tensor(34.1917, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.0717, dtype=torch.float64) delta_t tensor(0.7530, dtype=torch.float64)
3 gae_duplicate tensor(0.1487, dtype=torch.float64) tensor(-11.5642, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0031, dtype=torch.float64) delta_t tensor(0.6439, dtype=torch.float64)
2 gae_duplicate tensor(0.5641, dtype=torch.float64) tensor(-14.1320, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-1587.80322265625
value loss:73.9880599975586
entropies:355.8204345703125
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.7455339431762695 seconds
19 rew tensor(0.6575, dtype=torch.float64) delta_t tensor(-0.2205, dtype=torch.float64)
19 gae_duplicate tensor(-0.2781, dtype=torch.float64) tensor(4.3996, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6588, dtype=torch.float64) delta_t tensor(-0.1314, dtype=torch.float64)
18 gae_duplicate tensor(-0.2125, dtype=torch.float64) tensor(3.0785, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6601, dtype=torch.float64) delta_t tensor(-0.1301, dtype=torch.float64)
17 gae_duplicate tensor(-0.2047, dtype=torch.float64) tensor(2.8589, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6615, dtype=torch.float64) delta_t tensor(-0.1287, dtype=torch.float64)
16 gae_duplicate tensor(-0.2026, dtype=torch.float64) tensor(2.8336, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6628, dtype=torch.float64) delta_t tensor(-0.1274, dtype=torch.float64)
15 gae_duplicate tensor(-0.2011, dtype=torch.float64) tensor(2.7992, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6641, dtype=torch.float64) delta_t tensor(-0.1261, dtype=torch.float64)
14 gae_duplicate tensor(-0.1997, dtype=torch.float64) tensor(2.7878, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6655, dtype=torch.float64) delta_t tensor(-0.1247, dtype=torch.float64)
13 gae_duplicate tensor(-0.1982, dtype=torch.float64) tensor(2.7434, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6669, dtype=torch.float64) delta_t tensor(-0.1233, dtype=torch.float64)
12 gae_duplicate tensor(-0.1968, dtype=torch.float64) tensor(2.7263, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6682, dtype=torch.float64) delta_t tensor(0.5973, dtype=torch.float64)
11 gae_duplicate tensor(0.4504, dtype=torch.float64) tensor(-11.5100, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6696, dtype=torch.float64) delta_t tensor(0.9611, dtype=torch.float64)
10 gae_duplicate tensor(0.9521, dtype=torch.float64) tensor(-20.1492, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.9531, dtype=torch.float64) delta_t tensor(-0.7021, dtype=torch.float64)
9 gae_duplicate tensor(-1.7499, dtype=torch.float64) tensor(11.9802, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.5018, dtype=torch.float64) delta_t tensor(-0.2515, dtype=torch.float64)
8 gae_duplicate tensor(-0.7343, dtype=torch.float64) tensor(6.1723, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.7308, dtype=torch.float64) delta_t tensor(-0.4752, dtype=torch.float64)
7 gae_duplicate tensor(-0.7440, dtype=torch.float64) tensor(9.9692, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.7778, dtype=torch.float64) delta_t tensor(-0.3851, dtype=torch.float64)
6 gae_duplicate tensor(-0.6128, dtype=torch.float64) tensor(8.5633, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7585, dtype=torch.float64) delta_t tensor(0.6495, dtype=torch.float64)
5 gae_duplicate tensor(0.3516, dtype=torch.float64) tensor(-11.8204, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.1825, dtype=torch.float64) delta_t tensor(-0.8778, dtype=torch.float64)
4 gae_duplicate tensor(-3.0649, dtype=torch.float64) tensor(16.1307, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.0814, dtype=torch.float64) delta_t tensor(1.0597, dtype=torch.float64)
3 gae_duplicate tensor(0.0770, dtype=torch.float64) tensor(-19.5365, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.0366, dtype=torch.float64) delta_t tensor(0.5509, dtype=torch.float64)
2 gae_duplicate tensor(0.2858, dtype=torch.float64) tensor(-12.7677, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-164.06863403320312
value loss:71.22415924072266
entropies:355.7828063964844
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.3671159744262695 seconds
19 rew tensor(0.6569, dtype=torch.float64) delta_t tensor(0.1024, dtype=torch.float64)
19 gae_duplicate tensor(-0.2825, dtype=torch.float64) tensor(-2.0752, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6582, dtype=torch.float64) delta_t tensor(0.1591, dtype=torch.float64)
18 gae_duplicate tensor(-0.2175, dtype=torch.float64) tensor(-3.3700, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6594, dtype=torch.float64) delta_t tensor(0.1604, dtype=torch.float64)
17 gae_duplicate tensor(-0.2098, dtype=torch.float64) tensor(-3.6025, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6607, dtype=torch.float64) delta_t tensor(0.1616, dtype=torch.float64)
16 gae_duplicate tensor(-0.2079, dtype=torch.float64) tensor(-3.5104, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6619, dtype=torch.float64) delta_t tensor(0.1629, dtype=torch.float64)
15 gae_duplicate tensor(-0.2065, dtype=torch.float64) tensor(-3.6065, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6632, dtype=torch.float64) delta_t tensor(0.1642, dtype=torch.float64)
14 gae_duplicate tensor(-0.2051, dtype=torch.float64) tensor(-3.5354, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6645, dtype=torch.float64) delta_t tensor(0.1654, dtype=torch.float64)
13 gae_duplicate tensor(-0.2037, dtype=torch.float64) tensor(-3.5430, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6658, dtype=torch.float64) delta_t tensor(0.1667, dtype=torch.float64)
12 gae_duplicate tensor(-0.2024, dtype=torch.float64) tensor(-3.7297, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6671, dtype=torch.float64) delta_t tensor(0.5817, dtype=torch.float64)
11 gae_duplicate tensor(0.4535, dtype=torch.float64) tensor(-11.9237, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6684, dtype=torch.float64) delta_t tensor(0.9694, dtype=torch.float64)
10 gae_duplicate tensor(0.9772, dtype=torch.float64) tensor(-20.5268, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.8487, dtype=torch.float64) delta_t tensor(-0.5822, dtype=torch.float64)
9 gae_duplicate tensor(-1.3175, dtype=torch.float64) tensor(9.6311, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.8447, dtype=torch.float64) delta_t tensor(-0.5836, dtype=torch.float64)
8 gae_duplicate tensor(-1.1194, dtype=torch.float64) tensor(12.5165, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.8960, dtype=torch.float64) delta_t tensor(-0.6339, dtype=torch.float64)
7 gae_duplicate tensor(-2.2387, dtype=torch.float64) tensor(13.7756, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.6697, dtype=torch.float64) delta_t tensor(-0.2585, dtype=torch.float64)
6 gae_duplicate tensor(-0.4873, dtype=torch.float64) tensor(6.5657, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.6935, dtype=torch.float64) delta_t tensor(0.3975, dtype=torch.float64)
5 gae_duplicate tensor(-0.5580, dtype=torch.float64) tensor(-7.1340, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.7346, dtype=torch.float64) delta_t tensor(-1.4204, dtype=torch.float64)
4 gae_duplicate tensor(-4.6373, dtype=torch.float64) tensor(26.9764, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.0966, dtype=torch.float64) delta_t tensor(0.8647, dtype=torch.float64)
3 gae_duplicate tensor(0.0524, dtype=torch.float64) tensor(-14.2601, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0194, dtype=torch.float64) delta_t tensor(0.4724, dtype=torch.float64)
2 gae_duplicate tensor(0.2814, dtype=torch.float64) tensor(-10.8306, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:1101.8099365234375
value loss:112.38956451416016
entropies:355.74835205078125
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.938526153564453 seconds
19 rew tensor(0.6553, dtype=torch.float64) delta_t tensor(0.2211, dtype=torch.float64)
19 gae_duplicate tensor(-0.2556, dtype=torch.float64) tensor(-4.4493, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6565, dtype=torch.float64) delta_t tensor(0.2657, dtype=torch.float64)
18 gae_duplicate tensor(-0.1898, dtype=torch.float64) tensor(-5.6050, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6577, dtype=torch.float64) delta_t tensor(0.2669, dtype=torch.float64)
17 gae_duplicate tensor(-0.1820, dtype=torch.float64) tensor(-5.8178, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6588, dtype=torch.float64) delta_t tensor(0.2681, dtype=torch.float64)
16 gae_duplicate tensor(-0.1801, dtype=torch.float64) tensor(-5.9167, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6600, dtype=torch.float64) delta_t tensor(0.2693, dtype=torch.float64)
15 gae_duplicate tensor(-0.1787, dtype=torch.float64) tensor(-5.9248, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6612, dtype=torch.float64) delta_t tensor(0.2705, dtype=torch.float64)
14 gae_duplicate tensor(-0.1774, dtype=torch.float64) tensor(-5.8752, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6624, dtype=torch.float64) delta_t tensor(0.2717, dtype=torch.float64)
13 gae_duplicate tensor(-0.1761, dtype=torch.float64) tensor(-5.8291, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6637, dtype=torch.float64) delta_t tensor(0.2729, dtype=torch.float64)
12 gae_duplicate tensor(-0.1748, dtype=torch.float64) tensor(-5.9625, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6649, dtype=torch.float64) delta_t tensor(0.5786, dtype=torch.float64)
11 gae_duplicate tensor(0.4482, dtype=torch.float64) tensor(-11.9716, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6661, dtype=torch.float64) delta_t tensor(0.9634, dtype=torch.float64)
10 gae_duplicate tensor(0.9150, dtype=torch.float64) tensor(-20.4686, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.8328, dtype=torch.float64) delta_t tensor(-0.5627, dtype=torch.float64)
9 gae_duplicate tensor(-0.9026, dtype=torch.float64) tensor(9.1365, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.9607, dtype=torch.float64) delta_t tensor(-0.7003, dtype=torch.float64)
8 gae_duplicate tensor(-1.7633, dtype=torch.float64) tensor(14.5720, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.4990, dtype=torch.float64) delta_t tensor(-0.2405, dtype=torch.float64)
7 gae_duplicate tensor(-1.2354, dtype=torch.float64) tensor(6.1069, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.7728, dtype=torch.float64) delta_t tensor(-0.3717, dtype=torch.float64)
6 gae_duplicate tensor(-0.6138, dtype=torch.float64) tensor(8.0380, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.1176, dtype=torch.float64) delta_t tensor(0.0057, dtype=torch.float64)
5 gae_duplicate tensor(-0.9722, dtype=torch.float64) tensor(0.7604, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-3.1027, dtype=torch.float64) delta_t tensor(-1.8131, dtype=torch.float64)
4 gae_duplicate tensor(-4.5307, dtype=torch.float64) tensor(36.0276, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.1659, dtype=torch.float64) delta_t tensor(0.7887, dtype=torch.float64)
3 gae_duplicate tensor(-0.0008, dtype=torch.float64) tensor(-12.0520, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0672, dtype=torch.float64) delta_t tensor(0.7489, dtype=torch.float64)
2 gae_duplicate tensor(0.6997, dtype=torch.float64) tensor(-15.9991, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:1590.381103515625
value loss:130.81735229492188
entropies:355.755126953125
Policy training finished
---------------------
ToM training started
ToM data loaded
batch_size =  600
ToM_loss = tensor(3952.6536)
ToM Target loss= tensor(3261.5081)
optimized based on ToM loss
---------------------
gamma: 0.1
training start after waiting for 4.976512908935547 seconds
19 rew tensor(0.6584, dtype=torch.float64) delta_t tensor(-0.1068, dtype=torch.float64)
19 gae_duplicate tensor(-0.2561, dtype=torch.float64) tensor(2.2023, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6595, dtype=torch.float64) delta_t tensor(-0.0292, dtype=torch.float64)
18 gae_duplicate tensor(-0.1893, dtype=torch.float64) tensor(0.7342, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6606, dtype=torch.float64) delta_t tensor(-0.0281, dtype=torch.float64)
17 gae_duplicate tensor(-0.1815, dtype=torch.float64) tensor(0.5743, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6618, dtype=torch.float64) delta_t tensor(-0.0269, dtype=torch.float64)
16 gae_duplicate tensor(-0.1795, dtype=torch.float64) tensor(0.5411, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6629, dtype=torch.float64) delta_t tensor(-0.0258, dtype=torch.float64)
15 gae_duplicate tensor(-0.1782, dtype=torch.float64) tensor(0.5324, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6641, dtype=torch.float64) delta_t tensor(-0.0246, dtype=torch.float64)
14 gae_duplicate tensor(-0.1769, dtype=torch.float64) tensor(0.5282, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6652, dtype=torch.float64) delta_t tensor(-0.0235, dtype=torch.float64)
13 gae_duplicate tensor(-0.1757, dtype=torch.float64) tensor(0.4922, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6664, dtype=torch.float64) delta_t tensor(-0.0223, dtype=torch.float64)
12 gae_duplicate tensor(-0.1744, dtype=torch.float64) tensor(0.4927, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6675, dtype=torch.float64) delta_t tensor(0.4603, dtype=torch.float64)
11 gae_duplicate tensor(0.4134, dtype=torch.float64) tensor(-9.0168, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6687, dtype=torch.float64) delta_t tensor(1.1407, dtype=torch.float64)
10 gae_duplicate tensor(0.9777, dtype=torch.float64) tensor(-23.4067, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.6257, dtype=torch.float64) delta_t tensor(-0.1969, dtype=torch.float64)
9 gae_duplicate tensor(-0.9565, dtype=torch.float64) tensor(1.3728, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.6178, dtype=torch.float64) delta_t tensor(-0.2873, dtype=torch.float64)
8 gae_duplicate tensor(-0.5995, dtype=torch.float64) tensor(5.8965, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.8614, dtype=torch.float64) delta_t tensor(-0.5427, dtype=torch.float64)
7 gae_duplicate tensor(-1.4068, dtype=torch.float64) tensor(11.2097, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.7736, dtype=torch.float64) delta_t tensor(-0.3655, dtype=torch.float64)
6 gae_duplicate tensor(-0.9400, dtype=torch.float64) tensor(8.3530, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7705, dtype=torch.float64) delta_t tensor(0.5524, dtype=torch.float64)
5 gae_duplicate tensor(-0.1269, dtype=torch.float64) tensor(-10.0804, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.3659, dtype=torch.float64) delta_t tensor(-1.0721, dtype=torch.float64)
4 gae_duplicate tensor(-2.7559, dtype=torch.float64) tensor(19.8894, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.1918, dtype=torch.float64) delta_t tensor(1.1693, dtype=torch.float64)
3 gae_duplicate tensor(0.1464, dtype=torch.float64) tensor(-21.0148, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.0711, dtype=torch.float64) delta_t tensor(0.6000, dtype=torch.float64)
2 gae_duplicate tensor(0.2285, dtype=torch.float64) tensor(-13.9782, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:1236.568359375
value loss:75.73124694824219
entropies:355.7534484863281
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.975116729736328 seconds
19 rew tensor(0.6583, dtype=torch.float64) delta_t tensor(-0.0066, dtype=torch.float64)
19 gae_duplicate tensor(-0.2755, dtype=torch.float64) tensor(0.0947, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6594, dtype=torch.float64) delta_t tensor(0.0610, dtype=torch.float64)
18 gae_duplicate tensor(-0.2097, dtype=torch.float64) tensor(-1.2569, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6605, dtype=torch.float64) delta_t tensor(0.0621, dtype=torch.float64)
17 gae_duplicate tensor(-0.2021, dtype=torch.float64) tensor(-1.3532, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6616, dtype=torch.float64) delta_t tensor(0.0631, dtype=torch.float64)
16 gae_duplicate tensor(-0.2002, dtype=torch.float64) tensor(-1.4818, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6627, dtype=torch.float64) delta_t tensor(0.0642, dtype=torch.float64)
15 gae_duplicate tensor(-0.1990, dtype=torch.float64) tensor(-1.4017, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6638, dtype=torch.float64) delta_t tensor(0.0653, dtype=torch.float64)
14 gae_duplicate tensor(-0.1978, dtype=torch.float64) tensor(-1.5513, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6649, dtype=torch.float64) delta_t tensor(0.0664, dtype=torch.float64)
13 gae_duplicate tensor(-0.1966, dtype=torch.float64) tensor(-1.4097, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6660, dtype=torch.float64) delta_t tensor(0.0675, dtype=torch.float64)
12 gae_duplicate tensor(-0.1954, dtype=torch.float64) tensor(-1.4559, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6671, dtype=torch.float64) delta_t tensor(0.4287, dtype=torch.float64)
11 gae_duplicate tensor(0.3680, dtype=torch.float64) tensor(-8.5939, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6682, dtype=torch.float64) delta_t tensor(1.0803, dtype=torch.float64)
10 gae_duplicate tensor(0.8612, dtype=torch.float64) tensor(-22.5626, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.5139, dtype=torch.float64) delta_t tensor(-0.1336, dtype=torch.float64)
9 gae_duplicate tensor(-0.5406, dtype=torch.float64) tensor(0.4535, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.8429, dtype=torch.float64) delta_t tensor(-0.5362, dtype=torch.float64)
8 gae_duplicate tensor(-2.0989, dtype=torch.float64) tensor(10.5852, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.7419, dtype=torch.float64) delta_t tensor(-0.4716, dtype=torch.float64)
7 gae_duplicate tensor(-1.2865, dtype=torch.float64) tensor(10.4385, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.5535, dtype=torch.float64) delta_t tensor(-0.1759, dtype=torch.float64)
6 gae_duplicate tensor(-0.6219, dtype=torch.float64) tensor(4.5622, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7996, dtype=torch.float64) delta_t tensor(0.4681, dtype=torch.float64)
5 gae_duplicate tensor(-1.3231, dtype=torch.float64) tensor(-8.5732, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.3170, dtype=torch.float64) delta_t tensor(-0.0571, dtype=torch.float64)
4 gae_duplicate tensor(-3.0398, dtype=torch.float64) tensor(0.0947, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.2288, dtype=torch.float64) delta_t tensor(0.9776, dtype=torch.float64)
3 gae_duplicate tensor(-0.0550, dtype=torch.float64) tensor(-19.4258, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.0044, dtype=torch.float64) delta_t tensor(0.5807, dtype=torch.float64)
2 gae_duplicate tensor(0.4745, dtype=torch.float64) tensor(-13.4434, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:2943.08544921875
value loss:100.13838958740234
entropies:355.79486083984375
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.995130777359009 seconds
19 rew tensor(0.6571, dtype=torch.float64) delta_t tensor(-0.1484, dtype=torch.float64)
19 gae_duplicate tensor(-0.2848, dtype=torch.float64) tensor(2.9494, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6581, dtype=torch.float64) delta_t tensor(-0.0668, dtype=torch.float64)
18 gae_duplicate tensor(-0.2185, dtype=torch.float64) tensor(1.6103, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6591, dtype=torch.float64) delta_t tensor(-0.0658, dtype=torch.float64)
17 gae_duplicate tensor(-0.2109, dtype=torch.float64) tensor(1.3960, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6602, dtype=torch.float64) delta_t tensor(-0.0647, dtype=torch.float64)
16 gae_duplicate tensor(-0.2091, dtype=torch.float64) tensor(1.4317, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6612, dtype=torch.float64) delta_t tensor(-0.0637, dtype=torch.float64)
15 gae_duplicate tensor(-0.2079, dtype=torch.float64) tensor(1.3908, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6623, dtype=torch.float64) delta_t tensor(-0.0626, dtype=torch.float64)
14 gae_duplicate tensor(-0.2067, dtype=torch.float64) tensor(1.3787, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6633, dtype=torch.float64) delta_t tensor(-0.0616, dtype=torch.float64)
13 gae_duplicate tensor(-0.2056, dtype=torch.float64) tensor(1.3652, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6644, dtype=torch.float64) delta_t tensor(-0.0605, dtype=torch.float64)
12 gae_duplicate tensor(-0.2044, dtype=torch.float64) tensor(1.3102, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6654, dtype=torch.float64) delta_t tensor(0.3621, dtype=torch.float64)
11 gae_duplicate tensor(0.3149, dtype=torch.float64) tensor(-6.9976, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6665, dtype=torch.float64) delta_t tensor(1.0363, dtype=torch.float64)
10 gae_duplicate tensor(0.9873, dtype=torch.float64) tensor(-21.2498, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.7369, dtype=torch.float64) delta_t tensor(-0.4155, dtype=torch.float64)
9 gae_duplicate tensor(-0.5522, dtype=torch.float64) tensor(6.0861, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.8651, dtype=torch.float64) delta_t tensor(-0.5727, dtype=torch.float64)
8 gae_duplicate tensor(-1.4887, dtype=torch.float64) tensor(11.8799, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.6345, dtype=torch.float64) delta_t tensor(-0.3411, dtype=torch.float64)
7 gae_duplicate tensor(-1.8288, dtype=torch.float64) tensor(7.9318, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.7758, dtype=torch.float64) delta_t tensor(-0.3942, dtype=torch.float64)
6 gae_duplicate tensor(-0.6408, dtype=torch.float64) tensor(8.6051, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7797, dtype=torch.float64) delta_t tensor(0.5236, dtype=torch.float64)
5 gae_duplicate tensor(-0.2177, dtype=torch.float64) tensor(-9.4520, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.8375, dtype=torch.float64) delta_t tensor(-1.5929, dtype=torch.float64)
4 gae_duplicate tensor(-4.2396, dtype=torch.float64) tensor(30.7797, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.1969, dtype=torch.float64) delta_t tensor(1.0627, dtype=torch.float64)
3 gae_duplicate tensor(-0.2081, dtype=torch.float64) tensor(-18.0492, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.0625, dtype=torch.float64) delta_t tensor(0.5581, dtype=torch.float64)
2 gae_duplicate tensor(0.4610, dtype=torch.float64) tensor(-12.8170, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-611.7347412109375
value loss:119.54139709472656
entropies:355.85894775390625
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.987740993499756 seconds
19 rew tensor(0.6554, dtype=torch.float64) delta_t tensor(-0.1626, dtype=torch.float64)
19 gae_duplicate tensor(-0.2786, dtype=torch.float64) tensor(3.2299, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6563, dtype=torch.float64) delta_t tensor(-0.0798, dtype=torch.float64)
18 gae_duplicate tensor(-0.2120, dtype=torch.float64) tensor(1.8810, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6573, dtype=torch.float64) delta_t tensor(-0.0788, dtype=torch.float64)
17 gae_duplicate tensor(-0.2043, dtype=torch.float64) tensor(1.7610, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6583, dtype=torch.float64) delta_t tensor(-0.0778, dtype=torch.float64)
16 gae_duplicate tensor(-0.2026, dtype=torch.float64) tensor(1.7005, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6593, dtype=torch.float64) delta_t tensor(-0.0769, dtype=torch.float64)
15 gae_duplicate tensor(-0.2014, dtype=torch.float64) tensor(1.6991, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6603, dtype=torch.float64) delta_t tensor(-0.0759, dtype=torch.float64)
14 gae_duplicate tensor(-0.2003, dtype=torch.float64) tensor(1.6866, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6613, dtype=torch.float64) delta_t tensor(-0.0749, dtype=torch.float64)
13 gae_duplicate tensor(-0.1992, dtype=torch.float64) tensor(1.6676, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6623, dtype=torch.float64) delta_t tensor(-0.0739, dtype=torch.float64)
12 gae_duplicate tensor(-0.1981, dtype=torch.float64) tensor(1.6529, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6633, dtype=torch.float64) delta_t tensor(0.4399, dtype=torch.float64)
11 gae_duplicate tensor(0.2685, dtype=torch.float64) tensor(-8.5158, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6643, dtype=torch.float64) delta_t tensor(0.9440, dtype=torch.float64)
10 gae_duplicate tensor(0.7260, dtype=torch.float64) tensor(-19.4468, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.7320, dtype=torch.float64) delta_t tensor(-0.4879, dtype=torch.float64)
9 gae_duplicate tensor(-1.0188, dtype=torch.float64) tensor(7.6996, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.8484, dtype=torch.float64) delta_t tensor(-0.6189, dtype=torch.float64)
8 gae_duplicate tensor(-1.3374, dtype=torch.float64) tensor(12.9796, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.6250, dtype=torch.float64) delta_t tensor(-0.3987, dtype=torch.float64)
7 gae_duplicate tensor(-1.1149, dtype=torch.float64) tensor(9.1726, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.9101, dtype=torch.float64) delta_t tensor(-0.5295, dtype=torch.float64)
6 gae_duplicate tensor(-1.1054, dtype=torch.float64) tensor(11.3711, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.0510, dtype=torch.float64) delta_t tensor(0.1895, dtype=torch.float64)
5 gae_duplicate tensor(-0.3284, dtype=torch.float64) tensor(-2.6280, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.4110, dtype=torch.float64) delta_t tensor(-1.2214, dtype=torch.float64)
4 gae_duplicate tensor(-6.2898, dtype=torch.float64) tensor(23.8880, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.1179, dtype=torch.float64) delta_t tensor(0.7449, dtype=torch.float64)
3 gae_duplicate tensor(-0.3981, dtype=torch.float64) tensor(-12.2882, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.0035, dtype=torch.float64) delta_t tensor(0.3374, dtype=torch.float64)
2 gae_duplicate tensor(0.1000, dtype=torch.float64) tensor(-7.9040, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-1694.8453369140625
value loss:114.13317108154297
entropies:355.8986511230469
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.045987844467163 seconds
19 rew tensor(0.6569, dtype=torch.float64) delta_t tensor(0.0633, dtype=torch.float64)
19 gae_duplicate tensor(-0.2414, dtype=torch.float64) tensor(-1.2670, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6578, dtype=torch.float64) delta_t tensor(0.1236, dtype=torch.float64)
18 gae_duplicate tensor(-0.1761, dtype=torch.float64) tensor(-2.5369, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6588, dtype=torch.float64) delta_t tensor(0.1246, dtype=torch.float64)
17 gae_duplicate tensor(-0.1687, dtype=torch.float64) tensor(-2.7531, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6597, dtype=torch.float64) delta_t tensor(0.1255, dtype=torch.float64)
16 gae_duplicate tensor(-0.1670, dtype=torch.float64) tensor(-2.7797, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6607, dtype=torch.float64) delta_t tensor(0.1265, dtype=torch.float64)
15 gae_duplicate tensor(-0.1659, dtype=torch.float64) tensor(-2.8015, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6617, dtype=torch.float64) delta_t tensor(0.1274, dtype=torch.float64)
14 gae_duplicate tensor(-0.1649, dtype=torch.float64) tensor(-2.8160, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6626, dtype=torch.float64) delta_t tensor(0.1284, dtype=torch.float64)
13 gae_duplicate tensor(-0.1639, dtype=torch.float64) tensor(-2.8279, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6636, dtype=torch.float64) delta_t tensor(0.1293, dtype=torch.float64)
12 gae_duplicate tensor(-0.1628, dtype=torch.float64) tensor(-2.8448, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6646, dtype=torch.float64) delta_t tensor(0.3089, dtype=torch.float64)
11 gae_duplicate tensor(0.2370, dtype=torch.float64) tensor(-6.4215, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6655, dtype=torch.float64) delta_t tensor(0.9412, dtype=torch.float64)
10 gae_duplicate tensor(0.7584, dtype=torch.float64) tensor(-19.2278, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.7575, dtype=torch.float64) delta_t tensor(-0.5262, dtype=torch.float64)
9 gae_duplicate tensor(-1.9819, dtype=torch.float64) tensor(8.4674, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.7463, dtype=torch.float64) delta_t tensor(-0.5281, dtype=torch.float64)
8 gae_duplicate tensor(-1.1636, dtype=torch.float64) tensor(11.2501, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.6316, dtype=torch.float64) delta_t tensor(-0.4179, dtype=torch.float64)
7 gae_duplicate tensor(-0.7624, dtype=torch.float64) tensor(9.3967, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.6623, dtype=torch.float64) delta_t tensor(-0.3057, dtype=torch.float64)
6 gae_duplicate tensor(-1.0009, dtype=torch.float64) tensor(7.0029, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.9201, dtype=torch.float64) delta_t tensor(0.0274, dtype=torch.float64)
5 gae_duplicate tensor(-0.9049, dtype=torch.float64) tensor(0.1362, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.7694, dtype=torch.float64) delta_t tensor(-0.7607, dtype=torch.float64)
4 gae_duplicate tensor(-3.7214, dtype=torch.float64) tensor(14.8656, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.1838, dtype=torch.float64) delta_t tensor(0.6975, dtype=torch.float64)
3 gae_duplicate tensor(0.0111, dtype=torch.float64) tensor(-12.2732, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0209, dtype=torch.float64) delta_t tensor(0.3692, dtype=torch.float64)
2 gae_duplicate tensor(0.0032, dtype=torch.float64) tensor(-8.5290, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:765.7152709960938
value loss:76.49223327636719
entropies:355.90118408203125
Policy training finished
---------------------
ToM training started
ToM data loaded
batch_size =  600
ToM_loss = tensor(3951.1602)
ToM Target loss= tensor(3250.5310)
optimized based on ToM loss
---------------------
gamma: 0.1
Process Process-9:
Traceback (most recent call last):
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/suhuangyuan/DRA/ToM2C/train.py", line 453, in train
    if train_modes[rank] != -10:
  File "<string>", line 2, in __getitem__
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/managers.py", line 810, in _callmethod
    kind, result = conn.recv()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
training start after waiting for 5.145496129989624 seconds
19 rew tensor(0.6599, dtype=torch.float64) delta_t tensor(-0.2239, dtype=torch.float64)
19 gae_duplicate tensor(-0.2583, dtype=torch.float64) tensor(4.4223, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6608, dtype=torch.float64) delta_t tensor(-0.1346, dtype=torch.float64)
18 gae_duplicate tensor(-0.1917, dtype=torch.float64) tensor(3.0932, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6617, dtype=torch.float64) delta_t tensor(-0.1337, dtype=torch.float64)
17 gae_duplicate tensor(-0.1841, dtype=torch.float64) tensor(2.9537, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6627, dtype=torch.float64) delta_t tensor(-0.1328, dtype=torch.float64)
16 gae_duplicate tensor(-0.1825, dtype=torch.float64) tensor(2.9148, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6636, dtype=torch.float64) delta_t tensor(-0.1319, dtype=torch.float64)
15 gae_duplicate tensor(-0.1814, dtype=torch.float64) tensor(2.9047, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.6645, dtype=torch.float64) delta_t tensor(-0.1310, dtype=torch.float64)
14 gae_duplicate tensor(-0.1803, dtype=torch.float64) tensor(2.8714, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.6655, dtype=torch.float64) delta_t tensor(-0.1300, dtype=torch.float64)
13 gae_duplicate tensor(-0.1793, dtype=torch.float64) tensor(2.8585, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6664, dtype=torch.float64) delta_t tensor(-0.1291, dtype=torch.float64)
12 gae_duplicate tensor(-0.1783, dtype=torch.float64) tensor(2.8363, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6673, dtype=torch.float64) delta_t tensor(0.2899, dtype=torch.float64)
11 gae_duplicate tensor(0.2084, dtype=torch.float64) tensor(-5.4481, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6683, dtype=torch.float64) delta_t tensor(1.0254, dtype=torch.float64)
10 gae_duplicate tensor(0.9768, dtype=torch.float64) tensor(-20.8566, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.7507, dtype=torch.float64) delta_t tensor(-0.4690, dtype=torch.float64)
9 gae_duplicate tensor(-0.4394, dtype=torch.float64) tensor(7.2135, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.8475, dtype=torch.float64) delta_t tensor(-0.5652, dtype=torch.float64)
8 gae_duplicate tensor(-1.7010, dtype=torch.float64) tensor(11.8928, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.9870, dtype=torch.float64) delta_t tensor(-0.6952, dtype=torch.float64)
7 gae_duplicate tensor(-1.2165, dtype=torch.float64) tensor(14.9053, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.9219, dtype=torch.float64) delta_t tensor(-0.5352, dtype=torch.float64)
6 gae_duplicate tensor(-1.0228, dtype=torch.float64) tensor(12.1066, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.5704, dtype=torch.float64) delta_t tensor(0.6439, dtype=torch.float64)
5 gae_duplicate tensor(-0.4624, dtype=torch.float64) tensor(-11.5092, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.5419, dtype=torch.float64) delta_t tensor(-0.4010, dtype=torch.float64)
4 gae_duplicate tensor(-1.7277, dtype=torch.float64) tensor(6.7879, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.1794, dtype=torch.float64) delta_t tensor(0.8258, dtype=torch.float64)
3 gae_duplicate tensor(0.0387, dtype=torch.float64) tensor(-15.6558, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.0890, dtype=torch.float64) delta_t tensor(0.2709, dtype=torch.float64)
2 gae_duplicate tensor(-0.0348, dtype=torch.float64) tensor(-6.8983, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-1035.3275146484375
value loss:61.190452575683594
entropies:355.9240417480469
Policy training finished
---------------------
gamma: 0.1