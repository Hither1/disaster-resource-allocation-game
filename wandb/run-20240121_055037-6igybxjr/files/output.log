obs <crafter.objects.Shelter object at 0x15cc568e0> [39.  0.  0.  0. 39.  0.  0.  0. 13.  0.  0.  0.]
obs <crafter.objects.Warehouse object at 0x10bd86cd0> [37.  0.  0.  0. 39.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Station object at 0x15cc6e2e0> [ 9.  0.  0.  0.  9.  0.  0.  0. 12.  0.  0.  0.]
obs <crafter.objects.Shelter object at 0x15cc568e0> [39.  0.  0.  0. 39.  0.  0.  0.  7.  0.  0.  0.]
obs <crafter.objects.Warehouse object at 0x10bd86cd0> [42.  0.  0.  0. 41.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Station object at 0x15cc6e2e0> [ 9.  0.  0.  0.  9.  0.  0.  0. 14.  0.  0.  0.]
{'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0}
training start after waiting for 0.003245830535888672 seconds
19 rew tensor(1.0850, dtype=torch.float64) delta_t tensor(1.2058, dtype=torch.float64)
19 gae_duplicate tensor(1.1118, dtype=torch.float64) tensor(-23.7327, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(1.1504, dtype=torch.float64) delta_t tensor(1.2565, dtype=torch.float64)
18 gae_duplicate tensor(1.2639, dtype=torch.float64) tensor(-27.1725, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(1.2297, dtype=torch.float64) delta_t tensor(1.3370, dtype=torch.float64)
17 gae_duplicate tensor(1.3419, dtype=torch.float64) tensor(-29.1138, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(1.3288, dtype=torch.float64) delta_t tensor(1.4310, dtype=torch.float64)
16 gae_duplicate tensor(1.4308, dtype=torch.float64) tensor(-30.9296, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(1.4576, dtype=torch.float64) delta_t tensor(1.5418, dtype=torch.float64)
15 gae_duplicate tensor(1.5339, dtype=torch.float64) tensor(-33.6548, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(1.6359, dtype=torch.float64) delta_t tensor(1.7166, dtype=torch.float64)
14 gae_duplicate tensor(1.6567, dtype=torch.float64) tensor(-37.0430, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(1.7631, dtype=torch.float64) delta_t tensor(1.8433, dtype=torch.float64)
13 gae_duplicate tensor(1.8384, dtype=torch.float64) tensor(-39.4482, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(1.6164, dtype=torch.float64) delta_t tensor(1.6676, dtype=torch.float64)
12 gae_duplicate tensor(1.5416, dtype=torch.float64) tensor(-37.1445, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(1.6684, dtype=torch.float64) delta_t tensor(1.7360, dtype=torch.float64)
11 gae_duplicate tensor(1.6750, dtype=torch.float64) tensor(-37.7250, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(1.3692, dtype=torch.float64) delta_t tensor(1.4358, dtype=torch.float64)
10 gae_duplicate tensor(1.4220, dtype=torch.float64) tensor(-31.9342, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.6747, dtype=torch.float64) delta_t tensor(0.5877, dtype=torch.float64)
9 gae_duplicate tensor(0.1095, dtype=torch.float64) tensor(-14.9259, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.5928, dtype=torch.float64) delta_t tensor(0.5394, dtype=torch.float64)
8 gae_duplicate tensor(0.1572, dtype=torch.float64) tensor(-12.0522, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(0.3305, dtype=torch.float64) delta_t tensor(0.2310, dtype=torch.float64)
7 gae_duplicate tensor(-1.4877, dtype=torch.float64) tensor(-5.5650, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(0.2332, dtype=torch.float64) delta_t tensor(0.1364, dtype=torch.float64)
6 gae_duplicate tensor(-1.4272, dtype=torch.float64) tensor(-3.2608, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7518, dtype=torch.float64) delta_t tensor(-0.9555, dtype=torch.float64)
5 gae_duplicate tensor(-1.7022, dtype=torch.float64) tensor(18.4479, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-0.1451, dtype=torch.float64) delta_t tensor(-0.1439, dtype=torch.float64)
4 gae_duplicate tensor(-0.9732, dtype=torch.float64) tensor(4.5356, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-0.3549, dtype=torch.float64) delta_t tensor(-0.5514, dtype=torch.float64)
3 gae_duplicate tensor(-0.9117, dtype=torch.float64) tensor(11.3752, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.0572, dtype=torch.float64) delta_t tensor(-0.9604, dtype=torch.float64)
2 gae_duplicate tensor(-1.1349, dtype=torch.float64) tensor(20.2449, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:16595.259765625
value loss:312.44268798828125
entropies:355.7647399902344
Policy training finished
---------------------
gamma: 0.1
/Users/suhuangyuan/DRA/ToM2C/shared_optim.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1420.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
training start after waiting for 4.667651891708374 seconds
19 rew tensor(1.0433, dtype=torch.float64) delta_t tensor(1.0759, dtype=torch.float64)
19 gae_duplicate tensor(0.9977, dtype=torch.float64) tensor(-21.1336, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(1.0582, dtype=torch.float64) delta_t tensor(1.0846, dtype=torch.float64)
18 gae_duplicate tensor(1.1120, dtype=torch.float64) tensor(-24.1133, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(1.0882, dtype=torch.float64) delta_t tensor(1.1202, dtype=torch.float64)
17 gae_duplicate tensor(1.1955, dtype=torch.float64) tensor(-23.9002, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(1.1211, dtype=torch.float64) delta_t tensor(1.1351, dtype=torch.float64)
16 gae_duplicate tensor(1.2056, dtype=torch.float64) tensor(-24.8572, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(1.1296, dtype=torch.float64) delta_t tensor(1.1485, dtype=torch.float64)
15 gae_duplicate tensor(1.1793, dtype=torch.float64) tensor(-24.6329, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(1.2088, dtype=torch.float64) delta_t tensor(1.2037, dtype=torch.float64)
14 gae_duplicate tensor(1.2026, dtype=torch.float64) tensor(-26.0189, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(1.1928, dtype=torch.float64) delta_t tensor(1.2028, dtype=torch.float64)
13 gae_duplicate tensor(0.9755, dtype=torch.float64) tensor(-27.0260, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9879, dtype=torch.float64) delta_t tensor(0.9744, dtype=torch.float64)
12 gae_duplicate tensor(0.6721, dtype=torch.float64) tensor(-22.1453, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8549, dtype=torch.float64) delta_t tensor(0.8826, dtype=torch.float64)
11 gae_duplicate tensor(0.5387, dtype=torch.float64) tensor(-20.0536, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.5320, dtype=torch.float64) delta_t tensor(0.5556, dtype=torch.float64)
10 gae_duplicate tensor(0.2296, dtype=torch.float64) tensor(-12.8757, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.1004, dtype=torch.float64) delta_t tensor(-0.0287, dtype=torch.float64)
9 gae_duplicate tensor(-0.3643, dtype=torch.float64) tensor(-0.5301, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.0140, dtype=torch.float64) delta_t tensor(-0.1203, dtype=torch.float64)
8 gae_duplicate tensor(-0.3697, dtype=torch.float64) tensor(2.2523, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.5612, dtype=torch.float64) delta_t tensor(-0.7039, dtype=torch.float64)
7 gae_duplicate tensor(-3.0561, dtype=torch.float64) tensor(13.8221, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.5131, dtype=torch.float64) delta_t tensor(-0.6669, dtype=torch.float64)
6 gae_duplicate tensor(-2.0035, dtype=torch.float64) tensor(15.0131, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.2985, dtype=torch.float64) delta_t tensor(-1.5483, dtype=torch.float64)
5 gae_duplicate tensor(-3.0685, dtype=torch.float64) tensor(32.4879, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-0.8913, dtype=torch.float64) delta_t tensor(-1.1296, dtype=torch.float64)
4 gae_duplicate tensor(-1.5574, dtype=torch.float64) tensor(25.5374, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.2005, dtype=torch.float64) delta_t tensor(-1.2944, dtype=torch.float64)
3 gae_duplicate tensor(-1.6863, dtype=torch.float64) tensor(28.6689, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.2168, dtype=torch.float64) delta_t tensor(-1.2210, dtype=torch.float64)
2 gae_duplicate tensor(-1.8825, dtype=torch.float64) tensor(27.2723, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:4344.65576171875
value loss:230.55250549316406
entropies:355.2334899902344
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.0494279861450195 seconds
19 rew tensor(1.0176, dtype=torch.float64) delta_t tensor(0.8679, dtype=torch.float64)
19 gae_duplicate tensor(0.7532, dtype=torch.float64) tensor(-16.8746, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(1.0354, dtype=torch.float64) delta_t tensor(0.8875, dtype=torch.float64)
18 gae_duplicate tensor(0.8630, dtype=torch.float64) tensor(-20.1767, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(1.0542, dtype=torch.float64) delta_t tensor(0.9073, dtype=torch.float64)
17 gae_duplicate tensor(0.8900, dtype=torch.float64) tensor(-18.8498, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(1.0740, dtype=torch.float64) delta_t tensor(0.9205, dtype=torch.float64)
16 gae_duplicate tensor(0.8838, dtype=torch.float64) tensor(-19.7662, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(1.0950, dtype=torch.float64) delta_t tensor(0.9549, dtype=torch.float64)
15 gae_duplicate tensor(0.9239, dtype=torch.float64) tensor(-20.7651, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(1.1173, dtype=torch.float64) delta_t tensor(0.9741, dtype=torch.float64)
14 gae_duplicate tensor(0.9873, dtype=torch.float64) tensor(-20.8167, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(1.0896, dtype=torch.float64) delta_t tensor(0.9614, dtype=torch.float64)
13 gae_duplicate tensor(0.7187, dtype=torch.float64) tensor(-20.5778, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9626, dtype=torch.float64) delta_t tensor(0.8147, dtype=torch.float64)
12 gae_duplicate tensor(0.5842, dtype=torch.float64) tensor(-18.2023, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.7481, dtype=torch.float64) delta_t tensor(0.6691, dtype=torch.float64)
11 gae_duplicate tensor(0.1895, dtype=torch.float64) tensor(-14.7884, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.5624, dtype=torch.float64) delta_t tensor(0.4723, dtype=torch.float64)
10 gae_duplicate tensor(0.1325, dtype=torch.float64) tensor(-10.8443, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.1222, dtype=torch.float64) delta_t tensor(-0.0889, dtype=torch.float64)
9 gae_duplicate tensor(-0.3711, dtype=torch.float64) tensor(0.7675, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.2325, dtype=torch.float64) delta_t tensor(-0.4662, dtype=torch.float64)
8 gae_duplicate tensor(-1.2414, dtype=torch.float64) tensor(9.7060, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.2545, dtype=torch.float64) delta_t tensor(-0.5287, dtype=torch.float64)
7 gae_duplicate tensor(-1.6560, dtype=torch.float64) tensor(10.7028, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.6866, dtype=torch.float64) delta_t tensor(-0.9021, dtype=torch.float64)
6 gae_duplicate tensor(-3.7076, dtype=torch.float64) tensor(18.2769, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.8132, dtype=torch.float64) delta_t tensor(-1.1719, dtype=torch.float64)
5 gae_duplicate tensor(-1.6508, dtype=torch.float64) tensor(24.9689, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.0635, dtype=torch.float64) delta_t tensor(-1.2941, dtype=torch.float64)
4 gae_duplicate tensor(-1.8978, dtype=torch.float64) tensor(27.6209, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.2184, dtype=torch.float64) delta_t tensor(-1.3229, dtype=torch.float64)
3 gae_duplicate tensor(-1.8442, dtype=torch.float64) tensor(29.0842, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.2500, dtype=torch.float64) delta_t tensor(-1.3756, dtype=torch.float64)
2 gae_duplicate tensor(-1.7716, dtype=torch.float64) tensor(30.4103, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:1531.0611572265625
value loss:191.69326782226562
entropies:354.3039245605469
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.021527051925659 seconds
19 rew tensor(0.9800, dtype=torch.float64) delta_t tensor(0.6655, dtype=torch.float64)
19 gae_duplicate tensor(0.5585, dtype=torch.float64) tensor(-13.7761, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.9825, dtype=torch.float64) delta_t tensor(0.6677, dtype=torch.float64)
18 gae_duplicate tensor(0.5946, dtype=torch.float64) tensor(-14.2517, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9951, dtype=torch.float64) delta_t tensor(0.6825, dtype=torch.float64)
17 gae_duplicate tensor(0.6181, dtype=torch.float64) tensor(-14.9604, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(1.0082, dtype=torch.float64) delta_t tensor(0.7278, dtype=torch.float64)
16 gae_duplicate tensor(0.6504, dtype=torch.float64) tensor(-15.5830, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(1.0120, dtype=torch.float64) delta_t tensor(0.7352, dtype=torch.float64)
15 gae_duplicate tensor(0.5915, dtype=torch.float64) tensor(-16.2632, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(1.0455, dtype=torch.float64) delta_t tensor(0.7691, dtype=torch.float64)
14 gae_duplicate tensor(0.7295, dtype=torch.float64) tensor(-16.3029, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(1.0508, dtype=torch.float64) delta_t tensor(0.7988, dtype=torch.float64)
13 gae_duplicate tensor(0.7652, dtype=torch.float64) tensor(-17.5042, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8816, dtype=torch.float64) delta_t tensor(0.5898, dtype=torch.float64)
12 gae_duplicate tensor(0.2821, dtype=torch.float64) tensor(-13.1203, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8015, dtype=torch.float64) delta_t tensor(0.5833, dtype=torch.float64)
11 gae_duplicate tensor(0.1910, dtype=torch.float64) tensor(-13.6636, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.7445, dtype=torch.float64) delta_t tensor(0.5327, dtype=torch.float64)
10 gae_duplicate tensor(-0.0529, dtype=torch.float64) tensor(-11.9164, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.2076, dtype=torch.float64) delta_t tensor(-0.1090, dtype=torch.float64)
9 gae_duplicate tensor(-0.2846, dtype=torch.float64) tensor(0.9781, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.0035, dtype=torch.float64) delta_t tensor(-0.3456, dtype=torch.float64)
8 gae_duplicate tensor(-0.7250, dtype=torch.float64) tensor(6.9415, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.6404, dtype=torch.float64) delta_t tensor(-0.9879, dtype=torch.float64)
7 gae_duplicate tensor(-3.9522, dtype=torch.float64) tensor(18.7950, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.5053, dtype=torch.float64) delta_t tensor(-0.8057, dtype=torch.float64)
6 gae_duplicate tensor(-2.6744, dtype=torch.float64) tensor(18.0030, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.3844, dtype=torch.float64) delta_t tensor(-1.7608, dtype=torch.float64)
5 gae_duplicate tensor(-4.8674, dtype=torch.float64) tensor(37.5062, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.2439, dtype=torch.float64) delta_t tensor(-1.5125, dtype=torch.float64)
4 gae_duplicate tensor(-3.0570, dtype=torch.float64) tensor(32.1164, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.3241, dtype=torch.float64) delta_t tensor(-1.4275, dtype=torch.float64)
3 gae_duplicate tensor(-1.7555, dtype=torch.float64) tensor(31.2201, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.1226, dtype=torch.float64) delta_t tensor(-1.3491, dtype=torch.float64)
2 gae_duplicate tensor(-2.0976, dtype=torch.float64) tensor(28.6880, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-1548.1612548828125
value loss:216.75982666015625
entropies:352.6272888183594
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.753675937652588 seconds
19 rew tensor(0.9777, dtype=torch.float64) delta_t tensor(0.5191, dtype=torch.float64)
19 gae_duplicate tensor(0.4238, dtype=torch.float64) tensor(-10.2798, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.9875, dtype=torch.float64) delta_t tensor(0.5500, dtype=torch.float64)
18 gae_duplicate tensor(0.5340, dtype=torch.float64) tensor(-11.6824, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9975, dtype=torch.float64) delta_t tensor(0.5523, dtype=torch.float64)
17 gae_duplicate tensor(0.5539, dtype=torch.float64) tensor(-12.1526, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(1.0078, dtype=torch.float64) delta_t tensor(0.5569, dtype=torch.float64)
16 gae_duplicate tensor(0.5656, dtype=torch.float64) tensor(-12.3431, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(1.0185, dtype=torch.float64) delta_t tensor(0.5615, dtype=torch.float64)
15 gae_duplicate tensor(0.5060, dtype=torch.float64) tensor(-12.7166, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(1.0295, dtype=torch.float64) delta_t tensor(0.6148, dtype=torch.float64)
14 gae_duplicate tensor(0.5715, dtype=torch.float64) tensor(-13.6715, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(1.0409, dtype=torch.float64) delta_t tensor(0.6787, dtype=torch.float64)
13 gae_duplicate tensor(0.6749, dtype=torch.float64) tensor(-13.8899, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.7475, dtype=torch.float64) delta_t tensor(0.3842, dtype=torch.float64)
12 gae_duplicate tensor(0.0758, dtype=torch.float64) tensor(-8.6177, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.5425, dtype=torch.float64) delta_t tensor(0.2413, dtype=torch.float64)
11 gae_duplicate tensor(-0.1885, dtype=torch.float64) tensor(-5.9330, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.3533, dtype=torch.float64) delta_t tensor(0.0932, dtype=torch.float64)
10 gae_duplicate tensor(-0.3478, dtype=torch.float64) tensor(-2.4675, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.2937, dtype=torch.float64) delta_t tensor(-0.7157, dtype=torch.float64)
9 gae_duplicate tensor(-0.8909, dtype=torch.float64) tensor(14.2523, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.3863, dtype=torch.float64) delta_t tensor(-0.8197, dtype=torch.float64)
8 gae_duplicate tensor(-1.0460, dtype=torch.float64) tensor(16.6697, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.3205, dtype=torch.float64) delta_t tensor(-0.7636, dtype=torch.float64)
7 gae_duplicate tensor(-1.0138, dtype=torch.float64) tensor(16.1655, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.8341, dtype=torch.float64) delta_t tensor(-1.1987, dtype=torch.float64)
6 gae_duplicate tensor(-4.5229, dtype=torch.float64) tensor(27.2336, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.1114, dtype=torch.float64) delta_t tensor(-1.5076, dtype=torch.float64)
5 gae_duplicate tensor(-2.7816, dtype=torch.float64) tensor(33.1621, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.3789, dtype=torch.float64) delta_t tensor(-1.7529, dtype=torch.float64)
4 gae_duplicate tensor(-3.8781, dtype=torch.float64) tensor(36.9259, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.2519, dtype=torch.float64) delta_t tensor(-1.4051, dtype=torch.float64)
3 gae_duplicate tensor(-1.9161, dtype=torch.float64) tensor(32.3436, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.1302, dtype=torch.float64) delta_t tensor(-1.4495, dtype=torch.float64)
2 gae_duplicate tensor(-1.8962, dtype=torch.float64) tensor(30.1109, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-5662.87255859375
value loss:201.583740234375
entropies:351.7149353027344
Policy training finished
---------------------
ToM training started
ToM data loaded
batch_size =  600
ToM_loss = tensor(3995.3279)
ToM Target loss= tensor(3386.0208)
optimized based on ToM loss
---------------------
gamma: 0.1
training start after waiting for 4.870445966720581 seconds
19 rew tensor(0.9529, dtype=torch.float64) delta_t tensor(0.3550, dtype=torch.float64)
19 gae_duplicate tensor(0.2671, dtype=torch.float64) tensor(-6.5902, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.9606, dtype=torch.float64) delta_t tensor(0.4072, dtype=torch.float64)
18 gae_duplicate tensor(0.2597, dtype=torch.float64) tensor(-8.6801, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9685, dtype=torch.float64) delta_t tensor(0.4102, dtype=torch.float64)
17 gae_duplicate tensor(0.2733, dtype=torch.float64) tensor(-9.9989, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9766, dtype=torch.float64) delta_t tensor(0.4164, dtype=torch.float64)
16 gae_duplicate tensor(0.3022, dtype=torch.float64) tensor(-8.6483, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9849, dtype=torch.float64) delta_t tensor(0.4378, dtype=torch.float64)
15 gae_duplicate tensor(0.4370, dtype=torch.float64) tensor(-8.6281, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9934, dtype=torch.float64) delta_t tensor(0.4694, dtype=torch.float64)
14 gae_duplicate tensor(0.3111, dtype=torch.float64) tensor(-9.6318, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(1.0022, dtype=torch.float64) delta_t tensor(0.5302, dtype=torch.float64)
13 gae_duplicate tensor(0.4718, dtype=torch.float64) tensor(-11.4262, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6709, dtype=torch.float64) delta_t tensor(0.2368, dtype=torch.float64)
12 gae_duplicate tensor(-0.2773, dtype=torch.float64) tensor(-5.7724, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.5757, dtype=torch.float64) delta_t tensor(0.2654, dtype=torch.float64)
11 gae_duplicate tensor(-0.3327, dtype=torch.float64) tensor(-4.9706, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.4638, dtype=torch.float64) delta_t tensor(0.1257, dtype=torch.float64)
10 gae_duplicate tensor(-0.2453, dtype=torch.float64) tensor(-2.9007, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.0522, dtype=torch.float64) delta_t tensor(-0.4538, dtype=torch.float64)
9 gae_duplicate tensor(-0.7468, dtype=torch.float64) tensor(8.7625, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.1605, dtype=torch.float64) delta_t tensor(-0.6605, dtype=torch.float64)
8 gae_duplicate tensor(-1.4309, dtype=torch.float64) tensor(13.5472, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.4081, dtype=torch.float64) delta_t tensor(-0.9041, dtype=torch.float64)
7 gae_duplicate tensor(-2.7488, dtype=torch.float64) tensor(19.2795, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.6194, dtype=torch.float64) delta_t tensor(-0.9961, dtype=torch.float64)
6 gae_duplicate tensor(-2.4893, dtype=torch.float64) tensor(20.7724, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.0515, dtype=torch.float64) delta_t tensor(-1.4017, dtype=torch.float64)
5 gae_duplicate tensor(-2.0376, dtype=torch.float64) tensor(30.3095, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.9277, dtype=torch.float64) delta_t tensor(-2.3402, dtype=torch.float64)
4 gae_duplicate tensor(-7.1163, dtype=torch.float64) tensor(47.7015, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.3579, dtype=torch.float64) delta_t tensor(-1.5788, dtype=torch.float64)
3 gae_duplicate tensor(-2.3959, dtype=torch.float64) tensor(35.4889, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.9875, dtype=torch.float64) delta_t tensor(-1.3822, dtype=torch.float64)
2 gae_duplicate tensor(-1.7813, dtype=torch.float64) tensor(28.6256, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-6965.76953125
value loss:228.8670196533203
entropies:351.1776428222656
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.967928886413574 seconds
19 rew tensor(0.9588, dtype=torch.float64) delta_t tensor(0.2994, dtype=torch.float64)
19 gae_duplicate tensor(0.1344, dtype=torch.float64) tensor(-6.0912, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.9654, dtype=torch.float64) delta_t tensor(0.3554, dtype=torch.float64)
18 gae_duplicate tensor(0.2508, dtype=torch.float64) tensor(-7.4243, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9722, dtype=torch.float64) delta_t tensor(0.3650, dtype=torch.float64)
17 gae_duplicate tensor(0.2657, dtype=torch.float64) tensor(-7.1935, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9792, dtype=torch.float64) delta_t tensor(0.3386, dtype=torch.float64)
16 gae_duplicate tensor(0.2847, dtype=torch.float64) tensor(-7.0330, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9863, dtype=torch.float64) delta_t tensor(0.4049, dtype=torch.float64)
15 gae_duplicate tensor(0.2913, dtype=torch.float64) tensor(-7.9382, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9936, dtype=torch.float64) delta_t tensor(0.4151, dtype=torch.float64)
14 gae_duplicate tensor(0.2978, dtype=torch.float64) tensor(-8.7914, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9180, dtype=torch.float64) delta_t tensor(0.4325, dtype=torch.float64)
13 gae_duplicate tensor(0.0665, dtype=torch.float64) tensor(-8.7500, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.7016, dtype=torch.float64) delta_t tensor(0.1960, dtype=torch.float64)
12 gae_duplicate tensor(-0.1024, dtype=torch.float64) tensor(-4.8302, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.3915, dtype=torch.float64) delta_t tensor(0.0116, dtype=torch.float64)
11 gae_duplicate tensor(-0.4387, dtype=torch.float64) tensor(-0.5368, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.3027, dtype=torch.float64) delta_t tensor(-0.0122, dtype=torch.float64)
10 gae_duplicate tensor(-0.3982, dtype=torch.float64) tensor(0.1358, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.2513, dtype=torch.float64) delta_t tensor(-0.7855, dtype=torch.float64)
9 gae_duplicate tensor(-1.0745, dtype=torch.float64) tensor(15.1629, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.5540, dtype=torch.float64) delta_t tensor(-1.0786, dtype=torch.float64)
8 gae_duplicate tensor(-2.2567, dtype=torch.float64) tensor(22.1048, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.5241, dtype=torch.float64) delta_t tensor(-1.0299, dtype=torch.float64)
7 gae_duplicate tensor(-2.3599, dtype=torch.float64) tensor(24.3099, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-1.7450, dtype=torch.float64) delta_t tensor(-2.1497, dtype=torch.float64)
6 gae_duplicate tensor(-3.9784, dtype=torch.float64) tensor(43.4708, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.0611, dtype=torch.float64) delta_t tensor(-1.4841, dtype=torch.float64)
5 gae_duplicate tensor(-2.2697, dtype=torch.float64) tensor(32.6015, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.0792, dtype=torch.float64) delta_t tensor(-1.3596, dtype=torch.float64)
4 gae_duplicate tensor(-2.0566, dtype=torch.float64) tensor(30.1867, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.2011, dtype=torch.float64) delta_t tensor(-1.3316, dtype=torch.float64)
3 gae_duplicate tensor(-1.8406, dtype=torch.float64) tensor(29.4304, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.2491, dtype=torch.float64) delta_t tensor(-1.6912, dtype=torch.float64)
2 gae_duplicate tensor(-2.3644, dtype=torch.float64) tensor(33.9644, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-9424.798828125
value loss:215.94361877441406
entropies:350.94671630859375
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.5666117668151855 seconds
19 rew tensor(0.9544, dtype=torch.float64) delta_t tensor(0.2287, dtype=torch.float64)
19 gae_duplicate tensor(0.0841, dtype=torch.float64) tensor(-4.1784, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.9602, dtype=torch.float64) delta_t tensor(0.2673, dtype=torch.float64)
18 gae_duplicate tensor(0.1780, dtype=torch.float64) tensor(-5.5558, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9660, dtype=torch.float64) delta_t tensor(0.2679, dtype=torch.float64)
17 gae_duplicate tensor(0.1924, dtype=torch.float64) tensor(-5.4423, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9720, dtype=torch.float64) delta_t tensor(0.2696, dtype=torch.float64)
16 gae_duplicate tensor(0.1957, dtype=torch.float64) tensor(-5.6863, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9781, dtype=torch.float64) delta_t tensor(0.3124, dtype=torch.float64)
15 gae_duplicate tensor(0.1860, dtype=torch.float64) tensor(-6.6249, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9844, dtype=torch.float64) delta_t tensor(0.3742, dtype=torch.float64)
14 gae_duplicate tensor(0.2253, dtype=torch.float64) tensor(-8.1783, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9907, dtype=torch.float64) delta_t tensor(0.4653, dtype=torch.float64)
13 gae_duplicate tensor(0.3959, dtype=torch.float64) tensor(-9.1034, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6501, dtype=torch.float64) delta_t tensor(0.1708, dtype=torch.float64)
12 gae_duplicate tensor(-0.0438, dtype=torch.float64) tensor(-4.0869, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.3983, dtype=torch.float64) delta_t tensor(-0.0056, dtype=torch.float64)
11 gae_duplicate tensor(-0.2912, dtype=torch.float64) tensor(0.0397, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.1625, dtype=torch.float64) delta_t tensor(-0.1932, dtype=torch.float64)
10 gae_duplicate tensor(-0.4214, dtype=torch.float64) tensor(3.5330, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.1191, dtype=torch.float64) delta_t tensor(-0.6514, dtype=torch.float64)
9 gae_duplicate tensor(-0.9312, dtype=torch.float64) tensor(13.6433, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.2816, dtype=torch.float64) delta_t tensor(-0.8114, dtype=torch.float64)
8 gae_duplicate tensor(-1.3587, dtype=torch.float64) tensor(18.0980, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.8196, dtype=torch.float64) delta_t tensor(-1.3232, dtype=torch.float64)
7 gae_duplicate tensor(-3.7640, dtype=torch.float64) tensor(28.1933, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-1.2700, dtype=torch.float64) delta_t tensor(-1.6602, dtype=torch.float64)
6 gae_duplicate tensor(-3.9462, dtype=torch.float64) tensor(34.3253, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.2205, dtype=torch.float64) delta_t tensor(-1.6199, dtype=torch.float64)
5 gae_duplicate tensor(-3.5547, dtype=torch.float64) tensor(37.0728, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.6451, dtype=torch.float64) delta_t tensor(-1.8309, dtype=torch.float64)
4 gae_duplicate tensor(-5.1773, dtype=torch.float64) tensor(41.2294, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.1167, dtype=torch.float64) delta_t tensor(-1.3317, dtype=torch.float64)
3 gae_duplicate tensor(-1.9980, dtype=torch.float64) tensor(30.6579, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.2541, dtype=torch.float64) delta_t tensor(-1.8036, dtype=torch.float64)
2 gae_duplicate tensor(-2.4065, dtype=torch.float64) tensor(37.7492, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-10661.65234375
value loss:246.6250457763672
entropies:350.4934997558594
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.0692458152771 seconds
19 rew tensor(0.9591, dtype=torch.float64) delta_t tensor(0.1876, dtype=torch.float64)
19 gae_duplicate tensor(0.0759, dtype=torch.float64) tensor(-3.3819, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.9642, dtype=torch.float64) delta_t tensor(0.2429, dtype=torch.float64)
18 gae_duplicate tensor(0.1834, dtype=torch.float64) tensor(-4.9175, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9695, dtype=torch.float64) delta_t tensor(0.2902, dtype=torch.float64)
17 gae_duplicate tensor(0.2135, dtype=torch.float64) tensor(-6.0281, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9749, dtype=torch.float64) delta_t tensor(0.2593, dtype=torch.float64)
16 gae_duplicate tensor(0.2196, dtype=torch.float64) tensor(-5.1311, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9803, dtype=torch.float64) delta_t tensor(0.3012, dtype=torch.float64)
15 gae_duplicate tensor(0.2471, dtype=torch.float64) tensor(-6.1369, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9858, dtype=torch.float64) delta_t tensor(0.3473, dtype=torch.float64)
14 gae_duplicate tensor(0.2539, dtype=torch.float64) tensor(-7.0849, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9915, dtype=torch.float64) delta_t tensor(0.4490, dtype=torch.float64)
13 gae_duplicate tensor(0.2719, dtype=torch.float64) tensor(-8.5798, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.7026, dtype=torch.float64) delta_t tensor(0.2066, dtype=torch.float64)
12 gae_duplicate tensor(0.0621, dtype=torch.float64) tensor(-4.9680, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.4817, dtype=torch.float64) delta_t tensor(0.0849, dtype=torch.float64)
11 gae_duplicate tensor(-0.4328, dtype=torch.float64) tensor(-2.4243, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.3395, dtype=torch.float64) delta_t tensor(-0.0427, dtype=torch.float64)
10 gae_duplicate tensor(-0.3482, dtype=torch.float64) tensor(0.6686, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.0263, dtype=torch.float64) delta_t tensor(-0.5585, dtype=torch.float64)
9 gae_duplicate tensor(-0.8803, dtype=torch.float64) tensor(12.0635, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.1499, dtype=torch.float64) delta_t tensor(-0.6750, dtype=torch.float64)
8 gae_duplicate tensor(-1.0724, dtype=torch.float64) tensor(14.5837, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.2365, dtype=torch.float64) delta_t tensor(-0.7282, dtype=torch.float64)
7 gae_duplicate tensor(-1.1850, dtype=torch.float64) tensor(14.8397, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.5167, dtype=torch.float64) delta_t tensor(-0.8834, dtype=torch.float64)
6 gae_duplicate tensor(-3.0562, dtype=torch.float64) tensor(19.1174, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7212, dtype=torch.float64) delta_t tensor(-1.0347, dtype=torch.float64)
5 gae_duplicate tensor(-1.5252, dtype=torch.float64) tensor(21.3138, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-0.8896, dtype=torch.float64) delta_t tensor(-1.0747, dtype=torch.float64)
4 gae_duplicate tensor(-1.6243, dtype=torch.float64) tensor(22.1066, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.1228, dtype=torch.float64) delta_t tensor(-1.2774, dtype=torch.float64)
3 gae_duplicate tensor(-1.7883, dtype=torch.float64) tensor(25.9771, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.1271, dtype=torch.float64) delta_t tensor(-1.5603, dtype=torch.float64)
2 gae_duplicate tensor(-2.1123, dtype=torch.float64) tensor(35.1962, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-6423.908203125
value loss:112.74313354492188
entropies:349.42864990234375
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.669690132141113 seconds
19 rew tensor(0.9562, dtype=torch.float64) delta_t tensor(0.2191, dtype=torch.float64)
19 gae_duplicate tensor(0.1422, dtype=torch.float64) tensor(-4.1878, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.9608, dtype=torch.float64) delta_t tensor(0.2677, dtype=torch.float64)
18 gae_duplicate tensor(0.2123, dtype=torch.float64) tensor(-5.3087, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9655, dtype=torch.float64) delta_t tensor(0.2663, dtype=torch.float64)
17 gae_duplicate tensor(0.1879, dtype=torch.float64) tensor(-5.7908, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9703, dtype=torch.float64) delta_t tensor(0.2712, dtype=torch.float64)
16 gae_duplicate tensor(0.1668, dtype=torch.float64) tensor(-5.4234, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9752, dtype=torch.float64) delta_t tensor(0.3296, dtype=torch.float64)
15 gae_duplicate tensor(0.2925, dtype=torch.float64) tensor(-6.5528, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9801, dtype=torch.float64) delta_t tensor(0.3479, dtype=torch.float64)
14 gae_duplicate tensor(0.2750, dtype=torch.float64) tensor(-8.1360, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9851, dtype=torch.float64) delta_t tensor(0.4265, dtype=torch.float64)
13 gae_duplicate tensor(0.3180, dtype=torch.float64) tensor(-8.5836, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8939, dtype=torch.float64) delta_t tensor(0.3686, dtype=torch.float64)
12 gae_duplicate tensor(-0.0004, dtype=torch.float64) tensor(-7.9436, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.6365, dtype=torch.float64) delta_t tensor(0.2967, dtype=torch.float64)
11 gae_duplicate tensor(-0.1247, dtype=torch.float64) tensor(-7.3018, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.5336, dtype=torch.float64) delta_t tensor(0.2055, dtype=torch.float64)
10 gae_duplicate tensor(-0.1251, dtype=torch.float64) tensor(-4.7436, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.0054, dtype=torch.float64) delta_t tensor(-0.5214, dtype=torch.float64)
9 gae_duplicate tensor(-0.6767, dtype=torch.float64) tensor(8.8430, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.0819, dtype=torch.float64) delta_t tensor(-0.5653, dtype=torch.float64)
8 gae_duplicate tensor(-0.8575, dtype=torch.float64) tensor(12.0117, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.2720, dtype=torch.float64) delta_t tensor(-0.6943, dtype=torch.float64)
7 gae_duplicate tensor(-1.8767, dtype=torch.float64) tensor(14.6552, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.9991, dtype=torch.float64) delta_t tensor(-1.2724, dtype=torch.float64)
6 gae_duplicate tensor(-2.9131, dtype=torch.float64) tensor(25.9900, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.4902, dtype=torch.float64) delta_t tensor(-1.6970, dtype=torch.float64)
5 gae_duplicate tensor(-3.3413, dtype=torch.float64) tensor(37.0595, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.4048, dtype=torch.float64) delta_t tensor(-1.4743, dtype=torch.float64)
4 gae_duplicate tensor(-3.6265, dtype=torch.float64) tensor(30.3234, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.2067, dtype=torch.float64) delta_t tensor(-1.3272, dtype=torch.float64)
3 gae_duplicate tensor(-1.6792, dtype=torch.float64) tensor(29.9439, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.1289, dtype=torch.float64) delta_t tensor(-1.5207, dtype=torch.float64)
2 gae_duplicate tensor(-2.0748, dtype=torch.float64) tensor(33.0313, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-6999.99560546875
value loss:167.40921020507812
entropies:348.6871032714844
Policy training finished
---------------------
ToM training started
ToM data loaded
batch_size =  600
ToM_loss = tensor(3943.7424)
ToM Target loss= tensor(3324.7739)
optimized based on ToM loss
---------------------
gamma: 0.1
training start after waiting for 4.666810989379883 seconds
19 rew tensor(0.9608, dtype=torch.float64) delta_t tensor(0.2463, dtype=torch.float64)
19 gae_duplicate tensor(0.0970, dtype=torch.float64) tensor(-3.9489, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.9651, dtype=torch.float64) delta_t tensor(0.2979, dtype=torch.float64)
18 gae_duplicate tensor(0.1871, dtype=torch.float64) tensor(-6.5515, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9694, dtype=torch.float64) delta_t tensor(0.2948, dtype=torch.float64)
17 gae_duplicate tensor(0.1996, dtype=torch.float64) tensor(-6.1359, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9737, dtype=torch.float64) delta_t tensor(0.3015, dtype=torch.float64)
16 gae_duplicate tensor(0.2039, dtype=torch.float64) tensor(-6.3504, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9782, dtype=torch.float64) delta_t tensor(0.3537, dtype=torch.float64)
15 gae_duplicate tensor(0.2598, dtype=torch.float64) tensor(-7.8482, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9826, dtype=torch.float64) delta_t tensor(0.4562, dtype=torch.float64)
14 gae_duplicate tensor(0.3521, dtype=torch.float64) tensor(-9.5269, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8945, dtype=torch.float64) delta_t tensor(0.4774, dtype=torch.float64)
13 gae_duplicate tensor(0.2609, dtype=torch.float64) tensor(-9.7152, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.5190, dtype=torch.float64) delta_t tensor(0.1265, dtype=torch.float64)
12 gae_duplicate tensor(-0.1019, dtype=torch.float64) tensor(-3.6230, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.2981, dtype=torch.float64) delta_t tensor(-0.0251, dtype=torch.float64)
11 gae_duplicate tensor(-0.2620, dtype=torch.float64) tensor(0.0889, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.1370, dtype=torch.float64) delta_t tensor(-0.0883, dtype=torch.float64)
10 gae_duplicate tensor(-0.3439, dtype=torch.float64) tensor(1.8817, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.1233, dtype=torch.float64) delta_t tensor(-0.5652, dtype=torch.float64)
9 gae_duplicate tensor(-1.0578, dtype=torch.float64) tensor(11.1524, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.2915, dtype=torch.float64) delta_t tensor(-0.7251, dtype=torch.float64)
8 gae_duplicate tensor(-0.9296, dtype=torch.float64) tensor(14.7790, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-1.0711, dtype=torch.float64) delta_t tensor(-1.4432, dtype=torch.float64)
7 gae_duplicate tensor(-4.3590, dtype=torch.float64) tensor(29.0183, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.9797, dtype=torch.float64) delta_t tensor(-1.2018, dtype=torch.float64)
6 gae_duplicate tensor(-3.3097, dtype=torch.float64) tensor(27.4254, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.0601, dtype=torch.float64) delta_t tensor(-1.2372, dtype=torch.float64)
5 gae_duplicate tensor(-2.3886, dtype=torch.float64) tensor(26.4701, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-0.9127, dtype=torch.float64) delta_t tensor(-0.8899, dtype=torch.float64)
4 gae_duplicate tensor(-1.1352, dtype=torch.float64) tensor(20.5688, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.1742, dtype=torch.float64) delta_t tensor(-1.2473, dtype=torch.float64)
3 gae_duplicate tensor(-1.8175, dtype=torch.float64) tensor(26.7533, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.2517, dtype=torch.float64) delta_t tensor(-1.6731, dtype=torch.float64)
2 gae_duplicate tensor(-2.2589, dtype=torch.float64) tensor(32.1185, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-7468.0966796875
value loss:164.94117736816406
entropies:348.3235778808594
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.710264682769775 seconds
19 rew tensor(0.9690, dtype=torch.float64) delta_t tensor(0.3953, dtype=torch.float64)
19 gae_duplicate tensor(0.2985, dtype=torch.float64) tensor(-7.3794, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.9730, dtype=torch.float64) delta_t tensor(0.4115, dtype=torch.float64)
18 gae_duplicate tensor(0.3454, dtype=torch.float64) tensor(-8.9649, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9770, dtype=torch.float64) delta_t tensor(0.3912, dtype=torch.float64)
17 gae_duplicate tensor(0.3441, dtype=torch.float64) tensor(-8.4029, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9811, dtype=torch.float64) delta_t tensor(0.3871, dtype=torch.float64)
16 gae_duplicate tensor(0.3524, dtype=torch.float64) tensor(-8.1811, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9852, dtype=torch.float64) delta_t tensor(0.4370, dtype=torch.float64)
15 gae_duplicate tensor(0.3312, dtype=torch.float64) tensor(-8.8242, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9893, dtype=torch.float64) delta_t tensor(0.5189, dtype=torch.float64)
14 gae_duplicate tensor(0.4036, dtype=torch.float64) tensor(-11.0748, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9541, dtype=torch.float64) delta_t tensor(0.5753, dtype=torch.float64)
13 gae_duplicate tensor(0.5710, dtype=torch.float64) tensor(-12.9097, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6206, dtype=torch.float64) delta_t tensor(0.2642, dtype=torch.float64)
12 gae_duplicate tensor(-0.0195, dtype=torch.float64) tensor(-6.5626, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.3884, dtype=torch.float64) delta_t tensor(0.1582, dtype=torch.float64)
11 gae_duplicate tensor(-0.2384, dtype=torch.float64) tensor(-3.1127, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.2212, dtype=torch.float64) delta_t tensor(0.0871, dtype=torch.float64)
10 gae_duplicate tensor(-0.2889, dtype=torch.float64) tensor(-1.5761, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.3197, dtype=torch.float64) delta_t tensor(-0.6724, dtype=torch.float64)
9 gae_duplicate tensor(-1.1474, dtype=torch.float64) tensor(11.9290, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.3749, dtype=torch.float64) delta_t tensor(-0.7069, dtype=torch.float64)
8 gae_duplicate tensor(-0.9899, dtype=torch.float64) tensor(14.8156, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.5773, dtype=torch.float64) delta_t tensor(-0.8371, dtype=torch.float64)
7 gae_duplicate tensor(-1.8908, dtype=torch.float64) tensor(18.1215, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.1030, dtype=torch.float64) delta_t tensor(-0.2414, dtype=torch.float64)
6 gae_duplicate tensor(-0.6828, dtype=torch.float64) tensor(7.0007, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7958, dtype=torch.float64) delta_t tensor(-0.8126, dtype=torch.float64)
5 gae_duplicate tensor(-1.1545, dtype=torch.float64) tensor(16.4106, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-0.9566, dtype=torch.float64) delta_t tensor(-0.8418, dtype=torch.float64)
4 gae_duplicate tensor(-1.2873, dtype=torch.float64) tensor(18.1141, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.2892, dtype=torch.float64) delta_t tensor(-1.1998, dtype=torch.float64)
3 gae_duplicate tensor(-1.5004, dtype=torch.float64) tensor(24.8964, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.1282, dtype=torch.float64) delta_t tensor(-1.3307, dtype=torch.float64)
2 gae_duplicate tensor(-2.1482, dtype=torch.float64) tensor(29.3325, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-3530.0986328125
value loss:92.21884155273438
entropies:348.01409912109375
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.571045160293579 seconds
19 rew tensor(0.9734, dtype=torch.float64) delta_t tensor(0.3349, dtype=torch.float64)
19 gae_duplicate tensor(0.2300, dtype=torch.float64) tensor(-6.0664, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.9771, dtype=torch.float64) delta_t tensor(0.4006, dtype=torch.float64)
18 gae_duplicate tensor(0.3332, dtype=torch.float64) tensor(-8.4143, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9808, dtype=torch.float64) delta_t tensor(0.4069, dtype=torch.float64)
17 gae_duplicate tensor(0.3590, dtype=torch.float64) tensor(-8.9979, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9846, dtype=torch.float64) delta_t tensor(0.4116, dtype=torch.float64)
16 gae_duplicate tensor(0.3634, dtype=torch.float64) tensor(-9.0276, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9884, dtype=torch.float64) delta_t tensor(0.4193, dtype=torch.float64)
15 gae_duplicate tensor(0.3670, dtype=torch.float64) tensor(-9.3248, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9922, dtype=torch.float64) delta_t tensor(0.4938, dtype=torch.float64)
14 gae_duplicate tensor(0.3782, dtype=torch.float64) tensor(-12.0693, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9961, dtype=torch.float64) delta_t tensor(0.6345, dtype=torch.float64)
13 gae_duplicate tensor(0.5053, dtype=torch.float64) tensor(-13.6496, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8000, dtype=torch.float64) delta_t tensor(0.5261, dtype=torch.float64)
12 gae_duplicate tensor(0.4413, dtype=torch.float64) tensor(-12.4051, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.5440, dtype=torch.float64) delta_t tensor(0.4011, dtype=torch.float64)
11 gae_duplicate tensor(0.1943, dtype=torch.float64) tensor(-8.7254, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.1955, dtype=torch.float64) delta_t tensor(0.1153, dtype=torch.float64)
10 gae_duplicate tensor(-0.2101, dtype=torch.float64) tensor(-3.0180, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.1895, dtype=torch.float64) delta_t tensor(-0.4716, dtype=torch.float64)
9 gae_duplicate tensor(-0.7406, dtype=torch.float64) tensor(9.0136, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.2719, dtype=torch.float64) delta_t tensor(-0.5417, dtype=torch.float64)
8 gae_duplicate tensor(-0.9477, dtype=torch.float64) tensor(11.1078, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.2410, dtype=torch.float64) delta_t tensor(-0.4665, dtype=torch.float64)
7 gae_duplicate tensor(-0.7919, dtype=torch.float64) tensor(10.5210, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.0697, dtype=torch.float64) delta_t tensor(-0.0271, dtype=torch.float64)
6 gae_duplicate tensor(-0.1651, dtype=torch.float64) tensor(1.5567, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.8168, dtype=torch.float64) delta_t tensor(-0.7033, dtype=torch.float64)
5 gae_duplicate tensor(-0.9964, dtype=torch.float64) tensor(14.3605, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.0928, dtype=torch.float64) delta_t tensor(-0.8245, dtype=torch.float64)
4 gae_duplicate tensor(-1.1156, dtype=torch.float64) tensor(16.5409, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.1525, dtype=torch.float64) delta_t tensor(-0.9929, dtype=torch.float64)
3 gae_duplicate tensor(-1.4109, dtype=torch.float64) tensor(20.8015, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.2972, dtype=torch.float64) delta_t tensor(-1.3485, dtype=torch.float64)
2 gae_duplicate tensor(-1.6608, dtype=torch.float64) tensor(28.1637, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-1193.7545166015625
value loss:74.27479553222656
entropies:347.874267578125
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.379492282867432 seconds
19 rew tensor(0.9753, dtype=torch.float64) delta_t tensor(0.5145, dtype=torch.float64)
19 gae_duplicate tensor(0.3702, dtype=torch.float64) tensor(-8.9278, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.9787, dtype=torch.float64) delta_t tensor(0.4700, dtype=torch.float64)
18 gae_duplicate tensor(0.4034, dtype=torch.float64) tensor(-10.6298, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9821, dtype=torch.float64) delta_t tensor(0.4648, dtype=torch.float64)
17 gae_duplicate tensor(0.4342, dtype=torch.float64) tensor(-9.2022, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9856, dtype=torch.float64) delta_t tensor(0.4942, dtype=torch.float64)
16 gae_duplicate tensor(0.4859, dtype=torch.float64) tensor(-10.6076, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9892, dtype=torch.float64) delta_t tensor(0.5524, dtype=torch.float64)
15 gae_duplicate tensor(0.4288, dtype=torch.float64) tensor(-11.5340, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9928, dtype=torch.float64) delta_t tensor(0.6566, dtype=torch.float64)
14 gae_duplicate tensor(0.6417, dtype=torch.float64) tensor(-13.2153, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9964, dtype=torch.float64) delta_t tensor(0.7503, dtype=torch.float64)
13 gae_duplicate tensor(0.6598, dtype=torch.float64) tensor(-15.8559, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.6317, dtype=torch.float64) delta_t tensor(0.3930, dtype=torch.float64)
12 gae_duplicate tensor(0.1639, dtype=torch.float64) tensor(-9.2061, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.3699, dtype=torch.float64) delta_t tensor(0.2458, dtype=torch.float64)
11 gae_duplicate tensor(-0.1780, dtype=torch.float64) tensor(-5.2130, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.3012, dtype=torch.float64) delta_t tensor(0.2633, dtype=torch.float64)
10 gae_duplicate tensor(-0.1407, dtype=torch.float64) tensor(-5.5185, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.1716, dtype=torch.float64) delta_t tensor(-0.3846, dtype=torch.float64)
9 gae_duplicate tensor(-0.6456, dtype=torch.float64) tensor(6.9355, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.2551, dtype=torch.float64) delta_t tensor(-0.4841, dtype=torch.float64)
8 gae_duplicate tensor(-0.7959, dtype=torch.float64) tensor(10.2443, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.8909, dtype=torch.float64) delta_t tensor(-1.0572, dtype=torch.float64)
7 gae_duplicate tensor(-3.0832, dtype=torch.float64) tensor(22.8601, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.9865, dtype=torch.float64) delta_t tensor(-0.9829, dtype=torch.float64)
6 gae_duplicate tensor(-3.1657, dtype=torch.float64) tensor(20.9078, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.8791, dtype=torch.float64) delta_t tensor(-0.6392, dtype=torch.float64)
5 gae_duplicate tensor(-2.0143, dtype=torch.float64) tensor(14.0236, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-0.9446, dtype=torch.float64) delta_t tensor(-0.6456, dtype=torch.float64)
4 gae_duplicate tensor(-1.0589, dtype=torch.float64) tensor(14.0190, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.3586, dtype=torch.float64) delta_t tensor(-1.0985, dtype=torch.float64)
3 gae_duplicate tensor(-1.6188, dtype=torch.float64) tensor(21.6137, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.0794, dtype=torch.float64) delta_t tensor(-1.1498, dtype=torch.float64)
2 gae_duplicate tensor(-1.5527, dtype=torch.float64) tensor(25.3296, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-2039.3043212890625
value loss:123.03543090820312
entropies:348.288330078125
Policy training finished
---------------------
gamma: 0.1
Process Process-9:
Traceback (most recent call last):
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/suhuangyuan/DRA/ToM2C/train.py", line 453, in train
    if train_modes[rank] != -10:
  File "<string>", line 2, in __getitem__
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/managers.py", line 810, in _callmethod
    kind, result = conn.recv()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt