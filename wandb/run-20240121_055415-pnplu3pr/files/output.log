obs <crafter.objects.Shelter object at 0x13906d0d0> [39.  0.  0.  0. 39.  0.  0.  0. 11.  0.  0.  0.]
obs <crafter.objects.Warehouse object at 0x10fec64c0> [39.  0.  0.  0. 37.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Station object at 0x1390753a0> [ 9.  0.  0.  0.  9.  0.  0.  0. 13.  0.  0.  0.]
obs <crafter.objects.Shelter object at 0x13906d0d0> [39.  0.  0.  0. 39.  0.  0.  0. 11.  0.  0.  0.]
obs <crafter.objects.Warehouse object at 0x10fec64c0> [37.  0.  0.  0. 40.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Station object at 0x1390753a0> [ 9.  0.  0.  0.  9.  0.  0.  0. 12.  0.  0.  0.]
{'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0}
training start after waiting for 0.0036079883575439453 seconds
19 rew tensor(0.1152, dtype=torch.float64) delta_t tensor(0.1749, dtype=torch.float64)
19 gae_duplicate tensor(-0.0203, dtype=torch.float64) tensor(-3.4659, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.1417, dtype=torch.float64) delta_t tensor(0.2045, dtype=torch.float64)
18 gae_duplicate tensor(-0.0321, dtype=torch.float64) tensor(-4.3944, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.1976, dtype=torch.float64) delta_t tensor(0.2296, dtype=torch.float64)
17 gae_duplicate tensor(0.0008, dtype=torch.float64) tensor(-4.9737, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.3076, dtype=torch.float64) delta_t tensor(0.2651, dtype=torch.float64)
16 gae_duplicate tensor(0.0575, dtype=torch.float64) tensor(-5.7097, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.5411, dtype=torch.float64) delta_t tensor(0.4754, dtype=torch.float64)
15 gae_duplicate tensor(0.2976, dtype=torch.float64) tensor(-9.9960, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9763, dtype=torch.float64) delta_t tensor(0.9137, dtype=torch.float64)
14 gae_duplicate tensor(0.7405, dtype=torch.float64) tensor(-18.8799, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(1.0487, dtype=torch.float64) delta_t tensor(0.9861, dtype=torch.float64)
13 gae_duplicate tensor(0.8191, dtype=torch.float64) tensor(-21.1449, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(1.1411, dtype=torch.float64) delta_t tensor(1.0785, dtype=torch.float64)
12 gae_duplicate tensor(0.8895, dtype=torch.float64) tensor(-23.4961, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(1.2654, dtype=torch.float64) delta_t tensor(1.1737, dtype=torch.float64)
11 gae_duplicate tensor(0.8741, dtype=torch.float64) tensor(-25.3576, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(1.4475, dtype=torch.float64) delta_t tensor(1.4403, dtype=torch.float64)
10 gae_duplicate tensor(1.1602, dtype=torch.float64) tensor(-30.8286, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.2011, dtype=torch.float64) delta_t tensor(-0.2104, dtype=torch.float64)
9 gae_duplicate tensor(-0.8464, dtype=torch.float64) tensor(1.0148, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.2058, dtype=torch.float64) delta_t tensor(-0.2142, dtype=torch.float64)
8 gae_duplicate tensor(-1.9513, dtype=torch.float64) tensor(4.2062, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.6989, dtype=torch.float64) delta_t tensor(-0.7116, dtype=torch.float64)
7 gae_duplicate tensor(-1.7441, dtype=torch.float64) tensor(14.3738, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.2578, dtype=torch.float64) delta_t tensor(-0.2435, dtype=torch.float64)
6 gae_duplicate tensor(-0.7569, dtype=torch.float64) tensor(6.1972, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.5602, dtype=torch.float64) delta_t tensor(-0.5443, dtype=torch.float64)
5 gae_duplicate tensor(-1.9557, dtype=torch.float64) tensor(11.3693, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.0143, dtype=torch.float64) delta_t tensor(-1.0803, dtype=torch.float64)
4 gae_duplicate tensor(-2.0461, dtype=torch.float64) tensor(22.4358, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.7329, dtype=torch.float64) delta_t tensor(0.6490, dtype=torch.float64)
3 gae_duplicate tensor(-0.3250, dtype=torch.float64) tensor(-10.3778, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.1334, dtype=torch.float64) delta_t tensor(-0.0668, dtype=torch.float64)
2 gae_duplicate tensor(-0.6505, dtype=torch.float64) tensor(0.2835, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:5236.11083984375
value loss:146.43807983398438
entropies:355.789306640625
Policy training finished
---------------------
gamma: 0.1
/Users/suhuangyuan/DRA/ToM2C/shared_optim.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1420.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
training start after waiting for 4.683031797409058 seconds
19 rew tensor(0.1668, dtype=torch.float64) delta_t tensor(0.0992, dtype=torch.float64)
19 gae_duplicate tensor(-0.0622, dtype=torch.float64) tensor(-1.9716, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.2064, dtype=torch.float64) delta_t tensor(0.1814, dtype=torch.float64)
18 gae_duplicate tensor(-0.0597, dtype=torch.float64) tensor(-3.8335, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.2592, dtype=torch.float64) delta_t tensor(0.1992, dtype=torch.float64)
17 gae_duplicate tensor(0.0731, dtype=torch.float64) tensor(-4.2145, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.3488, dtype=torch.float64) delta_t tensor(0.1434, dtype=torch.float64)
16 gae_duplicate tensor(-0.0608, dtype=torch.float64) tensor(-3.3329, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.5285, dtype=torch.float64) delta_t tensor(0.2826, dtype=torch.float64)
15 gae_duplicate tensor(0.1562, dtype=torch.float64) tensor(-5.8599, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8929, dtype=torch.float64) delta_t tensor(0.6525, dtype=torch.float64)
14 gae_duplicate tensor(0.5976, dtype=torch.float64) tensor(-13.6081, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9171, dtype=torch.float64) delta_t tensor(0.6767, dtype=torch.float64)
13 gae_duplicate tensor(0.6507, dtype=torch.float64) tensor(-15.0211, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9435, dtype=torch.float64) delta_t tensor(0.7031, dtype=torch.float64)
12 gae_duplicate tensor(0.6785, dtype=torch.float64) tensor(-15.5826, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.9724, dtype=torch.float64) delta_t tensor(0.7677, dtype=torch.float64)
11 gae_duplicate tensor(0.6843, dtype=torch.float64) tensor(-17.0625, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(1.0042, dtype=torch.float64) delta_t tensor(0.9477, dtype=torch.float64)
10 gae_duplicate tensor(0.8652, dtype=torch.float64) tensor(-20.3835, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.6774, dtype=torch.float64) delta_t tensor(-0.7443, dtype=torch.float64)
9 gae_duplicate tensor(-0.9191, dtype=torch.float64) tensor(12.8742, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.6442, dtype=torch.float64) delta_t tensor(-0.7051, dtype=torch.float64)
8 gae_duplicate tensor(-2.9555, dtype=torch.float64) tensor(15.0011, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.5904, dtype=torch.float64) delta_t tensor(-0.6429, dtype=torch.float64)
7 gae_duplicate tensor(-0.9978, dtype=torch.float64) tensor(14.1465, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.6525, dtype=torch.float64) delta_t tensor(-0.6373, dtype=torch.float64)
6 gae_duplicate tensor(-2.2692, dtype=torch.float64) tensor(14.3366, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.8659, dtype=torch.float64) delta_t tensor(-0.9078, dtype=torch.float64)
5 gae_duplicate tensor(-2.1209, dtype=torch.float64) tensor(19.2916, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.6282, dtype=torch.float64) delta_t tensor(-2.8800, dtype=torch.float64)
4 gae_duplicate tensor(-4.6484, dtype=torch.float64) tensor(59.4276, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.1242, dtype=torch.float64) delta_t tensor(-0.0392, dtype=torch.float64)
3 gae_duplicate tensor(-0.7042, dtype=torch.float64) tensor(6.7358, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.0586, dtype=torch.float64) delta_t tensor(-0.0865, dtype=torch.float64)
2 gae_duplicate tensor(-0.3570, dtype=torch.float64) tensor(2.4061, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-2436.80712890625
value loss:200.47723388671875
entropies:355.3782653808594
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.96068000793457 seconds
19 rew tensor(0.2442, dtype=torch.float64) delta_t tensor(0.1506, dtype=torch.float64)
19 gae_duplicate tensor(0.0860, dtype=torch.float64) tensor(-2.9383, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.2750, dtype=torch.float64) delta_t tensor(0.2114, dtype=torch.float64)
18 gae_duplicate tensor(0.1552, dtype=torch.float64) tensor(-4.6796, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.3204, dtype=torch.float64) delta_t tensor(0.1675, dtype=torch.float64)
17 gae_duplicate tensor(0.1426, dtype=torch.float64) tensor(-3.6417, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.4019, dtype=torch.float64) delta_t tensor(0.1417, dtype=torch.float64)
16 gae_duplicate tensor(0.0956, dtype=torch.float64) tensor(-3.1990, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.5611, dtype=torch.float64) delta_t tensor(0.2469, dtype=torch.float64)
15 gae_duplicate tensor(0.1579, dtype=torch.float64) tensor(-5.2284, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9104, dtype=torch.float64) delta_t tensor(0.6028, dtype=torch.float64)
14 gae_duplicate tensor(0.5195, dtype=torch.float64) tensor(-12.3663, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9262, dtype=torch.float64) delta_t tensor(0.6185, dtype=torch.float64)
13 gae_duplicate tensor(0.5597, dtype=torch.float64) tensor(-13.1971, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9428, dtype=torch.float64) delta_t tensor(0.6351, dtype=torch.float64)
12 gae_duplicate tensor(0.5761, dtype=torch.float64) tensor(-13.9122, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.9603, dtype=torch.float64) delta_t tensor(0.6941, dtype=torch.float64)
11 gae_duplicate tensor(0.6001, dtype=torch.float64) tensor(-15.3047, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.9789, dtype=torch.float64) delta_t tensor(0.8907, dtype=torch.float64)
10 gae_duplicate tensor(0.7488, dtype=torch.float64) tensor(-18.9439, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.8520, dtype=torch.float64) delta_t tensor(-0.9495, dtype=torch.float64)
9 gae_duplicate tensor(-1.7829, dtype=torch.float64) tensor(17.1920, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.7659, dtype=torch.float64) delta_t tensor(-0.8625, dtype=torch.float64)
8 gae_duplicate tensor(-2.1381, dtype=torch.float64) tensor(19.2549, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-1.5084, dtype=torch.float64) delta_t tensor(-1.5875, dtype=torch.float64)
7 gae_duplicate tensor(-2.2819, dtype=torch.float64) tensor(32.4630, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.6307, dtype=torch.float64) delta_t tensor(-0.6595, dtype=torch.float64)
6 gae_duplicate tensor(-2.2280, dtype=torch.float64) tensor(16.3221, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.0458, dtype=torch.float64) delta_t tensor(-1.0944, dtype=torch.float64)
5 gae_duplicate tensor(-2.1064, dtype=torch.float64) tensor(22.9442, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.5991, dtype=torch.float64) delta_t tensor(-2.8223, dtype=torch.float64)
4 gae_duplicate tensor(-4.4240, dtype=torch.float64) tensor(57.2074, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.1136, dtype=torch.float64) delta_t tensor(-0.0087, dtype=torch.float64)
3 gae_duplicate tensor(-0.4470, dtype=torch.float64) tensor(6.0483, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0864, dtype=torch.float64) delta_t tensor(0.0952, dtype=torch.float64)
2 gae_duplicate tensor(-0.0724, dtype=torch.float64) tensor(-1.2172, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-4243.26318359375
value loss:193.92030334472656
entropies:355.08868408203125
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.587855100631714 seconds
19 rew tensor(0.2139, dtype=torch.float64) delta_t tensor(0.1314, dtype=torch.float64)
19 gae_duplicate tensor(0.0849, dtype=torch.float64) tensor(-2.6686, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.2425, dtype=torch.float64) delta_t tensor(0.1958, dtype=torch.float64)
18 gae_duplicate tensor(0.1283, dtype=torch.float64) tensor(-4.1572, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.2856, dtype=torch.float64) delta_t tensor(0.1894, dtype=torch.float64)
17 gae_duplicate tensor(0.0631, dtype=torch.float64) tensor(-4.1855, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.3778, dtype=torch.float64) delta_t tensor(0.1233, dtype=torch.float64)
16 gae_duplicate tensor(0.0828, dtype=torch.float64) tensor(-2.8886, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.5442, dtype=torch.float64) delta_t tensor(0.2311, dtype=torch.float64)
15 gae_duplicate tensor(0.1241, dtype=torch.float64) tensor(-4.8051, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8969, dtype=torch.float64) delta_t tensor(0.5912, dtype=torch.float64)
14 gae_duplicate tensor(0.4653, dtype=torch.float64) tensor(-12.2293, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9080, dtype=torch.float64) delta_t tensor(0.6023, dtype=torch.float64)
13 gae_duplicate tensor(0.5016, dtype=torch.float64) tensor(-13.2913, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9196, dtype=torch.float64) delta_t tensor(0.6139, dtype=torch.float64)
12 gae_duplicate tensor(0.5141, dtype=torch.float64) tensor(-13.4167, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.9316, dtype=torch.float64) delta_t tensor(0.6867, dtype=torch.float64)
11 gae_duplicate tensor(0.6135, dtype=torch.float64) tensor(-15.1661, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.9442, dtype=torch.float64) delta_t tensor(0.9397, dtype=torch.float64)
10 gae_duplicate tensor(0.8867, dtype=torch.float64) tensor(-20.1048, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.1620, dtype=torch.float64) delta_t tensor(-0.1847, dtype=torch.float64)
9 gae_duplicate tensor(-0.7267, dtype=torch.float64) tensor(1.6273, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.7856, dtype=torch.float64) delta_t tensor(-0.8053, dtype=torch.float64)
8 gae_duplicate tensor(-1.4752, dtype=torch.float64) tensor(15.8357, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.4588, dtype=torch.float64) delta_t tensor(-0.4623, dtype=torch.float64)
7 gae_duplicate tensor(-0.9450, dtype=torch.float64) tensor(10.6070, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.9369, dtype=torch.float64) delta_t tensor(-0.8886, dtype=torch.float64)
6 gae_duplicate tensor(-1.9444, dtype=torch.float64) tensor(18.7194, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.5846, dtype=torch.float64) delta_t tensor(-1.5038, dtype=torch.float64)
5 gae_duplicate tensor(-2.3927, dtype=torch.float64) tensor(32.3521, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-3.0974, dtype=torch.float64) delta_t tensor(-3.1873, dtype=torch.float64)
4 gae_duplicate tensor(-5.5251, dtype=torch.float64) tensor(65.2760, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.2345, dtype=torch.float64) delta_t tensor(0.1291, dtype=torch.float64)
3 gae_duplicate tensor(-0.6346, dtype=torch.float64) tensor(4.0660, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0270, dtype=torch.float64) delta_t tensor(0.0624, dtype=torch.float64)
2 gae_duplicate tensor(-0.2108, dtype=torch.float64) tensor(-0.7721, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-3054.989990234375
value loss:196.9449920654297
entropies:355.1379089355469
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.864019870758057 seconds
19 rew tensor(0.2173, dtype=torch.float64) delta_t tensor(0.2253, dtype=torch.float64)
19 gae_duplicate tensor(0.1180, dtype=torch.float64) tensor(-4.5005, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.2381, dtype=torch.float64) delta_t tensor(0.2449, dtype=torch.float64)
18 gae_duplicate tensor(0.1317, dtype=torch.float64) tensor(-5.2107, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.2812, dtype=torch.float64) delta_t tensor(0.1590, dtype=torch.float64)
17 gae_duplicate tensor(0.0668, dtype=torch.float64) tensor(-3.6954, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.3699, dtype=torch.float64) delta_t tensor(0.1359, dtype=torch.float64)
16 gae_duplicate tensor(0.0790, dtype=torch.float64) tensor(-3.0176, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.5378, dtype=torch.float64) delta_t tensor(0.2073, dtype=torch.float64)
15 gae_duplicate tensor(0.1019, dtype=torch.float64) tensor(-4.5186, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8973, dtype=torch.float64) delta_t tensor(0.5777, dtype=torch.float64)
14 gae_duplicate tensor(0.4975, dtype=torch.float64) tensor(-11.8582, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9061, dtype=torch.float64) delta_t tensor(0.5865, dtype=torch.float64)
13 gae_duplicate tensor(0.5273, dtype=torch.float64) tensor(-12.6354, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9151, dtype=torch.float64) delta_t tensor(0.5955, dtype=torch.float64)
12 gae_duplicate tensor(0.5368, dtype=torch.float64) tensor(-12.8655, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.9244, dtype=torch.float64) delta_t tensor(0.6477, dtype=torch.float64)
11 gae_duplicate tensor(0.5290, dtype=torch.float64) tensor(-14.1733, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.9341, dtype=torch.float64) delta_t tensor(0.9705, dtype=torch.float64)
10 gae_duplicate tensor(0.7844, dtype=torch.float64) tensor(-20.4013, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.7165, dtype=torch.float64) delta_t tensor(-0.7020, dtype=torch.float64)
9 gae_duplicate tensor(-1.4569, dtype=torch.float64) tensor(11.7577, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.4651, dtype=torch.float64) delta_t tensor(-0.4605, dtype=torch.float64)
8 gae_duplicate tensor(-1.4014, dtype=torch.float64) tensor(10.2999, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.7526, dtype=torch.float64) delta_t tensor(-0.7447, dtype=torch.float64)
7 gae_duplicate tensor(-0.9816, dtype=torch.float64) tensor(15.6098, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.8007, dtype=torch.float64) delta_t tensor(-0.7351, dtype=torch.float64)
6 gae_duplicate tensor(-1.0124, dtype=torch.float64) tensor(16.2799, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.0905, dtype=torch.float64) delta_t tensor(-1.0556, dtype=torch.float64)
5 gae_duplicate tensor(-1.7386, dtype=torch.float64) tensor(22.9506, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.9711, dtype=torch.float64) delta_t tensor(-1.9579, dtype=torch.float64)
4 gae_duplicate tensor(-4.6121, dtype=torch.float64) tensor(40.9979, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.3309, dtype=torch.float64) delta_t tensor(0.3503, dtype=torch.float64)
3 gae_duplicate tensor(-0.2823, dtype=torch.float64) tensor(-2.8792, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0492, dtype=torch.float64) delta_t tensor(0.1263, dtype=torch.float64)
2 gae_duplicate tensor(-0.1327, dtype=torch.float64) tensor(-2.7673, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-1142.0838623046875
value loss:151.6676025390625
entropies:355.3977966308594
Policy training finished
---------------------
ToM training started
ToM data loaded
batch_size =  600
ToM_loss = tensor(3970.2524)
ToM Target loss= tensor(3348.0388)
optimized based on ToM loss
---------------------
gamma: 0.1
training start after waiting for 5.665319919586182 seconds
19 rew tensor(0.2170, dtype=torch.float64) delta_t tensor(0.1899, dtype=torch.float64)
19 gae_duplicate tensor(0.1504, dtype=torch.float64) tensor(-3.6927, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.2471, dtype=torch.float64) delta_t tensor(0.2537, dtype=torch.float64)
18 gae_duplicate tensor(0.1986, dtype=torch.float64) tensor(-5.4073, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.2891, dtype=torch.float64) delta_t tensor(0.2191, dtype=torch.float64)
17 gae_duplicate tensor(0.1227, dtype=torch.float64) tensor(-4.9783, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.3783, dtype=torch.float64) delta_t tensor(0.1302, dtype=torch.float64)
16 gae_duplicate tensor(0.0813, dtype=torch.float64) tensor(-3.0400, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.5347, dtype=torch.float64) delta_t tensor(0.2135, dtype=torch.float64)
15 gae_duplicate tensor(0.1426, dtype=torch.float64) tensor(-4.4329, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8796, dtype=torch.float64) delta_t tensor(0.5675, dtype=torch.float64)
14 gae_duplicate tensor(0.4675, dtype=torch.float64) tensor(-11.7869, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8865, dtype=torch.float64) delta_t tensor(0.5744, dtype=torch.float64)
13 gae_duplicate tensor(0.5039, dtype=torch.float64) tensor(-12.5217, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8936, dtype=torch.float64) delta_t tensor(0.5815, dtype=torch.float64)
12 gae_duplicate tensor(0.5130, dtype=torch.float64) tensor(-12.9698, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.9008, dtype=torch.float64) delta_t tensor(0.6966, dtype=torch.float64)
11 gae_duplicate tensor(0.6215, dtype=torch.float64) tensor(-14.9152, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.9082, dtype=torch.float64) delta_t tensor(1.0517, dtype=torch.float64)
10 gae_duplicate tensor(1.0216, dtype=torch.float64) tensor(-22.2844, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.5932, dtype=torch.float64) delta_t tensor(-0.4762, dtype=torch.float64)
9 gae_duplicate tensor(-0.6308, dtype=torch.float64) tensor(7.3193, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.7567, dtype=torch.float64) delta_t tensor(-0.6411, dtype=torch.float64)
8 gae_duplicate tensor(-1.4438, dtype=torch.float64) tensor(13.3056, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.6433, dtype=torch.float64) delta_t tensor(-0.5181, dtype=torch.float64)
7 gae_duplicate tensor(-1.6917, dtype=torch.float64) tensor(11.5544, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.5897, dtype=torch.float64) delta_t tensor(-0.4282, dtype=torch.float64)
6 gae_duplicate tensor(-1.0398, dtype=torch.float64) tensor(9.6344, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.8581, dtype=torch.float64) delta_t tensor(-0.7180, dtype=torch.float64)
5 gae_duplicate tensor(-1.7728, dtype=torch.float64) tensor(15.5447, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.6461, dtype=torch.float64) delta_t tensor(-2.5511, dtype=torch.float64)
4 gae_duplicate tensor(-5.3666, dtype=torch.float64) tensor(51.8076, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.2272, dtype=torch.float64) delta_t tensor(0.2526, dtype=torch.float64)
3 gae_duplicate tensor(-0.4362, dtype=torch.float64) tensor(0.3097, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0627, dtype=torch.float64) delta_t tensor(0.2149, dtype=torch.float64)
2 gae_duplicate tensor(-0.0187, dtype=torch.float64) tensor(-4.1721, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-596.810791015625
value loss:173.51808166503906
entropies:355.5068054199219
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.51894474029541 seconds
19 rew tensor(0.2371, dtype=torch.float64) delta_t tensor(0.2542, dtype=torch.float64)
19 gae_duplicate tensor(0.1282, dtype=torch.float64) tensor(-5.0905, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.2516, dtype=torch.float64) delta_t tensor(0.2310, dtype=torch.float64)
18 gae_duplicate tensor(0.1391, dtype=torch.float64) tensor(-5.0140, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.2928, dtype=torch.float64) delta_t tensor(0.2299, dtype=torch.float64)
17 gae_duplicate tensor(0.2210, dtype=torch.float64) tensor(-4.9005, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.3678, dtype=torch.float64) delta_t tensor(0.1395, dtype=torch.float64)
16 gae_duplicate tensor(0.1031, dtype=torch.float64) tensor(-3.2377, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.5283, dtype=torch.float64) delta_t tensor(0.2442, dtype=torch.float64)
15 gae_duplicate tensor(0.1111, dtype=torch.float64) tensor(-5.0206, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8694, dtype=torch.float64) delta_t tensor(0.5925, dtype=torch.float64)
14 gae_duplicate tensor(0.4383, dtype=torch.float64) tensor(-12.0874, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8751, dtype=torch.float64) delta_t tensor(0.5983, dtype=torch.float64)
13 gae_duplicate tensor(0.4757, dtype=torch.float64) tensor(-13.0105, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8809, dtype=torch.float64) delta_t tensor(0.6041, dtype=torch.float64)
12 gae_duplicate tensor(0.4843, dtype=torch.float64) tensor(-13.2265, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8869, dtype=torch.float64) delta_t tensor(0.7011, dtype=torch.float64)
11 gae_duplicate tensor(0.6153, dtype=torch.float64) tensor(-15.1830, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.8930, dtype=torch.float64) delta_t tensor(1.0394, dtype=torch.float64)
10 gae_duplicate tensor(0.9522, dtype=torch.float64) tensor(-22.3281, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.8706, dtype=torch.float64) delta_t tensor(-0.7479, dtype=torch.float64)
9 gae_duplicate tensor(-1.4263, dtype=torch.float64) tensor(12.7655, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-1.0240, dtype=torch.float64) delta_t tensor(-0.9108, dtype=torch.float64)
8 gae_duplicate tensor(-2.6022, dtype=torch.float64) tensor(18.9105, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-1.0276, dtype=torch.float64) delta_t tensor(-0.9178, dtype=torch.float64)
7 gae_duplicate tensor(-2.2441, dtype=torch.float64) tensor(20.3556, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.4038, dtype=torch.float64) delta_t tensor(-0.2668, dtype=torch.float64)
6 gae_duplicate tensor(-1.6729, dtype=torch.float64) tensor(7.6395, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7775, dtype=torch.float64) delta_t tensor(-0.6676, dtype=torch.float64)
5 gae_duplicate tensor(-1.5433, dtype=torch.float64) tensor(13.8866, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.7081, dtype=torch.float64) delta_t tensor(-2.5562, dtype=torch.float64)
4 gae_duplicate tensor(-4.8542, dtype=torch.float64) tensor(52.2201, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.2177, dtype=torch.float64) delta_t tensor(0.3770, dtype=torch.float64)
3 gae_duplicate tensor(-0.3972, dtype=torch.float64) tensor(-2.3145, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0636, dtype=torch.float64) delta_t tensor(0.2446, dtype=torch.float64)
2 gae_duplicate tensor(0.0212, dtype=torch.float64) tensor(-5.0270, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-1140.17724609375
value loss:189.64358520507812
entropies:355.3960266113281
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.208134174346924 seconds
19 rew tensor(0.2158, dtype=torch.float64) delta_t tensor(0.1807, dtype=torch.float64)
19 gae_duplicate tensor(0.0826, dtype=torch.float64) tensor(-3.5553, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.2353, dtype=torch.float64) delta_t tensor(0.2206, dtype=torch.float64)
18 gae_duplicate tensor(0.0964, dtype=torch.float64) tensor(-4.6984, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.2763, dtype=torch.float64) delta_t tensor(0.2565, dtype=torch.float64)
17 gae_duplicate tensor(0.1371, dtype=torch.float64) tensor(-5.3356, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.3571, dtype=torch.float64) delta_t tensor(0.0796, dtype=torch.float64)
16 gae_duplicate tensor(0.0160, dtype=torch.float64) tensor(-2.1737, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.5273, dtype=torch.float64) delta_t tensor(0.2138, dtype=torch.float64)
15 gae_duplicate tensor(0.0652, dtype=torch.float64) tensor(-4.4163, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8691, dtype=torch.float64) delta_t tensor(0.5618, dtype=torch.float64)
14 gae_duplicate tensor(0.4371, dtype=torch.float64) tensor(-11.5780, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8741, dtype=torch.float64) delta_t tensor(0.5667, dtype=torch.float64)
13 gae_duplicate tensor(0.4696, dtype=torch.float64) tensor(-12.1284, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8792, dtype=torch.float64) delta_t tensor(0.5718, dtype=torch.float64)
12 gae_duplicate tensor(0.4770, dtype=torch.float64) tensor(-12.3428, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8843, dtype=torch.float64) delta_t tensor(0.6789, dtype=torch.float64)
11 gae_duplicate tensor(0.5501, dtype=torch.float64) tensor(-14.8467, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.8896, dtype=torch.float64) delta_t tensor(1.0645, dtype=torch.float64)
10 gae_duplicate tensor(1.0286, dtype=torch.float64) tensor(-22.3941, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.5789, dtype=torch.float64) delta_t tensor(-0.4309, dtype=torch.float64)
9 gae_duplicate tensor(-1.1999, dtype=torch.float64) tensor(6.4458, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.8427, dtype=torch.float64) delta_t tensor(-0.6986, dtype=torch.float64)
8 gae_duplicate tensor(-1.6622, dtype=torch.float64) tensor(14.5885, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.7422, dtype=torch.float64) delta_t tensor(-0.5944, dtype=torch.float64)
7 gae_duplicate tensor(-0.8965, dtype=torch.float64) tensor(13.1426, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.8097, dtype=torch.float64) delta_t tensor(-0.6054, dtype=torch.float64)
6 gae_duplicate tensor(-0.8538, dtype=torch.float64) tensor(13.2407, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.9916, dtype=torch.float64) delta_t tensor(-0.8023, dtype=torch.float64)
5 gae_duplicate tensor(-1.7539, dtype=torch.float64) tensor(17.4776, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.3812, dtype=torch.float64) delta_t tensor(-2.1745, dtype=torch.float64)
4 gae_duplicate tensor(-4.7179, dtype=torch.float64) tensor(44.6662, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.3446, dtype=torch.float64) delta_t tensor(0.5161, dtype=torch.float64)
3 gae_duplicate tensor(-0.0769, dtype=torch.float64) tensor(-5.6667, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0395, dtype=torch.float64) delta_t tensor(0.2490, dtype=torch.float64)
2 gae_duplicate tensor(0.0363, dtype=torch.float64) tensor(-5.3672, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-369.06634521484375
value loss:152.08180236816406
entropies:355.26123046875
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.495802164077759 seconds
19 rew tensor(0.1962, dtype=torch.float64) delta_t tensor(0.1640, dtype=torch.float64)
19 gae_duplicate tensor(0.1147, dtype=torch.float64) tensor(-3.2170, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.2096, dtype=torch.float64) delta_t tensor(0.1947, dtype=torch.float64)
18 gae_duplicate tensor(0.1511, dtype=torch.float64) tensor(-4.1294, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.2510, dtype=torch.float64) delta_t tensor(0.1518, dtype=torch.float64)
17 gae_duplicate tensor(0.0362, dtype=torch.float64) tensor(-3.4817, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.3475, dtype=torch.float64) delta_t tensor(0.0084, dtype=torch.float64)
16 gae_duplicate tensor(-0.0276, dtype=torch.float64) tensor(-0.5102, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.5121, dtype=torch.float64) delta_t tensor(0.0702, dtype=torch.float64)
15 gae_duplicate tensor(-0.0101, dtype=torch.float64) tensor(-1.3902, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8799, dtype=torch.float64) delta_t tensor(0.4508, dtype=torch.float64)
14 gae_duplicate tensor(0.3604, dtype=torch.float64) tensor(-8.7956, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8844, dtype=torch.float64) delta_t tensor(0.4553, dtype=torch.float64)
13 gae_duplicate tensor(0.3974, dtype=torch.float64) tensor(-10.0508, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8890, dtype=torch.float64) delta_t tensor(0.4599, dtype=torch.float64)
12 gae_duplicate tensor(0.4049, dtype=torch.float64) tensor(-10.1687, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8936, dtype=torch.float64) delta_t tensor(0.5940, dtype=torch.float64)
11 gae_duplicate tensor(0.5563, dtype=torch.float64) tensor(-12.7894, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.8984, dtype=torch.float64) delta_t tensor(1.1850, dtype=torch.float64)
10 gae_duplicate tensor(1.1761, dtype=torch.float64) tensor(-25.5311, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-1.0739, dtype=torch.float64) delta_t tensor(-0.8440, dtype=torch.float64)
9 gae_duplicate tensor(-1.5186, dtype=torch.float64) tensor(14.5682, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.4815, dtype=torch.float64) delta_t tensor(-0.2585, dtype=torch.float64)
8 gae_duplicate tensor(-0.9358, dtype=torch.float64) tensor(6.4174, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.8957, dtype=torch.float64) delta_t tensor(-0.6599, dtype=torch.float64)
7 gae_duplicate tensor(-1.3630, dtype=torch.float64) tensor(13.4267, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.6954, dtype=torch.float64) delta_t tensor(-0.4162, dtype=torch.float64)
6 gae_duplicate tensor(-0.7943, dtype=torch.float64) tensor(9.5097, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.9378, dtype=torch.float64) delta_t tensor(-0.6110, dtype=torch.float64)
5 gae_duplicate tensor(-1.1623, dtype=torch.float64) tensor(12.6054, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.6151, dtype=torch.float64) delta_t tensor(-1.3400, dtype=torch.float64)
4 gae_duplicate tensor(-3.6994, dtype=torch.float64) tensor(27.4587, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.3342, dtype=torch.float64) delta_t tensor(0.4928, dtype=torch.float64)
3 gae_duplicate tensor(-0.1323, dtype=torch.float64) tensor(-7.1243, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.0102, dtype=torch.float64) delta_t tensor(0.2285, dtype=torch.float64)
2 gae_duplicate tensor(0.0181, dtype=torch.float64) tensor(-5.4096, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:369.19085693359375
value loss:96.50743103027344
entropies:355.00384521484375
Policy training finished
---------------------
gamma: 0.1
Process Process-9:
Traceback (most recent call last):
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/suhuangyuan/DRA/ToM2C/train.py", line 453, in train
    if train_modes[rank] != -10:
  File "<string>", line 2, in __getitem__
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/managers.py", line 810, in _callmethod
    kind, result = conn.recv()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
training start after waiting for 5.0250372886657715 seconds
19 rew tensor(0.2280, dtype=torch.float64) delta_t tensor(0.1714, dtype=torch.float64)
19 gae_duplicate tensor(0.0943, dtype=torch.float64) tensor(-3.3449, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.2349, dtype=torch.float64) delta_t tensor(0.1846, dtype=torch.float64)
18 gae_duplicate tensor(0.1874, dtype=torch.float64) tensor(-3.8795, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.2767, dtype=torch.float64) delta_t tensor(0.1542, dtype=torch.float64)
17 gae_duplicate tensor(0.1308, dtype=torch.float64) tensor(-3.3866, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.3598, dtype=torch.float64) delta_t tensor(-0.0286, dtype=torch.float64)
16 gae_duplicate tensor(-0.0553, dtype=torch.float64) tensor(0.2116, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.5252, dtype=torch.float64) delta_t tensor(0.0178, dtype=torch.float64)
15 gae_duplicate tensor(-0.0195, dtype=torch.float64) tensor(-0.3349, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8897, dtype=torch.float64) delta_t tensor(0.3970, dtype=torch.float64)
14 gae_duplicate tensor(0.3100, dtype=torch.float64) tensor(-7.9543, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8939, dtype=torch.float64) delta_t tensor(0.4011, dtype=torch.float64)
13 gae_duplicate tensor(0.3450, dtype=torch.float64) tensor(-8.5288, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8981, dtype=torch.float64) delta_t tensor(0.4053, dtype=torch.float64)
12 gae_duplicate tensor(0.3521, dtype=torch.float64) tensor(-8.7905, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.9023, dtype=torch.float64) delta_t tensor(0.5769, dtype=torch.float64)
11 gae_duplicate tensor(0.5305, dtype=torch.float64) tensor(-12.3096, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.9066, dtype=torch.float64) delta_t tensor(1.2513, dtype=torch.float64)
10 gae_duplicate tensor(1.2234, dtype=torch.float64) tensor(-25.8352, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.5258, dtype=torch.float64) delta_t tensor(-0.2362, dtype=torch.float64)
9 gae_duplicate tensor(-1.3881, dtype=torch.float64) tensor(1.8777, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.5138, dtype=torch.float64) delta_t tensor(-0.2395, dtype=torch.float64)
8 gae_duplicate tensor(-0.7744, dtype=torch.float64) tensor(5.3120, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.6150, dtype=torch.float64) delta_t tensor(-0.3443, dtype=torch.float64)
7 gae_duplicate tensor(-0.7165, dtype=torch.float64) tensor(7.1016, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-1.2143, dtype=torch.float64) delta_t tensor(-0.9290, dtype=torch.float64)
6 gae_duplicate tensor(-1.8980, dtype=torch.float64) tensor(18.7952, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.0967, dtype=torch.float64) delta_t tensor(-0.7397, dtype=torch.float64)
5 gae_duplicate tensor(-2.2670, dtype=torch.float64) tensor(16.9230, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.8791, dtype=torch.float64) delta_t tensor(-1.5699, dtype=torch.float64)
4 gae_duplicate tensor(-3.6623, dtype=torch.float64) tensor(31.9468, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(0.1034, dtype=torch.float64) delta_t tensor(0.2726, dtype=torch.float64)
3 gae_duplicate tensor(-0.0894, dtype=torch.float64) tensor(-2.0840, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.0339, dtype=torch.float64) delta_t tensor(0.2958, dtype=torch.float64)
2 gae_duplicate tensor(0.2443, dtype=torch.float64) tensor(-6.1670, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-71.66511535644531
value loss:97.87472534179688
entropies:354.8940124511719
Policy training finished
---------------------
ToM training started
ToM data loaded
batch_size =  600
ToM_loss = tensor(3952.8147)
ToM Target loss= tensor(3425.2979)
optimized based on ToM loss
---------------------
gamma: 0.1