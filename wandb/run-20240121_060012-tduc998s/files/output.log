obs <crafter.objects.Shelter object at 0x135d1a520> [39.  0.  0.  0. 39.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Warehouse object at 0x135d20f10> [36.  0.  0.  0. 40.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Station object at 0x135d20370> [ 9.  0.  0.  0.  9.  0.  0.  0. 12.  0.  0.  0.]
obs <crafter.objects.Shelter object at 0x135d1a520> [39.  0.  0.  0. 39.  0.  0.  0. 11.  0.  0.  0.]
obs <crafter.objects.Warehouse object at 0x135d20f10> [39.  0.  0.  0. 40.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Station object at 0x135d20370> [ 9.  0.  0.  0.  9.  0.  0.  0. 11.  0.  0.  0.]
{'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0}
training start after waiting for 0.004050254821777344 seconds
19 rew tensor(0.8488, dtype=torch.float64) delta_t tensor(1.0311, dtype=torch.float64)
19 gae_duplicate tensor(0.7855, dtype=torch.float64) tensor(-20.3080, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8887, dtype=torch.float64) delta_t tensor(1.0233, dtype=torch.float64)
18 gae_duplicate tensor(0.8528, dtype=torch.float64) tensor(-22.2061, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9351, dtype=torch.float64) delta_t tensor(1.0412, dtype=torch.float64)
17 gae_duplicate tensor(0.7902, dtype=torch.float64) tensor(-22.8220, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9899, dtype=torch.float64) delta_t tensor(1.0942, dtype=torch.float64)
16 gae_duplicate tensor(0.8043, dtype=torch.float64) tensor(-23.6245, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(1.0564, dtype=torch.float64) delta_t tensor(1.1953, dtype=torch.float64)
15 gae_duplicate tensor(0.8952, dtype=torch.float64) tensor(-25.9482, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(1.1393, dtype=torch.float64) delta_t tensor(1.2622, dtype=torch.float64)
14 gae_duplicate tensor(0.9355, dtype=torch.float64) tensor(-27.3782, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(1.2193, dtype=torch.float64) delta_t tensor(1.3166, dtype=torch.float64)
13 gae_duplicate tensor(0.9827, dtype=torch.float64) tensor(-28.2134, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(1.3570, dtype=torch.float64) delta_t tensor(1.4656, dtype=torch.float64)
12 gae_duplicate tensor(1.2356, dtype=torch.float64) tensor(-31.8527, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(1.4609, dtype=torch.float64) delta_t tensor(1.5905, dtype=torch.float64)
11 gae_duplicate tensor(1.0908, dtype=torch.float64) tensor(-34.5520, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(1.3072, dtype=torch.float64) delta_t tensor(1.4186, dtype=torch.float64)
10 gae_duplicate tensor(1.2523, dtype=torch.float64) tensor(-31.2140, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(1.2714, dtype=torch.float64) delta_t tensor(1.3640, dtype=torch.float64)
9 gae_duplicate tensor(1.3170, dtype=torch.float64) tensor(-30.2177, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(1.0748, dtype=torch.float64) delta_t tensor(1.1377, dtype=torch.float64)
8 gae_duplicate tensor(0.1344, dtype=torch.float64) tensor(-25.3064, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(0.6952, dtype=torch.float64) delta_t tensor(0.6695, dtype=torch.float64)
7 gae_duplicate tensor(-2.4637, dtype=torch.float64) tensor(-15.8318, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(0.5824, dtype=torch.float64) delta_t tensor(0.6204, dtype=torch.float64)
6 gae_duplicate tensor(-0.9669, dtype=torch.float64) tensor(-13.8176, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(0.0217, dtype=torch.float64) delta_t tensor(0.0640, dtype=torch.float64)
5 gae_duplicate tensor(-0.3671, dtype=torch.float64) tensor(-2.6699, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-0.3822, dtype=torch.float64) delta_t tensor(-0.3170, dtype=torch.float64)
4 gae_duplicate tensor(-0.9011, dtype=torch.float64) tensor(5.9076, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.0583, dtype=torch.float64) delta_t tensor(-0.9161, dtype=torch.float64)
3 gae_duplicate tensor(-1.0270, dtype=torch.float64) tensor(18.6823, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.1446, dtype=torch.float64) delta_t tensor(-1.0799, dtype=torch.float64)
2 gae_duplicate tensor(-1.2187, dtype=torch.float64) tensor(23.0647, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:16552.5625
value loss:275.9212951660156
entropies:355.77044677734375
Policy training finished
---------------------
gamma: 0.1
/Users/suhuangyuan/DRA/ToM2C/shared_optim.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1420.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
Process Process-9:
Traceback (most recent call last):
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/suhuangyuan/DRA/ToM2C/train.py", line 453, in train
    if train_modes[rank] != -10:
  File "<string>", line 2, in __getitem__
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/managers.py", line 810, in _callmethod
    kind, result = conn.recv()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt