obs <crafter.objects.Shelter object at 0x13be5ceb0> [39.  0.  0.  0. 39.  0.  0.  0. 10.  0.  0.  0.]
obs <crafter.objects.Warehouse object at 0x13be6bb50> [41.  0.  0.  0. 43.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Station object at 0x13be6b1c0> [ 9.  0.  0.  0.  9.  0.  0.  0. 10.  0.  0.  0.]
obs <crafter.objects.Shelter object at 0x13be5ceb0> [39.  0.  0.  0. 39.  0.  0.  0.  8.  0.  0.  0.]
obs <crafter.objects.Warehouse object at 0x13be6bb50> [40.  0.  0.  0. 37.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Station object at 0x13be6b1c0> [ 9.  0.  0.  0.  9.  0.  0.  0. 15.  0.  0.  0.]
{'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0}
training start after waiting for 0.0035910606384277344 seconds
19 rew tensor(0.8818, dtype=torch.float64) delta_t tensor(1.0324, dtype=torch.float64)
19 gae_duplicate tensor(0.9495, dtype=torch.float64) tensor(-20.2782, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.9240, dtype=torch.float64) delta_t tensor(1.0577, dtype=torch.float64)
18 gae_duplicate tensor(1.0655, dtype=torch.float64) tensor(-22.9052, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9550, dtype=torch.float64) delta_t tensor(1.0585, dtype=torch.float64)
17 gae_duplicate tensor(0.9662, dtype=torch.float64) tensor(-23.1756, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9842, dtype=torch.float64) delta_t tensor(1.0574, dtype=torch.float64)
16 gae_duplicate tensor(0.8213, dtype=torch.float64) tensor(-23.0350, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9964, dtype=torch.float64) delta_t tensor(1.1291, dtype=torch.float64)
15 gae_duplicate tensor(0.5626, dtype=torch.float64) tensor(-24.7175, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(1.1785, dtype=torch.float64) delta_t tensor(1.2908, dtype=torch.float64)
14 gae_duplicate tensor(1.1706, dtype=torch.float64) tensor(-27.7471, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(1.2913, dtype=torch.float64) delta_t tensor(1.3798, dtype=torch.float64)
13 gae_duplicate tensor(1.3135, dtype=torch.float64) tensor(-29.4896, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(1.3933, dtype=torch.float64) delta_t tensor(1.5768, dtype=torch.float64)
12 gae_duplicate tensor(1.5091, dtype=torch.float64) tensor(-34.2667, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(1.5246, dtype=torch.float64) delta_t tensor(1.6453, dtype=torch.float64)
11 gae_duplicate tensor(1.5896, dtype=torch.float64) tensor(-35.9114, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(1.5427, dtype=torch.float64) delta_t tensor(1.6521, dtype=torch.float64)
10 gae_duplicate tensor(1.6316, dtype=torch.float64) tensor(-35.8829, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.9696, dtype=torch.float64) delta_t tensor(1.0780, dtype=torch.float64)
9 gae_duplicate tensor(-0.4098, dtype=torch.float64) tensor(-25.1557, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.7350, dtype=torch.float64) delta_t tensor(0.7631, dtype=torch.float64)
8 gae_duplicate tensor(-2.1129, dtype=torch.float64) tensor(-17.8098, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(1.4810, dtype=torch.float64) delta_t tensor(1.4641, dtype=torch.float64)
7 gae_duplicate tensor(1.0765, dtype=torch.float64) tensor(-30.5821, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(1.0841, dtype=torch.float64) delta_t tensor(1.1963, dtype=torch.float64)
6 gae_duplicate tensor(0.9842, dtype=torch.float64) tensor(-26.6824, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(0.1002, dtype=torch.float64) delta_t tensor(0.1479, dtype=torch.float64)
5 gae_duplicate tensor(-0.2165, dtype=torch.float64) tensor(-5.4992, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-0.5952, dtype=torch.float64) delta_t tensor(-0.5082, dtype=torch.float64)
4 gae_duplicate tensor(-1.1046, dtype=torch.float64) tensor(9.4277, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.0907, dtype=torch.float64) delta_t tensor(-0.9627, dtype=torch.float64)
3 gae_duplicate tensor(-1.1137, dtype=torch.float64) tensor(19.9228, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.1162, dtype=torch.float64) delta_t tensor(-1.0736, dtype=torch.float64)
2 gae_duplicate tensor(-1.2904, dtype=torch.float64) tensor(23.0729, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:17762.546875
value loss:301.6984558105469
entropies:355.7717590332031
Policy training finished
---------------------
gamma: 0.1
/Users/suhuangyuan/DRA/ToM2C/shared_optim.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1420.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
training start after waiting for 5.043984889984131 seconds
19 rew tensor(0.7331, dtype=torch.float64) delta_t tensor(0.7041, dtype=torch.float64)
19 gae_duplicate tensor(0.3566, dtype=torch.float64) tensor(-13.9383, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.7063, dtype=torch.float64) delta_t tensor(0.6460, dtype=torch.float64)
18 gae_duplicate tensor(0.3450, dtype=torch.float64) tensor(-14.3186, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6460, dtype=torch.float64) delta_t tensor(0.5687, dtype=torch.float64)
17 gae_duplicate tensor(0.2345, dtype=torch.float64) tensor(-12.4949, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6070, dtype=torch.float64) delta_t tensor(0.5266, dtype=torch.float64)
16 gae_duplicate tensor(0.2476, dtype=torch.float64) tensor(-11.6402, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.6915, dtype=torch.float64) delta_t tensor(0.6548, dtype=torch.float64)
15 gae_duplicate tensor(0.2173, dtype=torch.float64) tensor(-13.7358, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8466, dtype=torch.float64) delta_t tensor(0.8433, dtype=torch.float64)
14 gae_duplicate tensor(0.6019, dtype=torch.float64) tensor(-18.1115, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8697, dtype=torch.float64) delta_t tensor(0.9030, dtype=torch.float64)
13 gae_duplicate tensor(0.5955, dtype=torch.float64) tensor(-20.0239, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8948, dtype=torch.float64) delta_t tensor(0.8788, dtype=torch.float64)
12 gae_duplicate tensor(0.6236, dtype=torch.float64) tensor(-19.5984, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8422, dtype=torch.float64) delta_t tensor(0.8303, dtype=torch.float64)
11 gae_duplicate tensor(0.6844, dtype=torch.float64) tensor(-18.6782, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.1677, dtype=torch.float64) delta_t tensor(0.1675, dtype=torch.float64)
10 gae_duplicate tensor(-1.3039, dtype=torch.float64) tensor(-4.6933, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.9821, dtype=torch.float64) delta_t tensor(-1.0373, dtype=torch.float64)
9 gae_duplicate tensor(-2.7868, dtype=torch.float64) tensor(20.4390, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.9182, dtype=torch.float64) delta_t tensor(-1.0078, dtype=torch.float64)
8 gae_duplicate tensor(-2.3507, dtype=torch.float64) tensor(21.9595, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.6596, dtype=torch.float64) delta_t tensor(-0.7498, dtype=torch.float64)
7 gae_duplicate tensor(-2.8443, dtype=torch.float64) tensor(16.9396, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.6258, dtype=torch.float64) delta_t tensor(-0.6867, dtype=torch.float64)
6 gae_duplicate tensor(-2.8833, dtype=torch.float64) tensor(15.6820, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.8357, dtype=torch.float64) delta_t tensor(-0.8223, dtype=torch.float64)
5 gae_duplicate tensor(-1.3721, dtype=torch.float64) tensor(17.8437, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-2.6513, dtype=torch.float64) delta_t tensor(-2.6762, dtype=torch.float64)
4 gae_duplicate tensor(-4.7247, dtype=torch.float64) tensor(55.1001, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-0.7853, dtype=torch.float64) delta_t tensor(-0.8031, dtype=torch.float64)
3 gae_duplicate tensor(-1.7460, dtype=torch.float64) tensor(21.5896, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.9184, dtype=torch.float64) delta_t tensor(-0.9703, dtype=torch.float64)
2 gae_duplicate tensor(-1.9249, dtype=torch.float64) tensor(21.3515, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-2454.2138671875
value loss:263.4493713378906
entropies:355.29888916015625
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.310179710388184 seconds
19 rew tensor(0.7058, dtype=torch.float64) delta_t tensor(0.5454, dtype=torch.float64)
19 gae_duplicate tensor(0.3687, dtype=torch.float64) tensor(-10.8489, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6702, dtype=torch.float64) delta_t tensor(0.4991, dtype=torch.float64)
18 gae_duplicate tensor(0.4227, dtype=torch.float64) tensor(-11.4782, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.5540, dtype=torch.float64) delta_t tensor(0.3864, dtype=torch.float64)
17 gae_duplicate tensor(0.1618, dtype=torch.float64) tensor(-8.3780, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.5316, dtype=torch.float64) delta_t tensor(0.3786, dtype=torch.float64)
16 gae_duplicate tensor(0.1731, dtype=torch.float64) tensor(-8.3512, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.7067, dtype=torch.float64) delta_t tensor(0.5685, dtype=torch.float64)
15 gae_duplicate tensor(0.2339, dtype=torch.float64) tensor(-12.0132, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8140, dtype=torch.float64) delta_t tensor(0.7208, dtype=torch.float64)
14 gae_duplicate tensor(0.4340, dtype=torch.float64) tensor(-15.3865, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.7920, dtype=torch.float64) delta_t tensor(0.7520, dtype=torch.float64)
13 gae_duplicate tensor(0.4342, dtype=torch.float64) tensor(-15.8532, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.7877, dtype=torch.float64) delta_t tensor(0.7111, dtype=torch.float64)
12 gae_duplicate tensor(0.3068, dtype=torch.float64) tensor(-15.3529, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.7753, dtype=torch.float64) delta_t tensor(0.6781, dtype=torch.float64)
11 gae_duplicate tensor(0.1606, dtype=torch.float64) tensor(-15.0673, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6994, dtype=torch.float64) delta_t tensor(0.6112, dtype=torch.float64)
10 gae_duplicate tensor(0.1497, dtype=torch.float64) tensor(-13.2099, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.4049, dtype=torch.float64) delta_t tensor(-0.5003, dtype=torch.float64)
9 gae_duplicate tensor(-1.1675, dtype=torch.float64) tensor(9.0690, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.7776, dtype=torch.float64) delta_t tensor(-0.9260, dtype=torch.float64)
8 gae_duplicate tensor(-2.6816, dtype=torch.float64) tensor(19.3281, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.1061, dtype=torch.float64) delta_t tensor(-0.2926, dtype=torch.float64)
7 gae_duplicate tensor(-2.0666, dtype=torch.float64) tensor(7.6075, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-1.3009, dtype=torch.float64) delta_t tensor(-1.4109, dtype=torch.float64)
6 gae_duplicate tensor(-3.5285, dtype=torch.float64) tensor(28.4638, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.9156, dtype=torch.float64) delta_t tensor(-1.0032, dtype=torch.float64)
5 gae_duplicate tensor(-2.6728, dtype=torch.float64) tensor(23.0441, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.3592, dtype=torch.float64) delta_t tensor(-1.4584, dtype=torch.float64)
4 gae_duplicate tensor(-3.3689, dtype=torch.float64) tensor(30.3260, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-0.3921, dtype=torch.float64) delta_t tensor(-0.4684, dtype=torch.float64)
3 gae_duplicate tensor(-0.8094, dtype=torch.float64) tensor(12.4512, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.3451, dtype=torch.float64) delta_t tensor(-0.4793, dtype=torch.float64)
2 gae_duplicate tensor(-0.8845, dtype=torch.float64) tensor(10.6853, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-907.7069091796875
value loss:171.8453826904297
entropies:354.7473449707031
Policy training finished
---------------------
gamma: 0.1
Process Process-9:
Traceback (most recent call last):
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/suhuangyuan/DRA/ToM2C/train.py", line 453, in train
    if train_modes[rank] != -10:
  File "<string>", line 2, in __getitem__
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/managers.py", line 810, in _callmethod
    kind, result = conn.recv()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt