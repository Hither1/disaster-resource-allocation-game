obs <crafter.objects.Shelter object at 0x147e9b940> [39.  0.  0.  0. 39.  0.  0.  0. 19.  0.  0.  0.]
obs <crafter.objects.Warehouse object at 0x126f33df0> [39.  0.  0.  0. 42.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Station object at 0x147ea10a0> [ 9.  0.  0.  0.  9.  0.  0.  0. 11.  0.  0.  0.]
obs <crafter.objects.Shelter object at 0x147e9b940> [39.  0.  0.  0. 39.  0.  0.  0. 19.  0.  0.  0.]
obs <crafter.objects.Warehouse object at 0x126f33df0> [39.  0.  0.  0. 41.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Station object at 0x147ea10a0> [ 9.  0.  0.  0.  9.  0.  0.  0. 10.  0.  0.  0.]
{'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0}
training start after waiting for 2.9379730224609375 seconds
19 rew tensor(0.7982, dtype=torch.float64) delta_t tensor(0.7998, dtype=torch.float64)
19 gae_duplicate tensor(0.7222, dtype=torch.float64) tensor(-15.7309, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8235, dtype=torch.float64) delta_t tensor(0.8148, dtype=torch.float64)
18 gae_duplicate tensor(0.8198, dtype=torch.float64) tensor(-17.6625, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.8531, dtype=torch.float64) delta_t tensor(0.8336, dtype=torch.float64)
17 gae_duplicate tensor(0.8581, dtype=torch.float64) tensor(-18.2293, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.8701, dtype=torch.float64) delta_t tensor(0.8699, dtype=torch.float64)
16 gae_duplicate tensor(0.7755, dtype=torch.float64) tensor(-18.8536, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.8575, dtype=torch.float64) delta_t tensor(0.9224, dtype=torch.float64)
15 gae_duplicate tensor(0.4578, dtype=torch.float64) tensor(-20.2139, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(1.0234, dtype=torch.float64) delta_t tensor(1.0823, dtype=torch.float64)
14 gae_duplicate tensor(1.1018, dtype=torch.float64) tensor(-23.1992, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(1.1019, dtype=torch.float64) delta_t tensor(1.1503, dtype=torch.float64)
13 gae_duplicate tensor(1.2098, dtype=torch.float64) tensor(-24.6034, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(1.2023, dtype=torch.float64) delta_t tensor(1.3700, dtype=torch.float64)
12 gae_duplicate tensor(1.4211, dtype=torch.float64) tensor(-29.6010, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(1.3378, dtype=torch.float64) delta_t tensor(1.4066, dtype=torch.float64)
11 gae_duplicate tensor(1.4698, dtype=torch.float64) tensor(-30.6850, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(1.5157, dtype=torch.float64) delta_t tensor(1.4677, dtype=torch.float64)
10 gae_duplicate tensor(1.5791, dtype=torch.float64) tensor(-31.7619, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(1.3844, dtype=torch.float64) delta_t tensor(1.3999, dtype=torch.float64)
9 gae_duplicate tensor(1.4059, dtype=torch.float64) tensor(-30.9202, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(1.4416, dtype=torch.float64) delta_t tensor(1.4088, dtype=torch.float64)
8 gae_duplicate tensor(1.4779, dtype=torch.float64) tensor(-30.7270, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(1.5262, dtype=torch.float64) delta_t tensor(1.4895, dtype=torch.float64)
7 gae_duplicate tensor(1.5176, dtype=torch.float64) tensor(-32.4040, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(1.6368, dtype=torch.float64) delta_t tensor(1.7363, dtype=torch.float64)
6 gae_duplicate tensor(1.6919, dtype=torch.float64) tensor(-37.5684, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(1.3219, dtype=torch.float64) delta_t tensor(1.3624, dtype=torch.float64)
5 gae_duplicate tensor(1.1676, dtype=torch.float64) tensor(-30.4943, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-0.7440, dtype=torch.float64) delta_t tensor(-0.6409, dtype=torch.float64)
4 gae_duplicate tensor(-0.8064, dtype=torch.float64) tensor(9.6613, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.0250, dtype=torch.float64) delta_t tensor(-0.9005, dtype=torch.float64)
3 gae_duplicate tensor(-1.1170, dtype=torch.float64) tensor(18.7260, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.9342, dtype=torch.float64) delta_t tensor(-0.9904, dtype=torch.float64)
2 gae_duplicate tensor(-1.2920, dtype=torch.float64) tensor(21.2875, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:18424.8515625
value loss:278.26422119140625
entropies:355.7788391113281
Policy training finished
---------------------
gamma: 0.1
/Users/suhuangyuan/DRA/ToM2C/shared_optim.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1420.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
training start after waiting for 4.673214912414551 seconds
19 rew tensor(0.7819, dtype=torch.float64) delta_t tensor(0.7498, dtype=torch.float64)
19 gae_duplicate tensor(0.6761, dtype=torch.float64) tensor(-14.7385, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.7759, dtype=torch.float64) delta_t tensor(0.7087, dtype=torch.float64)
18 gae_duplicate tensor(0.6564, dtype=torch.float64) tensor(-15.9137, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.7264, dtype=torch.float64) delta_t tensor(0.6496, dtype=torch.float64)
17 gae_duplicate tensor(0.4637, dtype=torch.float64) tensor(-13.9295, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6116, dtype=torch.float64) delta_t tensor(0.5673, dtype=torch.float64)
16 gae_duplicate tensor(0.1109, dtype=torch.float64) tensor(-12.7828, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.8833, dtype=torch.float64) delta_t tensor(0.8955, dtype=torch.float64)
15 gae_duplicate tensor(0.8848, dtype=torch.float64) tensor(-18.5718, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9059, dtype=torch.float64) delta_t tensor(0.9086, dtype=torch.float64)
14 gae_duplicate tensor(0.9500, dtype=torch.float64) tensor(-19.7837, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9304, dtype=torch.float64) delta_t tensor(1.0574, dtype=torch.float64)
13 gae_duplicate tensor(0.9915, dtype=torch.float64) tensor(-23.4648, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9570, dtype=torch.float64) delta_t tensor(0.9947, dtype=torch.float64)
12 gae_duplicate tensor(0.9968, dtype=torch.float64) tensor(-22.2859, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.9861, dtype=torch.float64) delta_t tensor(0.9658, dtype=torch.float64)
11 gae_duplicate tensor(1.0055, dtype=torch.float64) tensor(-21.5964, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.9966, dtype=torch.float64) delta_t tensor(0.9364, dtype=torch.float64)
10 gae_duplicate tensor(0.9900, dtype=torch.float64) tensor(-20.6985, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.7339, dtype=torch.float64) delta_t tensor(0.7098, dtype=torch.float64)
9 gae_duplicate tensor(0.7031, dtype=torch.float64) tensor(-16.5133, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.5423, dtype=torch.float64) delta_t tensor(0.4545, dtype=torch.float64)
8 gae_duplicate tensor(0.3730, dtype=torch.float64) tensor(-10.4825, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(0.3052, dtype=torch.float64) delta_t tensor(0.2067, dtype=torch.float64)
7 gae_duplicate tensor(0.0160, dtype=torch.float64) tensor(-5.1164, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.0450, dtype=torch.float64) delta_t tensor(0.0270, dtype=torch.float64)
6 gae_duplicate tensor(-0.5024, dtype=torch.float64) tensor(-1.0854, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.4108, dtype=torch.float64) delta_t tensor(-0.3941, dtype=torch.float64)
5 gae_duplicate tensor(-0.6510, dtype=torch.float64) tensor(7.6683, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.1044, dtype=torch.float64) delta_t tensor(-1.0175, dtype=torch.float64)
4 gae_duplicate tensor(-1.2953, dtype=torch.float64) tensor(20.9881, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.2013, dtype=torch.float64) delta_t tensor(-1.1548, dtype=torch.float64)
3 gae_duplicate tensor(-1.7192, dtype=torch.float64) tensor(25.1939, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.0382, dtype=torch.float64) delta_t tensor(-1.0185, dtype=torch.float64)
2 gae_duplicate tensor(-1.5086, dtype=torch.float64) tensor(22.6763, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:7487.64453125
value loss:131.60057067871094
entropies:355.2990417480469
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.864925146102905 seconds
19 rew tensor(0.8019, dtype=torch.float64) delta_t tensor(0.5840, dtype=torch.float64)
19 gae_duplicate tensor(0.4897, dtype=torch.float64) tensor(-11.4747, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8034, dtype=torch.float64) delta_t tensor(0.6089, dtype=torch.float64)
18 gae_duplicate tensor(0.4908, dtype=torch.float64) tensor(-13.6243, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.7860, dtype=torch.float64) delta_t tensor(0.5777, dtype=torch.float64)
17 gae_duplicate tensor(0.3434, dtype=torch.float64) tensor(-12.3274, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.7399, dtype=torch.float64) delta_t tensor(0.5482, dtype=torch.float64)
16 gae_duplicate tensor(0.0513, dtype=torch.float64) tensor(-11.9429, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.8652, dtype=torch.float64) delta_t tensor(0.7259, dtype=torch.float64)
15 gae_duplicate tensor(0.7016, dtype=torch.float64) tensor(-15.5638, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8791, dtype=torch.float64) delta_t tensor(0.7821, dtype=torch.float64)
14 gae_duplicate tensor(0.7710, dtype=torch.float64) tensor(-16.8940, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8936, dtype=torch.float64) delta_t tensor(0.8418, dtype=torch.float64)
13 gae_duplicate tensor(0.7317, dtype=torch.float64) tensor(-17.9941, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9089, dtype=torch.float64) delta_t tensor(0.8246, dtype=torch.float64)
12 gae_duplicate tensor(0.6984, dtype=torch.float64) tensor(-18.4443, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.9250, dtype=torch.float64) delta_t tensor(0.6989, dtype=torch.float64)
11 gae_duplicate tensor(0.6960, dtype=torch.float64) tensor(-15.5523, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.9326, dtype=torch.float64) delta_t tensor(0.7043, dtype=torch.float64)
10 gae_duplicate tensor(0.7005, dtype=torch.float64) tensor(-15.2030, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.1887, dtype=torch.float64) delta_t tensor(-0.0409, dtype=torch.float64)
9 gae_duplicate tensor(-2.6717, dtype=torch.float64) tensor(-1.0736, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.8882, dtype=torch.float64) delta_t tensor(-1.1244, dtype=torch.float64)
8 gae_duplicate tensor(-3.5977, dtype=torch.float64) tensor(22.0176, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(0.0325, dtype=torch.float64) delta_t tensor(-0.1750, dtype=torch.float64)
7 gae_duplicate tensor(-1.1892, dtype=torch.float64) tensor(5.4503, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.5165, dtype=torch.float64) delta_t tensor(-0.5169, dtype=torch.float64)
6 gae_duplicate tensor(-2.0078, dtype=torch.float64) tensor(10.6660, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7224, dtype=torch.float64) delta_t tensor(-0.8019, dtype=torch.float64)
5 gae_duplicate tensor(-1.3123, dtype=torch.float64) tensor(17.1262, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.2255, dtype=torch.float64) delta_t tensor(-1.2076, dtype=torch.float64)
4 gae_duplicate tensor(-2.0991, dtype=torch.float64) tensor(25.2095, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.5760, dtype=torch.float64) delta_t tensor(-1.7637, dtype=torch.float64)
3 gae_duplicate tensor(-2.4222, dtype=torch.float64) tensor(37.3829, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.4398, dtype=torch.float64) delta_t tensor(-1.5398, dtype=torch.float64)
2 gae_duplicate tensor(-2.1812, dtype=torch.float64) tensor(34.2461, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-204.1540069580078
value loss:196.1778564453125
entropies:355.2812194824219
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.948843955993652 seconds
19 rew tensor(0.7469, dtype=torch.float64) delta_t tensor(0.3356, dtype=torch.float64)
19 gae_duplicate tensor(0.2470, dtype=torch.float64) tensor(-6.7431, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6682, dtype=torch.float64) delta_t tensor(0.2797, dtype=torch.float64)
18 gae_duplicate tensor(0.1194, dtype=torch.float64) tensor(-6.1688, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.5014, dtype=torch.float64) delta_t tensor(0.1411, dtype=torch.float64)
17 gae_duplicate tensor(-0.2141, dtype=torch.float64) tensor(-3.3187, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6682, dtype=torch.float64) delta_t tensor(0.3338, dtype=torch.float64)
16 gae_duplicate tensor(-0.1885, dtype=torch.float64) tensor(-7.0090, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.7437, dtype=torch.float64) delta_t tensor(0.4497, dtype=torch.float64)
15 gae_duplicate tensor(-0.1342, dtype=torch.float64) tensor(-9.7323, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8740, dtype=torch.float64) delta_t tensor(0.6914, dtype=torch.float64)
14 gae_duplicate tensor(0.5563, dtype=torch.float64) tensor(-14.7450, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8844, dtype=torch.float64) delta_t tensor(0.6287, dtype=torch.float64)
13 gae_duplicate tensor(0.5613, dtype=torch.float64) tensor(-13.8903, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8953, dtype=torch.float64) delta_t tensor(0.6075, dtype=torch.float64)
12 gae_duplicate tensor(0.5974, dtype=torch.float64) tensor(-13.4161, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8852, dtype=torch.float64) delta_t tensor(0.5680, dtype=torch.float64)
11 gae_duplicate tensor(0.5293, dtype=torch.float64) tensor(-12.7110, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.4394, dtype=torch.float64) delta_t tensor(0.0714, dtype=torch.float64)
10 gae_duplicate tensor(-1.9650, dtype=torch.float64) tensor(-2.9954, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.0641, dtype=torch.float64) delta_t tensor(-0.2795, dtype=torch.float64)
9 gae_duplicate tensor(-2.0081, dtype=torch.float64) tensor(5.2986, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.2697, dtype=torch.float64) delta_t tensor(-0.0417, dtype=torch.float64)
8 gae_duplicate tensor(-1.2775, dtype=torch.float64) tensor(1.2144, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(0.1661, dtype=torch.float64) delta_t tensor(-0.1682, dtype=torch.float64)
7 gae_duplicate tensor(-0.3387, dtype=torch.float64) tensor(3.4457, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.4759, dtype=torch.float64) delta_t tensor(-0.6026, dtype=torch.float64)
6 gae_duplicate tensor(-1.4509, dtype=torch.float64) tensor(12.1678, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.9938, dtype=torch.float64) delta_t tensor(-1.1229, dtype=torch.float64)
5 gae_duplicate tensor(-2.9832, dtype=torch.float64) tensor(23.6612, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.2021, dtype=torch.float64) delta_t tensor(-1.2282, dtype=torch.float64)
4 gae_duplicate tensor(-1.7218, dtype=torch.float64) tensor(26.2175, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.5297, dtype=torch.float64) delta_t tensor(-1.6656, dtype=torch.float64)
3 gae_duplicate tensor(-2.1131, dtype=torch.float64) tensor(35.2475, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.3814, dtype=torch.float64) delta_t tensor(-1.4945, dtype=torch.float64)
2 gae_duplicate tensor(-2.4083, dtype=torch.float64) tensor(32.9777, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-2769.03125
value loss:142.7478485107422
entropies:355.52886962890625
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.069201946258545 seconds
19 rew tensor(0.7944, dtype=torch.float64) delta_t tensor(0.3056, dtype=torch.float64)
19 gae_duplicate tensor(0.2011, dtype=torch.float64) tensor(-6.1334, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.7733, dtype=torch.float64) delta_t tensor(0.3110, dtype=torch.float64)
18 gae_duplicate tensor(0.1974, dtype=torch.float64) tensor(-6.7450, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6970, dtype=torch.float64) delta_t tensor(0.2231, dtype=torch.float64)
17 gae_duplicate tensor(0.0370, dtype=torch.float64) tensor(-5.0528, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.5377, dtype=torch.float64) delta_t tensor(0.0922, dtype=torch.float64)
16 gae_duplicate tensor(-0.2474, dtype=torch.float64) tensor(-2.3321, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.8706, dtype=torch.float64) delta_t tensor(0.4691, dtype=torch.float64)
15 gae_duplicate tensor(0.3601, dtype=torch.float64) tensor(-9.5945, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8787, dtype=torch.float64) delta_t tensor(0.4690, dtype=torch.float64)
14 gae_duplicate tensor(0.4279, dtype=torch.float64) tensor(-10.2290, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8870, dtype=torch.float64) delta_t tensor(0.6784, dtype=torch.float64)
13 gae_duplicate tensor(0.5445, dtype=torch.float64) tensor(-14.3584, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8956, dtype=torch.float64) delta_t tensor(0.5592, dtype=torch.float64)
12 gae_duplicate tensor(0.4507, dtype=torch.float64) tensor(-12.3772, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.9044, dtype=torch.float64) delta_t tensor(0.4606, dtype=torch.float64)
11 gae_duplicate tensor(0.4736, dtype=torch.float64) tensor(-10.3998, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.4682, dtype=torch.float64) delta_t tensor(0.0121, dtype=torch.float64)
10 gae_duplicate tensor(-1.7880, dtype=torch.float64) tensor(-1.2485, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.5474, dtype=torch.float64) delta_t tensor(-0.9685, dtype=torch.float64)
9 gae_duplicate tensor(-3.7989, dtype=torch.float64) tensor(19.5402, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.1009, dtype=torch.float64) delta_t tensor(-0.5172, dtype=torch.float64)
8 gae_duplicate tensor(-2.1595, dtype=torch.float64) tensor(12.0643, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(0.1969, dtype=torch.float64) delta_t tensor(-0.2489, dtype=torch.float64)
7 gae_duplicate tensor(-0.5278, dtype=torch.float64) tensor(6.1055, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.1727, dtype=torch.float64) delta_t tensor(-0.3872, dtype=torch.float64)
6 gae_duplicate tensor(-0.6095, dtype=torch.float64) tensor(8.2770, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.6934, dtype=torch.float64) delta_t tensor(-0.8219, dtype=torch.float64)
5 gae_duplicate tensor(-1.1737, dtype=torch.float64) tensor(17.2226, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.4188, dtype=torch.float64) delta_t tensor(-1.4801, dtype=torch.float64)
4 gae_duplicate tensor(-2.4015, dtype=torch.float64) tensor(30.7621, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.6220, dtype=torch.float64) delta_t tensor(-1.7595, dtype=torch.float64)
3 gae_duplicate tensor(-2.1085, dtype=torch.float64) tensor(38.0004, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.4366, dtype=torch.float64) delta_t tensor(-1.5629, dtype=torch.float64)
2 gae_duplicate tensor(-2.2603, dtype=torch.float64) tensor(34.7022, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-4859.046875
value loss:167.06202697753906
entropies:355.77374267578125
Policy training finished
---------------------
ToM training started
ToM data loaded
batch_size =  600
ToM_loss = tensor(3970.7056)
ToM Target loss= tensor(3609.3210)
optimized based on ToM loss
---------------------
gamma: 0.1
training start after waiting for 5.090546131134033 seconds
19 rew tensor(0.8277, dtype=torch.float64) delta_t tensor(0.2471, dtype=torch.float64)
19 gae_duplicate tensor(0.1596, dtype=torch.float64) tensor(-4.8611, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8225, dtype=torch.float64) delta_t tensor(0.2641, dtype=torch.float64)
18 gae_duplicate tensor(0.1730, dtype=torch.float64) tensor(-5.7411, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.7954, dtype=torch.float64) delta_t tensor(0.2424, dtype=torch.float64)
17 gae_duplicate tensor(-0.0223, dtype=torch.float64) tensor(-5.4036, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.7353, dtype=torch.float64) delta_t tensor(0.2051, dtype=torch.float64)
16 gae_duplicate tensor(-0.4004, dtype=torch.float64) tensor(-4.6321, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.8718, dtype=torch.float64) delta_t tensor(0.3747, dtype=torch.float64)
15 gae_duplicate tensor(0.3206, dtype=torch.float64) tensor(-7.8671, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8785, dtype=torch.float64) delta_t tensor(0.3698, dtype=torch.float64)
14 gae_duplicate tensor(0.3274, dtype=torch.float64) tensor(-8.1622, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8854, dtype=torch.float64) delta_t tensor(0.5231, dtype=torch.float64)
13 gae_duplicate tensor(0.3143, dtype=torch.float64) tensor(-11.1123, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8924, dtype=torch.float64) delta_t tensor(0.4911, dtype=torch.float64)
12 gae_duplicate tensor(0.3905, dtype=torch.float64) tensor(-10.9313, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8996, dtype=torch.float64) delta_t tensor(0.3968, dtype=torch.float64)
11 gae_duplicate tensor(0.4044, dtype=torch.float64) tensor(-8.9314, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.4605, dtype=torch.float64) delta_t tensor(-0.0751, dtype=torch.float64)
10 gae_duplicate tensor(-2.1361, dtype=torch.float64) tensor(0.4893, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.6093, dtype=torch.float64) delta_t tensor(0.1268, dtype=torch.float64)
9 gae_duplicate tensor(-0.0604, dtype=torch.float64) tensor(-2.4600, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.3513, dtype=torch.float64) delta_t tensor(-0.1019, dtype=torch.float64)
8 gae_duplicate tensor(-0.2966, dtype=torch.float64) tensor(1.7619, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(0.0352, dtype=torch.float64) delta_t tensor(-0.4610, dtype=torch.float64)
7 gae_duplicate tensor(-0.6301, dtype=torch.float64) tensor(9.2942, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.2608, dtype=torch.float64) delta_t tensor(-0.4094, dtype=torch.float64)
6 gae_duplicate tensor(-0.7802, dtype=torch.float64) tensor(8.9833, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.6936, dtype=torch.float64) delta_t tensor(-0.8021, dtype=torch.float64)
5 gae_duplicate tensor(-0.9791, dtype=torch.float64) tensor(16.8008, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.6617, dtype=torch.float64) delta_t tensor(-1.6910, dtype=torch.float64)
4 gae_duplicate tensor(-2.0020, dtype=torch.float64) tensor(35.0796, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.5839, dtype=torch.float64) delta_t tensor(-1.5136, dtype=torch.float64)
3 gae_duplicate tensor(-1.8127, dtype=torch.float64) tensor(33.3650, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.3140, dtype=torch.float64) delta_t tensor(-1.4793, dtype=torch.float64)
2 gae_duplicate tensor(-1.9177, dtype=torch.float64) tensor(32.2972, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-3766.398681640625
value loss:113.83417510986328
entropies:355.8358459472656
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.9284539222717285 seconds
19 rew tensor(0.7859, dtype=torch.float64) delta_t tensor(0.1675, dtype=torch.float64)
19 gae_duplicate tensor(0.0266, dtype=torch.float64) tensor(-3.3219, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.7407, dtype=torch.float64) delta_t tensor(0.1572, dtype=torch.float64)
18 gae_duplicate tensor(-0.0770, dtype=torch.float64) tensor(-3.4524, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6456, dtype=torch.float64) delta_t tensor(0.0592, dtype=torch.float64)
17 gae_duplicate tensor(-0.3842, dtype=torch.float64) tensor(-1.4952, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6649, dtype=torch.float64) delta_t tensor(0.0781, dtype=torch.float64)
16 gae_duplicate tensor(-0.4811, dtype=torch.float64) tensor(-1.7026, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.7230, dtype=torch.float64) delta_t tensor(0.1784, dtype=torch.float64)
15 gae_duplicate tensor(-0.5361, dtype=torch.float64) tensor(-3.6915, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8657, dtype=torch.float64) delta_t tensor(0.3857, dtype=torch.float64)
14 gae_duplicate tensor(0.2459, dtype=torch.float64) tensor(-7.9536, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8713, dtype=torch.float64) delta_t tensor(0.4604, dtype=torch.float64)
13 gae_duplicate tensor(0.2622, dtype=torch.float64) tensor(-9.8992, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8771, dtype=torch.float64) delta_t tensor(0.3811, dtype=torch.float64)
12 gae_duplicate tensor(0.2849, dtype=torch.float64) tensor(-8.5153, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8737, dtype=torch.float64) delta_t tensor(0.3148, dtype=torch.float64)
11 gae_duplicate tensor(0.2907, dtype=torch.float64) tensor(-7.0907, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.4456, dtype=torch.float64) delta_t tensor(-0.1009, dtype=torch.float64)
10 gae_duplicate tensor(-2.1669, dtype=torch.float64) tensor(1.3347, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.2705, dtype=torch.float64) delta_t tensor(-0.8200, dtype=torch.float64)
9 gae_duplicate tensor(-3.5058, dtype=torch.float64) tensor(16.4032, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.3753, dtype=torch.float64) delta_t tensor(-0.9129, dtype=torch.float64)
8 gae_duplicate tensor(-4.5385, dtype=torch.float64) tensor(19.7388, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.4107, dtype=torch.float64) delta_t tensor(-0.9392, dtype=torch.float64)
7 gae_duplicate tensor(-4.3034, dtype=torch.float64) tensor(20.6015, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.2471, dtype=torch.float64) delta_t tensor(-0.5514, dtype=torch.float64)
6 gae_duplicate tensor(-1.8204, dtype=torch.float64) tensor(12.9575, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.4874, dtype=torch.float64) delta_t tensor(-0.6132, dtype=torch.float64)
5 gae_duplicate tensor(-1.1020, dtype=torch.float64) tensor(13.3922, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.0962, dtype=torch.float64) delta_t tensor(-1.1466, dtype=torch.float64)
4 gae_duplicate tensor(-1.8138, dtype=torch.float64) tensor(23.9720, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.4743, dtype=torch.float64) delta_t tensor(-1.5962, dtype=torch.float64)
3 gae_duplicate tensor(-1.9706, dtype=torch.float64) tensor(34.0318, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.3177, dtype=torch.float64) delta_t tensor(-1.4810, dtype=torch.float64)
2 gae_duplicate tensor(-2.1744, dtype=torch.float64) tensor(32.5713, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-7001.6484375
value loss:184.60177612304688
entropies:355.90972900390625
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.780418157577515 seconds
19 rew tensor(0.7886, dtype=torch.float64) delta_t tensor(0.1243, dtype=torch.float64)
19 gae_duplicate tensor(0.0250, dtype=torch.float64) tensor(-2.4622, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.7615, dtype=torch.float64) delta_t tensor(0.1356, dtype=torch.float64)
18 gae_duplicate tensor(0.0243, dtype=torch.float64) tensor(-2.9187, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6721, dtype=torch.float64) delta_t tensor(0.0414, dtype=torch.float64)
17 gae_duplicate tensor(-0.1554, dtype=torch.float64) tensor(-1.1004, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.4893, dtype=torch.float64) delta_t tensor(-0.1246, dtype=torch.float64)
16 gae_duplicate tensor(-0.5355, dtype=torch.float64) tensor(2.3565, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.8629, dtype=torch.float64) delta_t tensor(0.2972, dtype=torch.float64)
15 gae_duplicate tensor(0.1714, dtype=torch.float64) tensor(-5.6473, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8678, dtype=torch.float64) delta_t tensor(0.2844, dtype=torch.float64)
14 gae_duplicate tensor(0.2381, dtype=torch.float64) tensor(-6.1771, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8728, dtype=torch.float64) delta_t tensor(0.5260, dtype=torch.float64)
13 gae_duplicate tensor(0.2895, dtype=torch.float64) tensor(-11.0028, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8778, dtype=torch.float64) delta_t tensor(0.3599, dtype=torch.float64)
12 gae_duplicate tensor(0.2550, dtype=torch.float64) tensor(-8.2038, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8829, dtype=torch.float64) delta_t tensor(0.2841, dtype=torch.float64)
11 gae_duplicate tensor(0.2683, dtype=torch.float64) tensor(-6.4577, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.8574, dtype=torch.float64) delta_t tensor(0.2644, dtype=torch.float64)
10 gae_duplicate tensor(0.2231, dtype=torch.float64) tensor(-5.8637, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.1347, dtype=torch.float64) delta_t tensor(-0.7065, dtype=torch.float64)
9 gae_duplicate tensor(-2.3521, dtype=torch.float64) tensor(13.3537, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.5512, dtype=torch.float64) delta_t tensor(-1.0893, dtype=torch.float64)
8 gae_duplicate tensor(-3.4177, dtype=torch.float64) tensor(22.8723, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.0486, dtype=torch.float64) delta_t tensor(-0.5883, dtype=torch.float64)
7 gae_duplicate tensor(-1.6470, dtype=torch.float64) tensor(13.9177, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.1592, dtype=torch.float64) delta_t tensor(-0.3338, dtype=torch.float64)
6 gae_duplicate tensor(-0.7303, dtype=torch.float64) tensor(7.9895, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.4843, dtype=torch.float64) delta_t tensor(-0.6028, dtype=torch.float64)
5 gae_duplicate tensor(-0.8939, dtype=torch.float64) tensor(12.7527, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.2699, dtype=torch.float64) delta_t tensor(-1.2285, dtype=torch.float64)
4 gae_duplicate tensor(-2.1595, dtype=torch.float64) tensor(25.5871, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.4769, dtype=torch.float64) delta_t tensor(-1.5240, dtype=torch.float64)
3 gae_duplicate tensor(-2.0770, dtype=torch.float64) tensor(32.6869, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.3179, dtype=torch.float64) delta_t tensor(-1.2951, dtype=torch.float64)
2 gae_duplicate tensor(-2.0985, dtype=torch.float64) tensor(28.7374, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-6058.796875
value loss:130.75596618652344
entropies:355.92974853515625
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.892219305038452 seconds
19 rew tensor(0.7868, dtype=torch.float64) delta_t tensor(0.1914, dtype=torch.float64)
19 gae_duplicate tensor(0.0278, dtype=torch.float64) tensor(-3.8009, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.7427, dtype=torch.float64) delta_t tensor(0.1755, dtype=torch.float64)
18 gae_duplicate tensor(-0.0711, dtype=torch.float64) tensor(-3.8444, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6309, dtype=torch.float64) delta_t tensor(0.0661, dtype=torch.float64)
17 gae_duplicate tensor(-0.3787, dtype=torch.float64) tensor(-1.6641, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6262, dtype=torch.float64) delta_t tensor(0.0406, dtype=torch.float64)
16 gae_duplicate tensor(-0.4587, dtype=torch.float64) tensor(-0.9735, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.8658, dtype=torch.float64) delta_t tensor(0.3215, dtype=torch.float64)
15 gae_duplicate tensor(0.2044, dtype=torch.float64) tensor(-6.4232, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8701, dtype=torch.float64) delta_t tensor(0.3979, dtype=torch.float64)
14 gae_duplicate tensor(0.2708, dtype=torch.float64) tensor(-8.4890, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8745, dtype=torch.float64) delta_t tensor(0.4674, dtype=torch.float64)
13 gae_duplicate tensor(0.3285, dtype=torch.float64) tensor(-10.1090, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8790, dtype=torch.float64) delta_t tensor(0.4967, dtype=torch.float64)
12 gae_duplicate tensor(0.2721, dtype=torch.float64) tensor(-10.8405, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8743, dtype=torch.float64) delta_t tensor(0.3203, dtype=torch.float64)
11 gae_duplicate tensor(0.3137, dtype=torch.float64) tensor(-7.4149, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.4951, dtype=torch.float64) delta_t tensor(-0.0439, dtype=torch.float64)
10 gae_duplicate tensor(-1.8907, dtype=torch.float64) tensor(0.1490, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.5580, dtype=torch.float64) delta_t tensor(-1.0347, dtype=torch.float64)
9 gae_duplicate tensor(-3.4181, dtype=torch.float64) tensor(20.4035, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.0124, dtype=torch.float64) delta_t tensor(-0.4621, dtype=torch.float64)
8 gae_duplicate tensor(-1.4663, dtype=torch.float64) tensor(11.1806, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.4279, dtype=torch.float64) delta_t tensor(-0.9036, dtype=torch.float64)
7 gae_duplicate tensor(-3.5558, dtype=torch.float64) tensor(18.8884, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.2392, dtype=torch.float64) delta_t tensor(-0.2672, dtype=torch.float64)
6 gae_duplicate tensor(-0.5206, dtype=torch.float64) tensor(7.1746, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.6015, dtype=torch.float64) delta_t tensor(-0.5565, dtype=torch.float64)
5 gae_duplicate tensor(-0.9441, dtype=torch.float64) tensor(11.6664, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.2695, dtype=torch.float64) delta_t tensor(-1.1028, dtype=torch.float64)
4 gae_duplicate tensor(-1.8645, dtype=torch.float64) tensor(22.9845, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.4518, dtype=torch.float64) delta_t tensor(-1.3976, dtype=torch.float64)
3 gae_duplicate tensor(-1.7488, dtype=torch.float64) tensor(29.8984, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.2410, dtype=torch.float64) delta_t tensor(-1.1711, dtype=torch.float64)
2 gae_duplicate tensor(-1.7309, dtype=torch.float64) tensor(26.2781, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-5229.5390625
value loss:134.582763671875
entropies:355.93060302734375
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.793384790420532 seconds
19 rew tensor(0.8040, dtype=torch.float64) delta_t tensor(0.2182, dtype=torch.float64)
19 gae_duplicate tensor(0.0493, dtype=torch.float64) tensor(-4.3196, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.7684, dtype=torch.float64) delta_t tensor(0.2258, dtype=torch.float64)
18 gae_duplicate tensor(-0.0513, dtype=torch.float64) tensor(-4.8935, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6828, dtype=torch.float64) delta_t tensor(0.1467, dtype=torch.float64)
17 gae_duplicate tensor(-0.3600, dtype=torch.float64) tensor(-3.4086, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.7308, dtype=torch.float64) delta_t tensor(0.1911, dtype=torch.float64)
16 gae_duplicate tensor(-0.4298, dtype=torch.float64) tensor(-4.1197, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.8658, dtype=torch.float64) delta_t tensor(0.3844, dtype=torch.float64)
15 gae_duplicate tensor(0.3200, dtype=torch.float64) tensor(-8.0191, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8697, dtype=torch.float64) delta_t tensor(0.4368, dtype=torch.float64)
14 gae_duplicate tensor(0.3423, dtype=torch.float64) tensor(-9.4551, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8737, dtype=torch.float64) delta_t tensor(0.4070, dtype=torch.float64)
13 gae_duplicate tensor(0.3467, dtype=torch.float64) tensor(-8.9744, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8777, dtype=torch.float64) delta_t tensor(0.5104, dtype=torch.float64)
12 gae_duplicate tensor(0.3986, dtype=torch.float64) tensor(-10.9988, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8725, dtype=torch.float64) delta_t tensor(0.3603, dtype=torch.float64)
11 gae_duplicate tensor(0.3602, dtype=torch.float64) tensor(-8.2197, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6464, dtype=torch.float64) delta_t tensor(0.1397, dtype=torch.float64)
10 gae_duplicate tensor(-0.8937, dtype=torch.float64) tensor(-3.5849, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.2069, dtype=torch.float64) delta_t tensor(-0.3002, dtype=torch.float64)
9 gae_duplicate tensor(-1.9128, dtype=torch.float64) tensor(5.5750, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.1443, dtype=torch.float64) delta_t tensor(-0.5211, dtype=torch.float64)
8 gae_duplicate tensor(-3.2648, dtype=torch.float64) tensor(10.8936, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(0.1727, dtype=torch.float64) delta_t tensor(-0.2352, dtype=torch.float64)
7 gae_duplicate tensor(-0.4271, dtype=torch.float64) tensor(5.7185, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.2765, dtype=torch.float64) delta_t tensor(-0.1355, dtype=torch.float64)
6 gae_duplicate tensor(-0.4773, dtype=torch.float64) tensor(3.2464, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.6319, dtype=torch.float64) delta_t tensor(-0.4464, dtype=torch.float64)
5 gae_duplicate tensor(-0.5868, dtype=torch.float64) tensor(9.1608, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.5784, dtype=torch.float64) delta_t tensor(-1.3381, dtype=torch.float64)
4 gae_duplicate tensor(-1.9783, dtype=torch.float64) tensor(27.3348, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.6989, dtype=torch.float64) delta_t tensor(-1.3813, dtype=torch.float64)
3 gae_duplicate tensor(-1.8895, dtype=torch.float64) tensor(30.0848, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.4893, dtype=torch.float64) delta_t tensor(-1.3640, dtype=torch.float64)
2 gae_duplicate tensor(-2.1370, dtype=torch.float64) tensor(30.0839, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-3125.73974609375
value loss:105.54832458496094
entropies:355.9417724609375
Policy training finished
---------------------
ToM training started
ToM data loaded
batch_size =  600
ToM_loss = tensor(3957.2434)
ToM Target loss= tensor(3623.2410)
optimized based on ToM loss
---------------------
gamma: 0.1
training start after waiting for 4.864228248596191 seconds
19 rew tensor(0.8011, dtype=torch.float64) delta_t tensor(0.3052, dtype=torch.float64)
19 gae_duplicate tensor(0.1479, dtype=torch.float64) tensor(-6.0198, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.7854, dtype=torch.float64) delta_t tensor(0.3229, dtype=torch.float64)
18 gae_duplicate tensor(0.1867, dtype=torch.float64) tensor(-6.9849, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.7229, dtype=torch.float64) delta_t tensor(0.2590, dtype=torch.float64)
17 gae_duplicate tensor(0.0047, dtype=torch.float64) tensor(-5.8151, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.5763, dtype=torch.float64) delta_t tensor(0.0894, dtype=torch.float64)
16 gae_duplicate tensor(-0.3244, dtype=torch.float64) tensor(-2.3413, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.7462, dtype=torch.float64) delta_t tensor(0.3077, dtype=torch.float64)
15 gae_duplicate tensor(-0.4264, dtype=torch.float64) tensor(-6.3187, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8699, dtype=torch.float64) delta_t tensor(0.4139, dtype=torch.float64)
14 gae_duplicate tensor(0.2618, dtype=torch.float64) tensor(-8.8278, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8734, dtype=torch.float64) delta_t tensor(0.6228, dtype=torch.float64)
13 gae_duplicate tensor(0.3657, dtype=torch.float64) tensor(-13.1798, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8771, dtype=torch.float64) delta_t tensor(0.5121, dtype=torch.float64)
12 gae_duplicate tensor(0.4036, dtype=torch.float64) tensor(-11.4485, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8807, dtype=torch.float64) delta_t tensor(0.4682, dtype=torch.float64)
11 gae_duplicate tensor(0.4481, dtype=torch.float64) tensor(-10.3732, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.4796, dtype=torch.float64) delta_t tensor(0.0651, dtype=torch.float64)
10 gae_duplicate tensor(-1.7965, dtype=torch.float64) tensor(-2.3007, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.4452, dtype=torch.float64) delta_t tensor(0.0880, dtype=torch.float64)
9 gae_duplicate tensor(-0.6770, dtype=torch.float64) tensor(-1.9660, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.5422, dtype=torch.float64) delta_t tensor(-0.8811, dtype=torch.float64)
8 gae_duplicate tensor(-3.1165, dtype=torch.float64) tensor(17.1719, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.3910, dtype=torch.float64) delta_t tensor(-0.7068, dtype=torch.float64)
7 gae_duplicate tensor(-2.3247, dtype=torch.float64) tensor(15.6586, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.3011, dtype=torch.float64) delta_t tensor(-0.1688, dtype=torch.float64)
6 gae_duplicate tensor(-1.3639, dtype=torch.float64) tensor(4.8889, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.5177, dtype=torch.float64) delta_t tensor(-0.2757, dtype=torch.float64)
5 gae_duplicate tensor(-0.5092, dtype=torch.float64) tensor(5.9498, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.2800, dtype=torch.float64) delta_t tensor(-0.8682, dtype=torch.float64)
4 gae_duplicate tensor(-1.4582, dtype=torch.float64) tensor(17.7526, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.5393, dtype=torch.float64) delta_t tensor(-1.1907, dtype=torch.float64)
3 gae_duplicate tensor(-1.6428, dtype=torch.float64) tensor(25.3729, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.4107, dtype=torch.float64) delta_t tensor(-1.0864, dtype=torch.float64)
2 gae_duplicate tensor(-1.5628, dtype=torch.float64) tensor(23.9462, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-1995.0162353515625
value loss:103.86116027832031
entropies:355.9404602050781
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.055361986160278 seconds
19 rew tensor(0.8306, dtype=torch.float64) delta_t tensor(0.3765, dtype=torch.float64)
19 gae_duplicate tensor(0.2856, dtype=torch.float64) tensor(-7.4313, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8228, dtype=torch.float64) delta_t tensor(0.3997, dtype=torch.float64)
18 gae_duplicate tensor(0.2494, dtype=torch.float64) tensor(-8.6564, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.7936, dtype=torch.float64) delta_t tensor(0.3736, dtype=torch.float64)
17 gae_duplicate tensor(0.0649, dtype=torch.float64) tensor(-8.2369, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.7322, dtype=torch.float64) delta_t tensor(0.3004, dtype=torch.float64)
16 gae_duplicate tensor(-0.3057, dtype=torch.float64) tensor(-6.7516, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.8630, dtype=torch.float64) delta_t tensor(0.4774, dtype=torch.float64)
15 gae_duplicate tensor(0.3990, dtype=torch.float64) tensor(-10.1166, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8662, dtype=torch.float64) delta_t tensor(0.4673, dtype=torch.float64)
14 gae_duplicate tensor(0.4040, dtype=torch.float64) tensor(-10.2523, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8695, dtype=torch.float64) delta_t tensor(0.5804, dtype=torch.float64)
13 gae_duplicate tensor(0.4185, dtype=torch.float64) tensor(-12.5037, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8727, dtype=torch.float64) delta_t tensor(0.5994, dtype=torch.float64)
12 gae_duplicate tensor(0.5143, dtype=torch.float64) tensor(-13.1032, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8761, dtype=torch.float64) delta_t tensor(0.4689, dtype=torch.float64)
11 gae_duplicate tensor(0.4821, dtype=torch.float64) tensor(-10.5502, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.8688, dtype=torch.float64) delta_t tensor(0.4844, dtype=torch.float64)
10 gae_duplicate tensor(0.4739, dtype=torch.float64) tensor(-10.6338, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.1914, dtype=torch.float64) delta_t tensor(-0.4932, dtype=torch.float64)
9 gae_duplicate tensor(-4.5750, dtype=torch.float64) tensor(8.6885, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.2076, dtype=torch.float64) delta_t tensor(-0.4626, dtype=torch.float64)
8 gae_duplicate tensor(-2.0533, dtype=torch.float64) tensor(9.9562, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.1866, dtype=torch.float64) delta_t tensor(-0.4275, dtype=torch.float64)
7 gae_duplicate tensor(-2.4546, dtype=torch.float64) tensor(9.4685, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.1405, dtype=torch.float64) delta_t tensor(0.2854, dtype=torch.float64)
6 gae_duplicate tensor(-0.2009, dtype=torch.float64) tensor(-4.7083, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.5686, dtype=torch.float64) delta_t tensor(-0.1501, dtype=torch.float64)
5 gae_duplicate tensor(-0.3130, dtype=torch.float64) tensor(2.5052, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.4379, dtype=torch.float64) delta_t tensor(-0.8756, dtype=torch.float64)
4 gae_duplicate tensor(-1.4646, dtype=torch.float64) tensor(17.5590, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.5539, dtype=torch.float64) delta_t tensor(-0.9859, dtype=torch.float64)
3 gae_duplicate tensor(-1.4435, dtype=torch.float64) tensor(21.2602, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.4099, dtype=torch.float64) delta_t tensor(-0.9967, dtype=torch.float64)
2 gae_duplicate tensor(-1.6118, dtype=torch.float64) tensor(21.8281, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:534.5447998046875
value loss:110.10506439208984
entropies:355.9399108886719
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.09522271156311 seconds
19 rew tensor(0.7790, dtype=torch.float64) delta_t tensor(0.3346, dtype=torch.float64)
19 gae_duplicate tensor(0.2496, dtype=torch.float64) tensor(-6.6090, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.7516, dtype=torch.float64) delta_t tensor(0.3206, dtype=torch.float64)
18 gae_duplicate tensor(0.2675, dtype=torch.float64) tensor(-6.9943, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.6548, dtype=torch.float64) delta_t tensor(0.2206, dtype=torch.float64)
17 gae_duplicate tensor(0.0933, dtype=torch.float64) tensor(-5.0593, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.4397, dtype=torch.float64) delta_t tensor(0.0200, dtype=torch.float64)
16 gae_duplicate tensor(-0.2883, dtype=torch.float64) tensor(-0.8884, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.7401, dtype=torch.float64) delta_t tensor(0.3185, dtype=torch.float64)
15 gae_duplicate tensor(-0.3527, dtype=torch.float64) tensor(-6.3883, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8670, dtype=torch.float64) delta_t tensor(0.4454, dtype=torch.float64)
14 gae_duplicate tensor(0.3568, dtype=torch.float64) tensor(-9.4472, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8700, dtype=torch.float64) delta_t tensor(0.6281, dtype=torch.float64)
13 gae_duplicate tensor(0.4373, dtype=torch.float64) tensor(-13.3650, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8730, dtype=torch.float64) delta_t tensor(0.5852, dtype=torch.float64)
12 gae_duplicate tensor(0.5060, dtype=torch.float64) tensor(-12.9094, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8761, dtype=torch.float64) delta_t tensor(0.5316, dtype=torch.float64)
11 gae_duplicate tensor(0.5294, dtype=torch.float64) tensor(-11.8025, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6320, dtype=torch.float64) delta_t tensor(0.2781, dtype=torch.float64)
10 gae_duplicate tensor(-0.5572, dtype=torch.float64) tensor(-6.6753, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(-0.1483, dtype=torch.float64) delta_t tensor(-0.3912, dtype=torch.float64)
9 gae_duplicate tensor(-1.7911, dtype=torch.float64) tensor(7.0436, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.1641, dtype=torch.float64) delta_t tensor(0.0142, dtype=torch.float64)
8 gae_duplicate tensor(-0.8456, dtype=torch.float64) tensor(0.4250, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(0.0602, dtype=torch.float64) delta_t tensor(-0.1069, dtype=torch.float64)
7 gae_duplicate tensor(-0.5789, dtype=torch.float64) tensor(2.1710, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.3391, dtype=torch.float64) delta_t tensor(0.0652, dtype=torch.float64)
6 gae_duplicate tensor(-0.4737, dtype=torch.float64) tensor(-1.0715, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7552, dtype=torch.float64) delta_t tensor(-0.1448, dtype=torch.float64)
5 gae_duplicate tensor(-0.4446, dtype=torch.float64) tensor(2.7660, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.4317, dtype=torch.float64) delta_t tensor(-0.7249, dtype=torch.float64)
4 gae_duplicate tensor(-1.4755, dtype=torch.float64) tensor(14.5922, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.5644, dtype=torch.float64) delta_t tensor(-0.8632, dtype=torch.float64)
3 gae_duplicate tensor(-1.1747, dtype=torch.float64) tensor(18.4889, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.3141, dtype=torch.float64) delta_t tensor(-0.6814, dtype=torch.float64)
2 gae_duplicate tensor(-1.1151, dtype=torch.float64) tensor(15.3517, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:1003.9646606445312
value loss:58.155086517333984
entropies:355.9451599121094
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.762556076049805 seconds
19 rew tensor(0.8357, dtype=torch.float64) delta_t tensor(0.4883, dtype=torch.float64)
19 gae_duplicate tensor(0.3654, dtype=torch.float64) tensor(-9.6489, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8278, dtype=torch.float64) delta_t tensor(0.5127, dtype=torch.float64)
18 gae_duplicate tensor(0.2777, dtype=torch.float64) tensor(-11.0997, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.7990, dtype=torch.float64) delta_t tensor(0.4357, dtype=torch.float64)
17 gae_duplicate tensor(0.0681, dtype=torch.float64) tensor(-9.7169, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.7390, dtype=torch.float64) delta_t tensor(0.3088, dtype=torch.float64)
16 gae_duplicate tensor(-0.3042, dtype=torch.float64) tensor(-7.0918, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.8660, dtype=torch.float64) delta_t tensor(0.5101, dtype=torch.float64)
15 gae_duplicate tensor(0.4055, dtype=torch.float64) tensor(-10.7894, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8688, dtype=torch.float64) delta_t tensor(0.4786, dtype=torch.float64)
14 gae_duplicate tensor(0.4792, dtype=torch.float64) tensor(-10.5341, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8716, dtype=torch.float64) delta_t tensor(0.5557, dtype=torch.float64)
13 gae_duplicate tensor(0.4824, dtype=torch.float64) tensor(-12.0382, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8744, dtype=torch.float64) delta_t tensor(0.6479, dtype=torch.float64)
12 gae_duplicate tensor(0.4716, dtype=torch.float64) tensor(-14.0174, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8772, dtype=torch.float64) delta_t tensor(0.5301, dtype=torch.float64)
11 gae_duplicate tensor(0.5308, dtype=torch.float64) tensor(-11.8906, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.4547, dtype=torch.float64) delta_t tensor(0.1530, dtype=torch.float64)
10 gae_duplicate tensor(-1.8906, dtype=torch.float64) tensor(-4.2214, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.5699, dtype=torch.float64) delta_t tensor(0.3934, dtype=torch.float64)
9 gae_duplicate tensor(0.3532, dtype=torch.float64) tensor(-8.1991, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.3373, dtype=torch.float64) delta_t tensor(0.1819, dtype=torch.float64)
8 gae_duplicate tensor(0.0296, dtype=torch.float64) tensor(-4.4189, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(0.0648, dtype=torch.float64) delta_t tensor(-0.1226, dtype=torch.float64)
7 gae_duplicate tensor(-0.3797, dtype=torch.float64) tensor(1.9887, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.1783, dtype=torch.float64) delta_t tensor(0.4246, dtype=torch.float64)
6 gae_duplicate tensor(0.1077, dtype=torch.float64) tensor(-8.1992, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7084, dtype=torch.float64) delta_t tensor(0.0314, dtype=torch.float64)
5 gae_duplicate tensor(-0.0646, dtype=torch.float64) tensor(-1.4392, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.5358, dtype=torch.float64) delta_t tensor(-0.7064, dtype=torch.float64)
4 gae_duplicate tensor(-1.2273, dtype=torch.float64) tensor(13.8317, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.4272, dtype=torch.float64) delta_t tensor(-0.5560, dtype=torch.float64)
3 gae_duplicate tensor(-0.9323, dtype=torch.float64) tensor(12.3682, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.1938, dtype=torch.float64) delta_t tensor(-0.5458, dtype=torch.float64)
2 gae_duplicate tensor(-0.9871, dtype=torch.float64) tensor(12.0445, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:4389.75048828125
value loss:53.479915618896484
entropies:355.94873046875
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.832117080688477 seconds
19 rew tensor(0.7614, dtype=torch.float64) delta_t tensor(0.2087, dtype=torch.float64)
19 gae_duplicate tensor(0.0485, dtype=torch.float64) tensor(-4.1253, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.6845, dtype=torch.float64) delta_t tensor(0.1433, dtype=torch.float64)
18 gae_duplicate tensor(-0.0465, dtype=torch.float64) tensor(-3.2479, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.5080, dtype=torch.float64) delta_t tensor(-0.0287, dtype=torch.float64)
17 gae_duplicate tensor(-0.3881, dtype=torch.float64) tensor(0.2436, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.6195, dtype=torch.float64) delta_t tensor(0.0918, dtype=torch.float64)
16 gae_duplicate tensor(-0.4076, dtype=torch.float64) tensor(-1.7918, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.8666, dtype=torch.float64) delta_t tensor(0.3276, dtype=torch.float64)
15 gae_duplicate tensor(0.2777, dtype=torch.float64) tensor(-6.6573, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.8692, dtype=torch.float64) delta_t tensor(0.4704, dtype=torch.float64)
14 gae_duplicate tensor(0.2806, dtype=torch.float64) tensor(-9.9685, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8718, dtype=torch.float64) delta_t tensor(0.5340, dtype=torch.float64)
13 gae_duplicate tensor(0.3095, dtype=torch.float64) tensor(-11.5565, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8744, dtype=torch.float64) delta_t tensor(0.3833, dtype=torch.float64)
12 gae_duplicate tensor(0.3768, dtype=torch.float64) tensor(-8.7348, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.8576, dtype=torch.float64) delta_t tensor(0.4642, dtype=torch.float64)
11 gae_duplicate tensor(0.3548, dtype=torch.float64) tensor(-10.0504, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(-0.3605, dtype=torch.float64) delta_t tensor(-0.7706, dtype=torch.float64)
10 gae_duplicate tensor(-2.0402, dtype=torch.float64) tensor(14.2330, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.5210, dtype=torch.float64) delta_t tensor(0.1503, dtype=torch.float64)
9 gae_duplicate tensor(-0.8872, dtype=torch.float64) tensor(-1.5540, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.2971, dtype=torch.float64) delta_t tensor(-0.4792, dtype=torch.float64)
8 gae_duplicate tensor(-2.1735, dtype=torch.float64) tensor(9.3152, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.2309, dtype=torch.float64) delta_t tensor(-0.3328, dtype=torch.float64)
7 gae_duplicate tensor(-2.4667, dtype=torch.float64) tensor(7.5153, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.4741, dtype=torch.float64) delta_t tensor(-0.0761, dtype=torch.float64)
6 gae_duplicate tensor(-1.1808, dtype=torch.float64) tensor(2.2585, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.6168, dtype=torch.float64) delta_t tensor(0.0711, dtype=torch.float64)
5 gae_duplicate tensor(-0.2147, dtype=torch.float64) tensor(-1.1817, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.1469, dtype=torch.float64) delta_t tensor(-0.2785, dtype=torch.float64)
4 gae_duplicate tensor(-1.4223, dtype=torch.float64) tensor(5.3717, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.6359, dtype=torch.float64) delta_t tensor(-0.7631, dtype=torch.float64)
3 gae_duplicate tensor(-1.1918, dtype=torch.float64) tensor(15.6306, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.4470, dtype=torch.float64) delta_t tensor(-0.5061, dtype=torch.float64)
2 gae_duplicate tensor(-1.2167, dtype=torch.float64) tensor(11.5627, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-488.27008056640625
value loss:72.43254089355469
entropies:355.9495544433594
Policy training finished
---------------------
ToM training started
ToM data loaded
batch_size =  600
ToM_loss = tensor(3956.0249)
ToM Target loss= tensor(3645.9949)
optimized based on ToM loss
---------------------
gamma: 0.1
Process Process-9:
Traceback (most recent call last):
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/suhuangyuan/DRA/ToM2C/train.py", line 452, in train
    for rank in range(args.workers):
KeyboardInterrupt