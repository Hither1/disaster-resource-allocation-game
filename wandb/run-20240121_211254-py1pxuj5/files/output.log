obs <crafter.objects.Shelter object at 0x16d5931c0> [39.  0.  0.  0. 39.  0.  0.  0. 18.  0.  0.  0.]
obs <crafter.objects.Warehouse object at 0x12ee3be20> [41.  0.  0.  0. 39.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Station object at 0x16d599610> [ 9.  0.  0.  0.  9.  0.  0.  0. 13.  0.  0.  0.]
obs <crafter.objects.Shelter object at 0x16d5931c0> [39.  0.  0.  0. 39.  0.  0.  0. 16.  0.  0.  0.]
obs <crafter.objects.Warehouse object at 0x12ee3be20> [42.  0.  0.  0. 38.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Station object at 0x16d599610> [9. 0. 0. 0. 9. 0. 0. 0. 9. 0. 0. 0.]
{'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0}
training start after waiting for 0.0046579837799072266 seconds
19 rew tensor(0.8554, dtype=torch.float64) delta_t tensor(0.9082, dtype=torch.float64)
19 gae_duplicate tensor(0.8688, dtype=torch.float64) tensor(-18.0468, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8948, dtype=torch.float64) delta_t tensor(0.9383, dtype=torch.float64)
18 gae_duplicate tensor(0.9853, dtype=torch.float64) tensor(-20.4649, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9404, dtype=torch.float64) delta_t tensor(0.9835, dtype=torch.float64)
17 gae_duplicate tensor(1.0321, dtype=torch.float64) tensor(-21.2798, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9938, dtype=torch.float64) delta_t tensor(1.0036, dtype=torch.float64)
16 gae_duplicate tensor(0.9292, dtype=torch.float64) tensor(-21.1367, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(1.0579, dtype=torch.float64) delta_t tensor(1.0879, dtype=torch.float64)
15 gae_duplicate tensor(1.1323, dtype=torch.float64) tensor(-23.2866, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(1.1366, dtype=torch.float64) delta_t tensor(1.1603, dtype=torch.float64)
14 gae_duplicate tensor(1.2100, dtype=torch.float64) tensor(-25.4079, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(1.2366, dtype=torch.float64) delta_t tensor(1.2426, dtype=torch.float64)
13 gae_duplicate tensor(1.2136, dtype=torch.float64) tensor(-26.5718, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(1.3699, dtype=torch.float64) delta_t tensor(1.3780, dtype=torch.float64)
12 gae_duplicate tensor(1.3991, dtype=torch.float64) tensor(-29.9791, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(1.5610, dtype=torch.float64) delta_t tensor(1.4435, dtype=torch.float64)
11 gae_duplicate tensor(1.4368, dtype=torch.float64) tensor(-31.2004, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(1.5514, dtype=torch.float64) delta_t tensor(1.3605, dtype=torch.float64)
10 gae_duplicate tensor(1.3606, dtype=torch.float64) tensor(-29.5468, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(1.3809, dtype=torch.float64) delta_t tensor(1.4750, dtype=torch.float64)
9 gae_duplicate tensor(1.5436, dtype=torch.float64) tensor(-31.6676, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(1.3766, dtype=torch.float64) delta_t tensor(1.4233, dtype=torch.float64)
8 gae_duplicate tensor(1.4176, dtype=torch.float64) tensor(-30.8381, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(1.4841, dtype=torch.float64) delta_t tensor(1.5378, dtype=torch.float64)
7 gae_duplicate tensor(1.4928, dtype=torch.float64) tensor(-33.6059, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(1.4646, dtype=torch.float64) delta_t tensor(1.6233, dtype=torch.float64)
6 gae_duplicate tensor(1.4967, dtype=torch.float64) tensor(-35.2114, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(1.1960, dtype=torch.float64) delta_t tensor(1.2562, dtype=torch.float64)
5 gae_duplicate tensor(1.1342, dtype=torch.float64) tensor(-28.6388, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-0.7733, dtype=torch.float64) delta_t tensor(-0.7518, dtype=torch.float64)
4 gae_duplicate tensor(-0.9608, dtype=torch.float64) tensor(11.7813, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-0.9960, dtype=torch.float64) delta_t tensor(-0.8710, dtype=torch.float64)
3 gae_duplicate tensor(-1.0152, dtype=torch.float64) tensor(17.6024, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-0.8978, dtype=torch.float64) delta_t tensor(-0.9086, dtype=torch.float64)
2 gae_duplicate tensor(-1.2150, dtype=torch.float64) tensor(19.8285, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:19218.474609375
value loss:290.3648681640625
entropies:354.4940490722656
Policy training finished
---------------------
gamma: 0.1
/Users/suhuangyuan/DRA/ToM2C/shared_optim.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1420.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
training start after waiting for 5.0462048053741455 seconds
19 rew tensor(0.8749, dtype=torch.float64) delta_t tensor(0.9184, dtype=torch.float64)
19 gae_duplicate tensor(0.8752, dtype=torch.float64) tensor(-17.6934, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8948, dtype=torch.float64) delta_t tensor(0.9335, dtype=torch.float64)
18 gae_duplicate tensor(0.9825, dtype=torch.float64) tensor(-20.8000, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9162, dtype=torch.float64) delta_t tensor(0.9535, dtype=torch.float64)
17 gae_duplicate tensor(1.0005, dtype=torch.float64) tensor(-20.5555, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9392, dtype=torch.float64) delta_t tensor(0.9788, dtype=torch.float64)
16 gae_duplicate tensor(1.0273, dtype=torch.float64) tensor(-21.0422, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9640, dtype=torch.float64) delta_t tensor(0.9952, dtype=torch.float64)
15 gae_duplicate tensor(1.0589, dtype=torch.float64) tensor(-21.3911, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9909, dtype=torch.float64) delta_t tensor(1.0156, dtype=torch.float64)
14 gae_duplicate tensor(1.0875, dtype=torch.float64) tensor(-21.5710, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(1.0203, dtype=torch.float64) delta_t tensor(1.0521, dtype=torch.float64)
13 gae_duplicate tensor(1.1068, dtype=torch.float64) tensor(-23.1187, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(1.0524, dtype=torch.float64) delta_t tensor(1.0747, dtype=torch.float64)
12 gae_duplicate tensor(1.1412, dtype=torch.float64) tensor(-23.8752, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(1.0879, dtype=torch.float64) delta_t tensor(0.9802, dtype=torch.float64)
11 gae_duplicate tensor(1.0591, dtype=torch.float64) tensor(-21.5614, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.8514, dtype=torch.float64) delta_t tensor(0.6465, dtype=torch.float64)
10 gae_duplicate tensor(0.6977, dtype=torch.float64) tensor(-15.0060, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.4353, dtype=torch.float64) delta_t tensor(0.5192, dtype=torch.float64)
9 gae_duplicate tensor(0.5278, dtype=torch.float64) tensor(-11.9607, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.2623, dtype=torch.float64) delta_t tensor(0.2233, dtype=torch.float64)
8 gae_duplicate tensor(-0.0326, dtype=torch.float64) tensor(-5.5929, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(0.1258, dtype=torch.float64) delta_t tensor(0.1698, dtype=torch.float64)
7 gae_duplicate tensor(-0.1453, dtype=torch.float64) tensor(-3.8794, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.0801, dtype=torch.float64) delta_t tensor(0.0602, dtype=torch.float64)
6 gae_duplicate tensor(-0.0288, dtype=torch.float64) tensor(-1.5567, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.4912, dtype=torch.float64) delta_t tensor(-0.4305, dtype=torch.float64)
5 gae_duplicate tensor(-0.5443, dtype=torch.float64) tensor(8.2361, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.1889, dtype=torch.float64) delta_t tensor(-1.1390, dtype=torch.float64)
4 gae_duplicate tensor(-1.3308, dtype=torch.float64) tensor(23.4165, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.3753, dtype=torch.float64) delta_t tensor(-1.2393, dtype=torch.float64)
3 gae_duplicate tensor(-1.5834, dtype=torch.float64) tensor(26.6295, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.2617, dtype=torch.float64) delta_t tensor(-1.2749, dtype=torch.float64)
2 gae_duplicate tensor(-1.6931, dtype=torch.float64) tensor(28.4890, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:7617.1376953125
value loss:155.3511962890625
entropies:354.9521484375
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.814100027084351 seconds
19 rew tensor(0.8820, dtype=torch.float64) delta_t tensor(0.9089, dtype=torch.float64)
19 gae_duplicate tensor(0.8962, dtype=torch.float64) tensor(-17.9339, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8954, dtype=torch.float64) delta_t tensor(0.9196, dtype=torch.float64)
18 gae_duplicate tensor(0.9998, dtype=torch.float64) tensor(-20.3097, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9094, dtype=torch.float64) delta_t tensor(0.9333, dtype=torch.float64)
17 gae_duplicate tensor(1.0077, dtype=torch.float64) tensor(-19.6457, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9149, dtype=torch.float64) delta_t tensor(0.9075, dtype=torch.float64)
16 gae_duplicate tensor(0.8518, dtype=torch.float64) tensor(-19.5737, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9300, dtype=torch.float64) delta_t tensor(0.9213, dtype=torch.float64)
15 gae_duplicate tensor(0.9044, dtype=torch.float64) tensor(-20.1678, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9549, dtype=torch.float64) delta_t tensor(0.9397, dtype=torch.float64)
14 gae_duplicate tensor(0.9383, dtype=torch.float64) tensor(-20.1829, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9629, dtype=torch.float64) delta_t tensor(0.9548, dtype=torch.float64)
13 gae_duplicate tensor(0.9686, dtype=torch.float64) tensor(-20.9478, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9715, dtype=torch.float64) delta_t tensor(0.9673, dtype=torch.float64)
12 gae_duplicate tensor(1.0265, dtype=torch.float64) tensor(-21.2850, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.9717, dtype=torch.float64) delta_t tensor(0.8270, dtype=torch.float64)
11 gae_duplicate tensor(0.7293, dtype=torch.float64) tensor(-18.0018, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.7518, dtype=torch.float64) delta_t tensor(0.5969, dtype=torch.float64)
10 gae_duplicate tensor(0.5902, dtype=torch.float64) tensor(-13.3654, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.3285, dtype=torch.float64) delta_t tensor(0.3525, dtype=torch.float64)
9 gae_duplicate tensor(0.3202, dtype=torch.float64) tensor(-8.3788, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.1512, dtype=torch.float64) delta_t tensor(0.1836, dtype=torch.float64)
8 gae_duplicate tensor(0.0653, dtype=torch.float64) tensor(-4.5671, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.0098, dtype=torch.float64) delta_t tensor(0.0545, dtype=torch.float64)
7 gae_duplicate tensor(-0.2839, dtype=torch.float64) tensor(-1.4596, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.3190, dtype=torch.float64) delta_t tensor(-0.1984, dtype=torch.float64)
6 gae_duplicate tensor(-0.6064, dtype=torch.float64) tensor(3.6008, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7014, dtype=torch.float64) delta_t tensor(-0.6527, dtype=torch.float64)
5 gae_duplicate tensor(-1.1379, dtype=torch.float64) tensor(12.8270, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.4247, dtype=torch.float64) delta_t tensor(-1.3760, dtype=torch.float64)
4 gae_duplicate tensor(-1.5657, dtype=torch.float64) tensor(28.4364, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.6466, dtype=torch.float64) delta_t tensor(-1.5293, dtype=torch.float64)
3 gae_duplicate tensor(-2.0940, dtype=torch.float64) tensor(33.5590, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.5095, dtype=torch.float64) delta_t tensor(-1.4867, dtype=torch.float64)
2 gae_duplicate tensor(-2.2007, dtype=torch.float64) tensor(33.0294, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:5000.0009765625
value loss:165.36849975585938
entropies:354.7797546386719
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.88436484336853 seconds
19 rew tensor(0.8824, dtype=torch.float64) delta_t tensor(0.9092, dtype=torch.float64)
19 gae_duplicate tensor(0.8799, dtype=torch.float64) tensor(-18.4471, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8923, dtype=torch.float64) delta_t tensor(0.9168, dtype=torch.float64)
18 gae_duplicate tensor(0.9764, dtype=torch.float64) tensor(-19.5979, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9026, dtype=torch.float64) delta_t tensor(0.9277, dtype=torch.float64)
17 gae_duplicate tensor(1.0084, dtype=torch.float64) tensor(-20.2991, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9133, dtype=torch.float64) delta_t tensor(0.9344, dtype=torch.float64)
16 gae_duplicate tensor(1.0169, dtype=torch.float64) tensor(-19.6101, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9244, dtype=torch.float64) delta_t tensor(0.9326, dtype=torch.float64)
15 gae_duplicate tensor(1.0149, dtype=torch.float64) tensor(-20.8756, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9359, dtype=torch.float64) delta_t tensor(0.9313, dtype=torch.float64)
14 gae_duplicate tensor(1.0185, dtype=torch.float64) tensor(-20.4325, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9478, dtype=torch.float64) delta_t tensor(0.9598, dtype=torch.float64)
13 gae_duplicate tensor(1.0450, dtype=torch.float64) tensor(-20.6914, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9602, dtype=torch.float64) delta_t tensor(0.9477, dtype=torch.float64)
12 gae_duplicate tensor(1.0270, dtype=torch.float64) tensor(-20.3832, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.9731, dtype=torch.float64) delta_t tensor(0.7964, dtype=torch.float64)
11 gae_duplicate tensor(0.8491, dtype=torch.float64) tensor(-17.8822, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.7129, dtype=torch.float64) delta_t tensor(0.4950, dtype=torch.float64)
10 gae_duplicate tensor(0.5298, dtype=torch.float64) tensor(-11.3469, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.2299, dtype=torch.float64) delta_t tensor(0.2923, dtype=torch.float64)
9 gae_duplicate tensor(0.3224, dtype=torch.float64) tensor(-7.1017, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.1436, dtype=torch.float64) delta_t tensor(0.2057, dtype=torch.float64)
8 gae_duplicate tensor(0.0463, dtype=torch.float64) tensor(-4.8144, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.0342, dtype=torch.float64) delta_t tensor(-0.0154, dtype=torch.float64)
7 gae_duplicate tensor(-0.3820, dtype=torch.float64) tensor(-0.1863, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.2312, dtype=torch.float64) delta_t tensor(-0.0765, dtype=torch.float64)
6 gae_duplicate tensor(-0.1456, dtype=torch.float64) tensor(1.4916, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.6759, dtype=torch.float64) delta_t tensor(-0.6311, dtype=torch.float64)
5 gae_duplicate tensor(-0.7351, dtype=torch.float64) tensor(12.7556, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.5661, dtype=torch.float64) delta_t tensor(-1.5113, dtype=torch.float64)
4 gae_duplicate tensor(-1.8274, dtype=torch.float64) tensor(31.1264, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.7486, dtype=torch.float64) delta_t tensor(-1.5978, dtype=torch.float64)
3 gae_duplicate tensor(-1.8825, dtype=torch.float64) tensor(34.6464, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.5904, dtype=torch.float64) delta_t tensor(-1.5800, dtype=torch.float64)
2 gae_duplicate tensor(-1.9029, dtype=torch.float64) tensor(33.8606, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:4644.8525390625
value loss:170.27740478515625
entropies:354.39862060546875
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 4.8811399936676025 seconds
19 rew tensor(0.8866, dtype=torch.float64) delta_t tensor(0.9078, dtype=torch.float64)
19 gae_duplicate tensor(0.8729, dtype=torch.float64) tensor(-18.3410, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8946, dtype=torch.float64) delta_t tensor(0.9100, dtype=torch.float64)
18 gae_duplicate tensor(0.9685, dtype=torch.float64) tensor(-19.4355, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.9029, dtype=torch.float64) delta_t tensor(0.9215, dtype=torch.float64)
17 gae_duplicate tensor(0.9858, dtype=torch.float64) tensor(-20.0295, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9027, dtype=torch.float64) delta_t tensor(0.9198, dtype=torch.float64)
16 gae_duplicate tensor(0.9843, dtype=torch.float64) tensor(-20.3091, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9112, dtype=torch.float64) delta_t tensor(0.9160, dtype=torch.float64)
15 gae_duplicate tensor(0.9895, dtype=torch.float64) tensor(-19.7938, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9287, dtype=torch.float64) delta_t tensor(0.9251, dtype=torch.float64)
14 gae_duplicate tensor(0.9839, dtype=torch.float64) tensor(-20.2550, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9379, dtype=torch.float64) delta_t tensor(0.9281, dtype=torch.float64)
13 gae_duplicate tensor(0.9973, dtype=torch.float64) tensor(-20.6149, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9474, dtype=torch.float64) delta_t tensor(0.9077, dtype=torch.float64)
12 gae_duplicate tensor(0.9850, dtype=torch.float64) tensor(-20.0738, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.4146, dtype=torch.float64) delta_t tensor(0.2475, dtype=torch.float64)
11 gae_duplicate tensor(-2.2350, dtype=torch.float64) tensor(-6.7476, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6726, dtype=torch.float64) delta_t tensor(0.3906, dtype=torch.float64)
10 gae_duplicate tensor(0.0830, dtype=torch.float64) tensor(-8.3199, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.2466, dtype=torch.float64) delta_t tensor(0.2762, dtype=torch.float64)
9 gae_duplicate tensor(0.2150, dtype=torch.float64) tensor(-6.4981, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.0448, dtype=torch.float64) delta_t tensor(-0.0246, dtype=torch.float64)
8 gae_duplicate tensor(-0.8067, dtype=torch.float64) tensor(-0.0432, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.0512, dtype=torch.float64) delta_t tensor(-0.0167, dtype=torch.float64)
7 gae_duplicate tensor(-0.1402, dtype=torch.float64) tensor(0.2500, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.2750, dtype=torch.float64) delta_t tensor(-0.0919, dtype=torch.float64)
6 gae_duplicate tensor(-0.1725, dtype=torch.float64) tensor(1.8603, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7341, dtype=torch.float64) delta_t tensor(-0.6525, dtype=torch.float64)
5 gae_duplicate tensor(-0.8068, dtype=torch.float64) tensor(13.1405, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.4911, dtype=torch.float64) delta_t tensor(-1.4482, dtype=torch.float64)
4 gae_duplicate tensor(-1.9374, dtype=torch.float64) tensor(29.4688, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.6816, dtype=torch.float64) delta_t tensor(-1.5358, dtype=torch.float64)
3 gae_duplicate tensor(-1.7906, dtype=torch.float64) tensor(33.4856, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.5380, dtype=torch.float64) delta_t tensor(-1.5292, dtype=torch.float64)
2 gae_duplicate tensor(-1.8920, dtype=torch.float64) tensor(31.7463, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:3711.890869140625
value loss:167.57093811035156
entropies:354.2363586425781
Policy training finished
---------------------
ToM training started
ToM data loaded
batch_size =  600
ToM_loss = tensor(3979.0925)
ToM Target loss= tensor(3824.4766)
optimized based on ToM loss
---------------------
gamma: 0.1
training start after waiting for 4.871412038803101 seconds
19 rew tensor(0.8843, dtype=torch.float64) delta_t tensor(0.8642, dtype=torch.float64)
19 gae_duplicate tensor(0.8399, dtype=torch.float64) tensor(-16.9017, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8909, dtype=torch.float64) delta_t tensor(0.8698, dtype=torch.float64)
18 gae_duplicate tensor(0.9399, dtype=torch.float64) tensor(-19.6843, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(0.8977, dtype=torch.float64) delta_t tensor(0.8719, dtype=torch.float64)
17 gae_duplicate tensor(0.9472, dtype=torch.float64) tensor(-20.0862, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(0.9046, dtype=torch.float64) delta_t tensor(0.8601, dtype=torch.float64)
16 gae_duplicate tensor(0.8482, dtype=torch.float64) tensor(-18.8375, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9117, dtype=torch.float64) delta_t tensor(0.8764, dtype=torch.float64)
15 gae_duplicate tensor(0.9302, dtype=torch.float64) tensor(-19.1931, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9190, dtype=torch.float64) delta_t tensor(0.8806, dtype=torch.float64)
14 gae_duplicate tensor(0.9692, dtype=torch.float64) tensor(-19.7126, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.9265, dtype=torch.float64) delta_t tensor(0.8861, dtype=torch.float64)
13 gae_duplicate tensor(0.8882, dtype=torch.float64) tensor(-19.2739, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.9341, dtype=torch.float64) delta_t tensor(0.8899, dtype=torch.float64)
12 gae_duplicate tensor(0.9772, dtype=torch.float64) tensor(-19.0854, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.9419, dtype=torch.float64) delta_t tensor(0.7188, dtype=torch.float64)
11 gae_duplicate tensor(0.7877, dtype=torch.float64) tensor(-16.2324, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.6760, dtype=torch.float64) delta_t tensor(0.4214, dtype=torch.float64)
10 gae_duplicate tensor(0.4496, dtype=torch.float64) tensor(-9.7161, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.2820, dtype=torch.float64) delta_t tensor(0.2995, dtype=torch.float64)
9 gae_duplicate tensor(0.2736, dtype=torch.float64) tensor(-6.7268, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.1904, dtype=torch.float64) delta_t tensor(0.2859, dtype=torch.float64)
8 gae_duplicate tensor(-0.0648, dtype=torch.float64) tensor(-6.2867, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.0255, dtype=torch.float64) delta_t tensor(-0.0076, dtype=torch.float64)
7 gae_duplicate tensor(-0.0072, dtype=torch.float64) tensor(-0.4855, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.2858, dtype=torch.float64) delta_t tensor(-0.1713, dtype=torch.float64)
6 gae_duplicate tensor(-0.3646, dtype=torch.float64) tensor(3.2326, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.7262, dtype=torch.float64) delta_t tensor(-0.6255, dtype=torch.float64)
5 gae_duplicate tensor(-0.6953, dtype=torch.float64) tensor(12.3812, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-1.7685, dtype=torch.float64) delta_t tensor(-1.7357, dtype=torch.float64)
4 gae_duplicate tensor(-2.0776, dtype=torch.float64) tensor(35.1337, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.7125, dtype=torch.float64) delta_t tensor(-1.5820, dtype=torch.float64)
3 gae_duplicate tensor(-1.9364, dtype=torch.float64) tensor(34.1927, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(-1.5276, dtype=torch.float64) delta_t tensor(-1.5093, dtype=torch.float64)
2 gae_duplicate tensor(-1.8740, dtype=torch.float64) tensor(32.7157, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:3930.9365234375
value loss:164.51803588867188
entropies:354.27703857421875
Policy training finished
---------------------
gamma: 0.1
Process Process-9:
Traceback (most recent call last):
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/suhuangyuan/DRA/ToM2C/train.py", line 453, in train
    if train_modes[rank] != -10:
  File "<string>", line 2, in __getitem__
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/managers.py", line 810, in _callmethod
    kind, result = conn.recv()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt