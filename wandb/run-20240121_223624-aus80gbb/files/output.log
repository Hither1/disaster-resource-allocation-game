obs <crafter.objects.Shelter object at 0x13f05a670> [39.  0.  0.  0. 39.  0.  0.  0. 15.  0.  0.  0.]
obs <crafter.objects.Warehouse object at 0x13f05a040> [38.  0.  0.  0. 39.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Station object at 0x13f060700> [ 9.  0.  0.  0.  9.  0.  0.  0. 14.  0.  0.  0.]
obs <crafter.objects.Shelter object at 0x13f05a670> [39.  0.  0.  0. 39.  0.  0.  0. 16.  0.  0.  0.]
obs <crafter.objects.Warehouse object at 0x13f05a040> [40.  0.  0.  0. 40.  0.  0.  0.  9.  0.  0.  0.]
obs <crafter.objects.Station object at 0x13f060700> [9. 0. 0. 0. 9. 0. 0. 0. 9. 0. 0. 0.]
{'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0} {'food': 0.0, 'drink': 0.0, 'staff': 0.0}
training start after waiting for 0.0031249523162841797 seconds
19 rew tensor(1.1337, dtype=torch.float64) delta_t tensor(0.8489, dtype=torch.float64)
19 gae_duplicate tensor(0.5979, dtype=torch.float64) tensor(-17.6030, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(1.1574, dtype=torch.float64) delta_t tensor(0.9139, dtype=torch.float64)
18 gae_duplicate tensor(0.7327, dtype=torch.float64) tensor(-19.8732, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(1.1760, dtype=torch.float64) delta_t tensor(0.9318, dtype=torch.float64)
17 gae_duplicate tensor(0.7913, dtype=torch.float64) tensor(-19.9065, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(1.1281, dtype=torch.float64) delta_t tensor(0.8907, dtype=torch.float64)
16 gae_duplicate tensor(0.8589, dtype=torch.float64) tensor(-20.4324, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(1.1643, dtype=torch.float64) delta_t tensor(0.9831, dtype=torch.float64)
15 gae_duplicate tensor(0.7847, dtype=torch.float64) tensor(-20.5400, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(1.0805, dtype=torch.float64) delta_t tensor(0.9410, dtype=torch.float64)
14 gae_duplicate tensor(0.9778, dtype=torch.float64) tensor(-21.6063, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(1.1377, dtype=torch.float64) delta_t tensor(1.0973, dtype=torch.float64)
13 gae_duplicate tensor(0.6322, dtype=torch.float64) tensor(-24.9538, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.8569, dtype=torch.float64) delta_t tensor(0.7150, dtype=torch.float64)
12 gae_duplicate tensor(0.6027, dtype=torch.float64) tensor(-15.8826, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.5851, dtype=torch.float64) delta_t tensor(0.5693, dtype=torch.float64)
11 gae_duplicate tensor(-1.7901, dtype=torch.float64) tensor(-12.9960, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.1344, dtype=torch.float64) delta_t tensor(-0.1156, dtype=torch.float64)
10 gae_duplicate tensor(-3.1741, dtype=torch.float64) tensor(1.5942, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(1.0055, dtype=torch.float64) delta_t tensor(0.8162, dtype=torch.float64)
9 gae_duplicate tensor(0.1716, dtype=torch.float64) tensor(-15.5227, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(0.3604, dtype=torch.float64) delta_t tensor(0.1117, dtype=torch.float64)
8 gae_duplicate tensor(-0.1110, dtype=torch.float64) tensor(-3.9564, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(0.1322, dtype=torch.float64) delta_t tensor(-0.2335, dtype=torch.float64)
7 gae_duplicate tensor(-1.0867, dtype=torch.float64) tensor(3.5875, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.0563, dtype=torch.float64) delta_t tensor(-0.1429, dtype=torch.float64)
6 gae_duplicate tensor(-1.4921, dtype=torch.float64) tensor(3.5019, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-0.8402, dtype=torch.float64) delta_t tensor(-1.1343, dtype=torch.float64)
5 gae_duplicate tensor(-1.6139, dtype=torch.float64) tensor(22.5742, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(0.6164, dtype=torch.float64) delta_t tensor(0.6759, dtype=torch.float64)
4 gae_duplicate tensor(-0.6732, dtype=torch.float64) tensor(-10.6616, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-0.1585, dtype=torch.float64) delta_t tensor(-0.1535, dtype=torch.float64)
3 gae_duplicate tensor(-0.5971, dtype=torch.float64) tensor(1.5466, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(1.1218, dtype=torch.float64) delta_t tensor(1.1114, dtype=torch.float64)
2 gae_duplicate tensor(0.9811, dtype=torch.float64) tensor(-22.9847, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:10387.0009765625
value loss:165.4911651611328
entropies:352.5664367675781
Policy training finished
---------------------
gamma: 0.1
/Users/suhuangyuan/DRA/ToM2C/shared_optim.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1420.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
training start after waiting for 4.963630199432373 seconds
19 rew tensor(1.1536, dtype=torch.float64) delta_t tensor(0.9132, dtype=torch.float64)
19 gae_duplicate tensor(0.5898, dtype=torch.float64) tensor(-18.7894, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(0.8481, dtype=torch.float64) delta_t tensor(0.5975, dtype=torch.float64)
18 gae_duplicate tensor(-0.5983, dtype=torch.float64) tensor(-13.6574, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(1.0806, dtype=torch.float64) delta_t tensor(0.8465, dtype=torch.float64)
17 gae_duplicate tensor(0.6642, dtype=torch.float64) tensor(-17.6242, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(1.1064, dtype=torch.float64) delta_t tensor(0.8826, dtype=torch.float64)
16 gae_duplicate tensor(0.7317, dtype=torch.float64) tensor(-19.2516, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9939, dtype=torch.float64) delta_t tensor(0.7872, dtype=torch.float64)
15 gae_duplicate tensor(0.6604, dtype=torch.float64) tensor(-17.4340, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.9216, dtype=torch.float64) delta_t tensor(0.7720, dtype=torch.float64)
14 gae_duplicate tensor(0.5117, dtype=torch.float64) tensor(-16.1972, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.3095, dtype=torch.float64) delta_t tensor(0.2559, dtype=torch.float64)
13 gae_duplicate tensor(-1.7360, dtype=torch.float64) tensor(-6.3162, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.3197, dtype=torch.float64) delta_t tensor(0.2307, dtype=torch.float64)
12 gae_duplicate tensor(-0.8545, dtype=torch.float64) tensor(-5.3069, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.5266, dtype=torch.float64) delta_t tensor(0.5425, dtype=torch.float64)
11 gae_duplicate tensor(0.0685, dtype=torch.float64) tensor(-10.8068, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.2671, dtype=torch.float64) delta_t tensor(0.0575, dtype=torch.float64)
10 gae_duplicate tensor(-0.1463, dtype=torch.float64) tensor(-2.1284, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.6276, dtype=torch.float64) delta_t tensor(0.4576, dtype=torch.float64)
9 gae_duplicate tensor(-0.2037, dtype=torch.float64) tensor(-8.7336, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.4087, dtype=torch.float64) delta_t tensor(-0.6973, dtype=torch.float64)
8 gae_duplicate tensor(-1.3830, dtype=torch.float64) tensor(12.2554, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.1960, dtype=torch.float64) delta_t tensor(-0.5415, dtype=torch.float64)
7 gae_duplicate tensor(-1.7076, dtype=torch.float64) tensor(12.1873, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.4495, dtype=torch.float64) delta_t tensor(-0.6353, dtype=torch.float64)
6 gae_duplicate tensor(-1.2940, dtype=torch.float64) tensor(13.3276, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.0846, dtype=torch.float64) delta_t tensor(-1.3750, dtype=torch.float64)
5 gae_duplicate tensor(-1.7806, dtype=torch.float64) tensor(27.5302, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(0.0143, dtype=torch.float64) delta_t tensor(0.1034, dtype=torch.float64)
4 gae_duplicate tensor(-0.6814, dtype=torch.float64) tensor(0.6981, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-0.6194, dtype=torch.float64) delta_t tensor(-0.5895, dtype=torch.float64)
3 gae_duplicate tensor(-1.5018, dtype=torch.float64) tensor(11.1542, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.3057, dtype=torch.float64) delta_t tensor(0.2084, dtype=torch.float64)
2 gae_duplicate tensor(-0.4628, dtype=torch.float64) tensor(-2.9354, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:3253.988037109375
value loss:114.71752166748047
entropies:353.83740234375
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.324131727218628 seconds
19 rew tensor(1.1683, dtype=torch.float64) delta_t tensor(0.8774, dtype=torch.float64)
19 gae_duplicate tensor(0.6250, dtype=torch.float64) tensor(-17.2092, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(1.1390, dtype=torch.float64) delta_t tensor(0.8711, dtype=torch.float64)
18 gae_duplicate tensor(0.7310, dtype=torch.float64) tensor(-17.5888, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(1.0872, dtype=torch.float64) delta_t tensor(0.8362, dtype=torch.float64)
17 gae_duplicate tensor(0.6537, dtype=torch.float64) tensor(-18.7583, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(1.0458, dtype=torch.float64) delta_t tensor(0.8174, dtype=torch.float64)
16 gae_duplicate tensor(0.6527, dtype=torch.float64) tensor(-17.5288, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9615, dtype=torch.float64) delta_t tensor(0.7361, dtype=torch.float64)
15 gae_duplicate tensor(0.6563, dtype=torch.float64) tensor(-16.8934, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.5336, dtype=torch.float64) delta_t tensor(0.3759, dtype=torch.float64)
14 gae_duplicate tensor(-0.8799, dtype=torch.float64) tensor(-9.2445, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.5039, dtype=torch.float64) delta_t tensor(0.3631, dtype=torch.float64)
13 gae_duplicate tensor(-1.0586, dtype=torch.float64) tensor(-8.2609, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.5790, dtype=torch.float64) delta_t tensor(0.4909, dtype=torch.float64)
12 gae_duplicate tensor(0.2209, dtype=torch.float64) tensor(-10.0373, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.4230, dtype=torch.float64) delta_t tensor(0.4556, dtype=torch.float64)
11 gae_duplicate tensor(-0.0127, dtype=torch.float64) tensor(-9.7654, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(0.2218, dtype=torch.float64) delta_t tensor(0.0141, dtype=torch.float64)
10 gae_duplicate tensor(-0.2420, dtype=torch.float64) tensor(-1.3496, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.3909, dtype=torch.float64) delta_t tensor(0.1557, dtype=torch.float64)
9 gae_duplicate tensor(-0.2890, dtype=torch.float64) tensor(-3.0907, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.4282, dtype=torch.float64) delta_t tensor(-0.7513, dtype=torch.float64)
8 gae_duplicate tensor(-1.3827, dtype=torch.float64) tensor(13.9856, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-0.2323, dtype=torch.float64) delta_t tensor(-0.5894, dtype=torch.float64)
7 gae_duplicate tensor(-1.6348, dtype=torch.float64) tensor(13.4466, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.4836, dtype=torch.float64) delta_t tensor(-0.7460, dtype=torch.float64)
6 gae_duplicate tensor(-1.3056, dtype=torch.float64) tensor(16.3490, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.2732, dtype=torch.float64) delta_t tensor(-1.5557, dtype=torch.float64)
5 gae_duplicate tensor(-2.3122, dtype=torch.float64) tensor(31.6392, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-0.1104, dtype=torch.float64) delta_t tensor(-0.0308, dtype=torch.float64)
4 gae_duplicate tensor(-0.6781, dtype=torch.float64) tensor(3.9593, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-0.6583, dtype=torch.float64) delta_t tensor(-0.6009, dtype=torch.float64)
3 gae_duplicate tensor(-1.1582, dtype=torch.float64) tensor(12.4849, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.2098, dtype=torch.float64) delta_t tensor(0.0791, dtype=torch.float64)
2 gae_duplicate tensor(-0.4978, dtype=torch.float64) tensor(-0.3410, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:1967.2469482421875
value loss:110.14515686035156
entropies:354.55352783203125
Policy training finished
---------------------
gamma: 0.1
training start after waiting for 5.441846132278442 seconds
19 rew tensor(1.1745, dtype=torch.float64) delta_t tensor(0.9417, dtype=torch.float64)
19 gae_duplicate tensor(0.7254, dtype=torch.float64) tensor(-18.4883, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(1.1380, dtype=torch.float64) delta_t tensor(0.9072, dtype=torch.float64)
18 gae_duplicate tensor(0.7900, dtype=torch.float64) tensor(-19.5003, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(1.1553, dtype=torch.float64) delta_t tensor(0.9227, dtype=torch.float64)
17 gae_duplicate tensor(0.7946, dtype=torch.float64) tensor(-20.1241, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(1.1145, dtype=torch.float64) delta_t tensor(0.8697, dtype=torch.float64)
16 gae_duplicate tensor(0.6719, dtype=torch.float64) tensor(-19.0642, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(0.9716, dtype=torch.float64) delta_t tensor(0.8042, dtype=torch.float64)
15 gae_duplicate tensor(0.5975, dtype=torch.float64) tensor(-17.8727, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.4539, dtype=torch.float64) delta_t tensor(0.2797, dtype=torch.float64)
14 gae_duplicate tensor(-0.4685, dtype=torch.float64) tensor(-7.4797, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(0.8275, dtype=torch.float64) delta_t tensor(0.8327, dtype=torch.float64)
13 gae_duplicate tensor(0.4885, dtype=torch.float64) tensor(-17.2916, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.2662, dtype=torch.float64) delta_t tensor(0.1105, dtype=torch.float64)
12 gae_duplicate tensor(-0.4342, dtype=torch.float64) tensor(-4.0574, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.5924, dtype=torch.float64) delta_t tensor(0.5815, dtype=torch.float64)
11 gae_duplicate tensor(-0.0142, dtype=torch.float64) tensor(-11.7801, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(-0.0710, dtype=torch.float64) delta_t tensor(-0.3306, dtype=torch.float64)
10 gae_duplicate tensor(-0.7043, dtype=torch.float64) tensor(5.4541, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.5349, dtype=torch.float64) delta_t tensor(0.3246, dtype=torch.float64)
9 gae_duplicate tensor(-0.2870, dtype=torch.float64) tensor(-6.0186, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.4965, dtype=torch.float64) delta_t tensor(-0.7410, dtype=torch.float64)
8 gae_duplicate tensor(-1.3234, dtype=torch.float64) tensor(14.1731, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-1.1029, dtype=torch.float64) delta_t tensor(-1.4327, dtype=torch.float64)
7 gae_duplicate tensor(-4.5423, dtype=torch.float64) tensor(29.3953, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.8174, dtype=torch.float64) delta_t tensor(-0.9359, dtype=torch.float64)
6 gae_duplicate tensor(-1.6336, dtype=torch.float64) tensor(21.8227, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.2306, dtype=torch.float64) delta_t tensor(-1.4181, dtype=torch.float64)
5 gae_duplicate tensor(-2.2469, dtype=torch.float64) tensor(29.6750, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(-0.0037, dtype=torch.float64) delta_t tensor(0.0496, dtype=torch.float64)
4 gae_duplicate tensor(-0.9432, dtype=torch.float64) tensor(2.1519, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-0.9188, dtype=torch.float64) delta_t tensor(-0.9515, dtype=torch.float64)
3 gae_duplicate tensor(-2.5669, dtype=torch.float64) tensor(19.4723, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.2773, dtype=torch.float64) delta_t tensor(0.2206, dtype=torch.float64)
2 gae_duplicate tensor(-0.8561, dtype=torch.float64) tensor(-2.4812, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:1092.87060546875
value loss:181.431640625
entropies:355.09521484375
Policy training finished
---------------------
gamma: 0.1
Process Process-9:
Traceback (most recent call last):
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/Users/suhuangyuan/miniconda3/envs/resource/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/suhuangyuan/DRA/ToM2C/train.py", line 501, in train
    ToM_loss_sum, ToM_loss_avg, ToM_target_loss, ToM_target_acc = optimize_ToM(state, masks, available_actions, args, params_ToM, optimizer_ToM, shared_model, device_share, env)
  File "/Users/suhuangyuan/DRA/ToM2C/train.py", line 126, in optimize_ToM
    loss.backward()
AttributeError: 'float' object has no attribute 'backward'
training start after waiting for 4.773961067199707 seconds
19 rew tensor(1.2224, dtype=torch.float64) delta_t tensor(0.9073, dtype=torch.float64)
19 gae_duplicate tensor(0.7987, dtype=torch.float64) tensor(-18.0518, dtype=torch.float64, grad_fn=<SumBackward0>)
18 rew tensor(1.2381, dtype=torch.float64) delta_t tensor(0.9692, dtype=torch.float64)
18 gae_duplicate tensor(0.9429, dtype=torch.float64) tensor(-21.0267, dtype=torch.float64, grad_fn=<SumBackward0>)
17 rew tensor(1.1707, dtype=torch.float64) delta_t tensor(0.8979, dtype=torch.float64)
17 gae_duplicate tensor(0.8473, dtype=torch.float64) tensor(-19.4560, dtype=torch.float64, grad_fn=<SumBackward0>)
16 rew tensor(1.0863, dtype=torch.float64) delta_t tensor(0.8298, dtype=torch.float64)
16 gae_duplicate tensor(0.6651, dtype=torch.float64) tensor(-17.5826, dtype=torch.float64, grad_fn=<SumBackward0>)
15 rew tensor(1.0794, dtype=torch.float64) delta_t tensor(0.8294, dtype=torch.float64)
15 gae_duplicate tensor(0.7144, dtype=torch.float64) tensor(-18.1627, dtype=torch.float64, grad_fn=<SumBackward0>)
14 rew tensor(0.3343, dtype=torch.float64) delta_t tensor(0.2067, dtype=torch.float64)
14 gae_duplicate tensor(-1.1420, dtype=torch.float64) tensor(-5.8101, dtype=torch.float64, grad_fn=<SumBackward0>)
13 rew tensor(-0.3567, dtype=torch.float64) delta_t tensor(-0.3329, dtype=torch.float64)
13 gae_duplicate tensor(-1.9962, dtype=torch.float64) tensor(6.0099, dtype=torch.float64, grad_fn=<SumBackward0>)
12 rew tensor(0.0146, dtype=torch.float64) delta_t tensor(-0.0877, dtype=torch.float64)
12 gae_duplicate tensor(-0.9260, dtype=torch.float64) tensor(2.5175, dtype=torch.float64, grad_fn=<SumBackward0>)
11 rew tensor(0.5607, dtype=torch.float64) delta_t tensor(0.5447, dtype=torch.float64)
11 gae_duplicate tensor(0.3194, dtype=torch.float64) tensor(-10.3686, dtype=torch.float64, grad_fn=<SumBackward0>)
10 rew tensor(-0.0958, dtype=torch.float64) delta_t tensor(-0.3770, dtype=torch.float64)
10 gae_duplicate tensor(-0.7593, dtype=torch.float64) tensor(6.3264, dtype=torch.float64, grad_fn=<SumBackward0>)
9 rew tensor(0.7363, dtype=torch.float64) delta_t tensor(0.4456, dtype=torch.float64)
9 gae_duplicate tensor(0.0511, dtype=torch.float64) tensor(-8.0526, dtype=torch.float64, grad_fn=<SumBackward0>)
8 rew tensor(-0.6542, dtype=torch.float64) delta_t tensor(-0.8730, dtype=torch.float64)
8 gae_duplicate tensor(-1.1003, dtype=torch.float64) tensor(16.5923, dtype=torch.float64, grad_fn=<SumBackward0>)
7 rew tensor(-1.4292, dtype=torch.float64) delta_t tensor(-1.8074, dtype=torch.float64)
7 gae_duplicate tensor(-4.2343, dtype=torch.float64) tensor(37.5748, dtype=torch.float64, grad_fn=<SumBackward0>)
6 rew tensor(-0.8123, dtype=torch.float64) delta_t tensor(-0.8067, dtype=torch.float64)
6 gae_duplicate tensor(-1.3963, dtype=torch.float64) tensor(19.6566, dtype=torch.float64, grad_fn=<SumBackward0>)
5 rew tensor(-1.4713, dtype=torch.float64) delta_t tensor(-1.7910, dtype=torch.float64)
5 gae_duplicate tensor(-2.1033, dtype=torch.float64) tensor(36.8300, dtype=torch.float64, grad_fn=<SumBackward0>)
4 rew tensor(0.3804, dtype=torch.float64) delta_t tensor(0.3967, dtype=torch.float64)
4 gae_duplicate tensor(-0.0580, dtype=torch.float64) tensor(-4.1848, dtype=torch.float64, grad_fn=<SumBackward0>)
3 rew tensor(-1.6237, dtype=torch.float64) delta_t tensor(-1.6049, dtype=torch.float64)
3 gae_duplicate tensor(-2.0782, dtype=torch.float64) tensor(31.5256, dtype=torch.float64, grad_fn=<SumBackward0>)
2 rew tensor(0.6922, dtype=torch.float64) delta_t tensor(0.7460, dtype=torch.float64)
2 gae_duplicate tensor(0.2754, dtype=torch.float64) tensor(-11.5943, dtype=torch.float64, grad_fn=<SumBackward0>)
policy loss:-1324.0543212890625
value loss:192.9093475341797
entropies:355.30487060546875
Policy training finished
---------------------
ToM training started
ToM data loaded